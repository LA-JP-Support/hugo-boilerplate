<!DOCTYPE html>
<html dir="ltr" lang="ja">
<head>
<meta content="strict-origin-when-cross-origin" name="referrer"/>
<meta charset="utf-8"/>
<meta content="minimum-scale=1, width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport"/>
<title>音声認識 | SmartWeb</title>
<link href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/speech-recognition/" rel="canonical"/>
<link href="/images/faivicon.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="/images/faivicon.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="/images/faivicon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="/images/faivicon.png" rel="shortcut icon"/>
<link href="https://main.d1jtfhinlastnr.amplifyapp.com/glossary/speech-recognition/" hreflang="en" rel="alternate"/>
<link href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/speech-recognition/" hreflang="ja" rel="alternate"/>
<link href="https://main.d1jtfhinlastnr.amplifyapp.com/glossary/speech-recognition/" hreflang="x-default" rel="alternate"/>
<meta content="音声認識(ASR)は、話し言葉をテキストに変換する技術です。このAI技術の仕組み、アルゴリズム、機能、応用分野、そして今後のトレンドについて解説します。" name="description"/>
<meta content="音声認識, ASR, ディープラーニング, AI, 文字起こし" name="keywords"/>
<meta content="website" property="og:type"/>
<meta content="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/speech-recognition/" property="og:url"/>
<meta content="音声認識 | SmartWeb" property="og:title"/>
<meta content="音声認識(ASR)は、話し言葉をテキストに変換する技術です。このAI技術の仕組み、アルゴリズム、機能、応用分野、そして今後のトレンドについて解説します。" property="og:description"/>
<meta content="" property="og:image"/>
<meta content="1200" property="og:image:width"/>
<meta content="630" property="og:image:height"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/speech-recognition/" name="twitter:url"/>
<meta content="音声認識 | SmartWeb" name="twitter:title"/>
<meta content="音声認識(ASR)は、話し言葉をテキストに変換する技術です。このAI技術の仕組み、アルゴリズム、機能、応用分野、そして今後のトレンドについて解説します。" name="twitter:description"/>
<meta content="" name="twitter:image"/>
<style>
  :root {
     
    --color-primary: #1a73e8;
    --color-primary-light: #4285f4;
    --color-primary-dark: #1557b0;

    --color-secondary: #34a853;
    --color-accent: #fbbc05;

    --color-text: #202124;
    --color-background: #ffffff;

     
    --gradient-primary: linear-gradient(to right, var(--color-primary), var(--color-primary-light));
  }

   
  .bg-gradient-primary {
    background-image: var(--gradient-primary);
  }

  .text-gradient,
  .text-gradient-primary {
    background-image: var(--gradient-primary);
    background-clip: text;
    -webkit-background-clip: text;
    color: transparent;
    -webkit-text-fill-color: transparent;
  }
</style>
<link as="font" crossorigin="anonymous" href="/fonts/inter/Inter-VariableFont_opsz,wght.woff2" rel="preload" type="font/woff2"/>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;500;700&amp;family=Noto+Serif+JP:wght@400;500;600;700&amp;display=swap" rel="stylesheet"/>
<link crossorigin="anonymous" href="/css/main.css?v=20260111190816" rel="stylesheet"/>
<link crossorigin="anonymous" href="/css/custom-code-blockquote.css?v=20260111190816" rel="stylesheet"/>
<script defer="" src="/js/main.js?v=20260111190816"></script>
</head>
<body class="antialiased bg-white">
<header class="bg-white">
<nav aria-label="Global" class="mx-auto flex max-w-7xl items-center justify-between gap-x-6 p-6 lg:px-8">
<div class="flex lg:flex-1">
<a class="-m-1.5 p-1.5" href="/ja/">
<span class="sr-only">SmartWeb</span>
<picture class="lazy-picture" data-maxwidth="200">
<source data-original-src="/images/smartweb-logo.png" data-srcset="/images/smartweb-logo.png 466w" sizes="200px" type="image/png">
<img alt="SmartWeb Logo" class="lazy-image h-6 sm:h-10 md:h-12 w-auto" data-original-src="/images/smartweb-logo.png" data-src="/images/smartweb-logo.png" decoding="async" loading="lazy"/>
</source></picture>
</a>
</div>
<div class="hidden lg:flex lg:gap-x-12"><a class="text-sm/6 font-semibold text-gray-900" href="/ja/">ホーム</a><a class="text-sm/6 font-semibold text-gray-900" href="/ja/blog/">ブログ</a><a class="text-sm/6 font-semibold text-gray-900" href="/ja/glossary/">用語集</a><a class="text-sm/6 font-semibold text-gray-900" href="https://www.intwk.co.jp/about/">会社情報</a></div>
<div class="flex flex-1 items-center justify-end gap-x-6">
<a class="hidden text-sm/6 font-semibold text-gray-900 lg:block" href="https://support.smartweb.jp/">サポート</a>
<a class="rounded-md bg-indigo-600 px-3 py-2 text-sm font-semibold text-white shadow-xs hover:bg-indigo-500 focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-indigo-600" href="/ja/blog/">今すぐ始める</a>
</div>
<div class="flex lg:hidden">
<button aria-controls="mobile-menu-1768126096741115000" aria-expanded="false" class="-m-2.5 inline-flex items-center justify-center rounded-xl p-2.5 text-gray-700" type="button">
<span class="sr-only">Open main menu</span>
<svg aria-hidden="true" class="size-6" data-slot="icon" fill="none" stroke="currentColor" stroke-width="1.5" viewbox="0 0 24 24">
<path d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
</svg>
</button>
</div>
</nav>
<div aria-modal="true" class="lg:hidden hidden relative z-50" id="mobile-menu-1768126096741115000" role="dialog">
<div class="fixed inset-0 z-50 bg-black bg-opacity-25"></div>
<div class="fixed inset-y-0 right-0 z-50 w-full overflow-y-auto bg-white px-6 py-6 sm:max-w-sm sm:ring-1 sm:ring-gray-900/10 transform transition-transform duration-300 ease-in-out translate-x-full">
<div class="flex items-center gap-x-6">
<a class="-m-1.5 p-1.5" href="/ja/">
<span class="sr-only">SmartWeb</span>
<picture class="lazy-picture" data-maxwidth="3000">
<source data-original-src="/images/smartweb-logo.png" data-srcset="/images/smartweb-logo.png 466w" sizes="(max-width: 466px) 466px, 3000px" type="image/png">
<img alt="SmartWeb Logo" class="lazy-image h-6 sm:h-10 md:h-12 w-auto" data-original-src="/images/smartweb-logo.png" data-src="/images/smartweb-logo.png" decoding="async" loading="lazy"/>
</source></picture>
</a>
<a class="ml-auto rounded-md bg-indigo-600 px-3 py-2 text-sm font-semibold text-white shadow-xs hover:bg-indigo-500 focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-indigo-600" href="/ja/blog/">今すぐ始める</a>
<button class="-m-2.5 rounded-xl p-2.5 text-gray-700 close-mobile-menu" type="button">
<span class="sr-only">Close menu</span>
<svg aria-hidden="true" class="size-6" data-slot="icon" fill="none" stroke="currentColor" stroke-width="1.5" viewbox="0 0 24 24">
<path d="M6 18 18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
</svg>
</button>
</div>
<div class="mt-6 flow-root">
<div class="-my-6 divide-y divide-gray-500/10">
<div class="space-y-2 py-6"><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="/ja/">ホーム</a><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="/ja/blog/">ブログ</a><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="/ja/glossary/">用語集</a><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="https://www.intwk.co.jp/about/">会社情報</a></div>
<div class="py-6">
<a class="-mx-3 block rounded-lg px-3 py-2.5 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="https://support.smartweb.jp/">サポート</a>
</div>
</div>
</div>
</div>
</div>
</header>
<script>
  document.addEventListener('DOMContentLoaded', function() {
    const mobileMenuButton = document.querySelector('[aria-controls="mobile-menu-1768126096741115000"]');
    const mobileMenu = document.getElementById('mobile-menu-1768126096741115000');
    const closeButtons = document.querySelectorAll('.close-mobile-menu');
    const mobileMenuContent = mobileMenu.querySelector('.fixed.inset-y-0');
    
    if (mobileMenuButton && mobileMenu) {
      mobileMenuButton.addEventListener('click', function() {
        const expanded = mobileMenuButton.getAttribute('aria-expanded') === 'true';
        
        if (expanded) {
          closeMobileMenu();
        } else {
          openMobileMenu();
        }
      });
      
      
      closeButtons.forEach(button => {
        button.addEventListener('click', closeMobileMenu);
      });
      
      
      mobileMenu.addEventListener('click', function(event) {
        if (event.target === mobileMenu) {
          closeMobileMenu();
        }
      });
      
      
      mobileMenuContent.addEventListener('click', function(event) {
        event.stopPropagation();
      });
      
      function openMobileMenu() {
        mobileMenuButton.setAttribute('aria-expanded', 'true');
        mobileMenu.classList.remove('hidden');
        
        
        mobileMenuContent.offsetHeight;
        
        mobileMenuContent.classList.remove('translate-x-full');
        document.body.classList.add('overflow-hidden');
      }
      
      function closeMobileMenu() {
        mobileMenuButton.setAttribute('aria-expanded', 'false');
        mobileMenuContent.classList.add('translate-x-full');
        
        
        setTimeout(() => {
          mobileMenu.classList.add('hidden');
          document.body.classList.remove('overflow-hidden');
        }, 300);
      }
    }
  });
</script>
<main class="w-full">
<article class="mx-auto max-w-5xl px-4 sm:px-6 lg:px-8">
<header class="py-12 sm:py-16">
<div class="mx-auto max-w-4xl">
<div class="mb-8">
<nav class="text-sm hidden sm:block">
<ol class="flex items-center space-x-2 text-gray-400 dark:text-gray-500">
<li class="flex items-center">
<a class="hover:text-gray-900 dark:hover:text-gray-300 transition-colors flex items-center" href="/ja/">
<img alt="Home" class="h-4 w-4 opacity-60" src="/images/home-icon.png"/>
</a>
</li>
<li><span class="mx-2 text-gray-300 dark:text-gray-600">/</span></li>
<li>
<a class="hover:text-gray-900 dark:hover:text-gray-300 transition-colors" href="/ja/glossary/">
                用語集
              </a>
</li>
<li><span class="mx-2 text-gray-300 dark:text-gray-600">/</span></li>
<li class="text-gray-600 dark:text-gray-400 truncate max-w-xs">音声認識</li>
</ol>
</nav>
</div>
<div class="mb-6">
<span class="inline-flex items-center text-xs font-medium tracking-wider uppercase text-gray-500 dark:text-gray-400 border-b border-gray-300 dark:border-gray-600 pb-1">
<svg class="mr-2 h-3.5 w-3.5" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M7 7h.01M7 3h5c.512 0 1.024.195 1.414.586l7 7a2 2 0 010 2.828l-7 7a2 2 0 01-2.828 0l-7-7A1.994 1.994 0 013 12V7a4 4 0 014-4z" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
            Technology
          </span>
</div>
<h1 class="text-2xl font-bold tracking-tight text-gray-900 dark:text-white sm:text-3xl md:text-4xl leading-tight mb-2">
        音声認識
      </h1>
<p class="text-sm sm:text-base text-gray-500 dark:text-gray-400 mb-6">
          Speech Recognition
        </p>
<p class="text-base sm:text-lg leading-relaxed text-gray-600 dark:text-gray-300 font-light max-w-3xl">
          音声認識(ASR)は、話し言葉をテキストに変換する技術です。このAI技術の仕組み、アルゴリズム、機能、応用分野、そして今後のトレンドについて解説します。
        </p>
<div class="mt-6 mb-4 border-t border-gray-100 dark:border-gray-800"></div>
<div class="flex flex-col sm:flex-row sm:items-center sm:justify-between gap-4">
<div class="flex flex-wrap gap-2">
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                音声認識
              </span>
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                ASR
              </span>
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                ディープラーニング
              </span>
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                AI
              </span>
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                文字起こし
              </span>
</div>
<div class="text-sm text-gray-500 dark:text-gray-400 flex flex-col items-end gap-y-1 text-right">
<span class="inline-flex items-center justify-end">
<svg class="mr-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M8 7V5a3 3 0 013-3h2a3 3 0 013 3v2m4 0h-16a2 2 0 00-2 2v9a2 2 0 002 2h16a2 2 0 002-2V9a2 2 0 00-2-2z" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
      
        作成日: 2025年12月19日
      
    </span>
</div>
</div>
</div>
</header>
<div class="prose prose-base sm:prose-lg dark:prose-invert mx-auto max-w-4xl py-6 sm:py-8">
<h2 id="音声認識とは何か">音声認識とは何か?</h2>
<p>音声認識は、自動音声認識(ASR)または音声テキスト変換とも呼ばれ、話し言葉を書き言葉に変換する技術です。現代の音声認識により、コンピュータ、ソフトウェアアプリケーション、スマートデバイスは、音声信号を機械可読テキストに変換することで、人間の音声を処理、解釈し、それに基づいて行動できるようになります。この技術は<a data-lb="1" href="/ja/glossary/artificial-intelligence/" title="自律システムの包括的ガイド:自己動作技術、AI駆動の自動化、ロボティクス、インテリジェントな意思決定システムについて解説します。">人工知能</a>と自動化の基盤コンポーネントとして機能し、仮想アシスタントや音声入力ソフトウェアから、アクセシビリティツールやカスタマーサービスの自動化まで、幅広いアプリケーションを支えています。</p>
<p>音声認識は声紋認識とは異なります。音声認識は話者に関係なく話された言葉を文字起こしするのに対し、声紋認識は個々の話者を固有の声の特徴によって識別し、主に認証や話者識別の目的で使用されます。</p>
<p>現代の音声認識の有効性は、深層学習の進歩、大規模なトレーニングデータセット、強力なコンピューティングインフラストラクチャ、洗練された言語モデルから生まれています。これらのシステムは現在、多くの状況で人間に近い精度を達成し、多様なアプリケーションや業界にわたって自然な音声インタラクションを可能にしています。</p>
<h2 id="コア技術とコンポーネント">コア技術とコンポーネント</h2>
<h3 id="音声認識の必須コンポーネント">音声認識の必須コンポーネント</h3>
<p><strong>音声キャプチャと前処理</strong><br/>
マイクや録音デバイスを通じた高品質な音声キャプチャが、正確な認識の基盤を形成します。前処理には、適応フィルタリングによるノイズ低減、一貫した音量レベルのための音声正規化、無音除去とセグメンテーション、電話アプリケーション向けのエコーキャンセレーション、モデル要件に合わせたサンプルレート変換が含まれます。</p>
<p><strong>特徴抽出</strong><br/>
生の音声は、音声特性を強調しながら無関係な情報を最小化する特徴表現に変換されます。一般的な技術には、スペクトル特性を捉えるメル周波数ケプストラム係数(MFCC)、音周波数の視覚的表現を提供するスペクトログラム、周波数帯域のエネルギー分布を表すフィルタバンクエネルギー、イントネーションとリズムを捉えるピッチと韻律特徴が含まれます。</p>
<p><strong>音響モデリング</strong><br/>
音響モデルは、音声特徴を音素、文字、単語などの言語単位にマッピングします。従来のシステムは、ガウス混合モデル(GMM)を用いた隠れマルコフモデル(HMM)を使用していました。現代のシステムは、特徴抽出のための畳み込みニューラルネットワーク(CNN)、系列モデリングのための再帰型ニューラルネットワーク(RNN)、長距離依存関係を処理する長短期記憶(LSTM)ネットワーク、並列処理とアテンションメカニズムを提供するトランスフォーマーアーキテクチャを含む深層ニューラルネットワークを採用しています。</p>
<p><strong>言語モデリング</strong><br/>
言語モデルは、可能性の高い単語列を予測し、曖昧さを解決するための文脈理解を提供します。N-gramモデルは単語列の統計的確率を使用し、ニューラル言語モデルは文脈理解のために深層学習を採用し、<a data-lb="1" href="/ja/glossary/large-language-models/" title="大規模言語モデル(LLM)は、深層学習とトランスフォーマーネットワークを活用した高度なAIシステムで、テキスト生成、翻訳などを実現します。その中核概念、応用分野、課題について理解を深めましょう。">大規模言語モデル(LLM)</a>は洗練された文脈推論とエラー訂正を提供します。</p>
<p><strong>デコーダと出力生成</strong><br/>
デコーダは、音響モデルと言語モデルのスコアを組み合わせて、最も可能性の高いテキスト列を決定します。ビームサーチは複数の仮説を同時に探索し、信頼度スコアは結果の信頼性を示し、読みやすさのために句読点と大文字化が追加され、話者ダイアライゼーションは複数人の会話で異なる話者を識別します。</p>
<h2 id="音声認識の仕組み">音声認識の仕組み</h2>
<h3 id="処理パイプライン">処理パイプライン</h3>
<p><strong>1. 音声キャプチャ</strong><br/>
音声はマイクを通じてアナログ音声信号としてキャプチャされます。マイク感度、サンプリングレート(音声では通常16kHz以上)、ビット深度、環境ノイズなどの品質要因が、下流の精度に大きく影響します。</p>
<p><strong>2. 信号処理</strong><br/>
アナログ信号はデジタル化され、音声品質を向上させるために前処理されます。デジタルフィルタはノイズを除去し、音声活動検出は音声セグメントを識別し、正規化は音量レベルを均等化し、フレーミングは音声を短い分析ウィンドウ(通常20〜40ms)に分割します。</p>
<p><strong>3. 特徴抽出</strong><br/>
処理された音声は、音響特性を表す特徴ベクトルに変換されます。この次元削減は、ノイズや無関係な変動を破棄しながら、関連情報を抽出します。</p>
<p><strong>4. 音響分析</strong><br/>
深層学習モデルは特徴ベクトルを分析して、音素、音節、または文字を識別します。現代のエンドツーエンドモデルは、明示的な音素モデリングなしに、音声から直接このマッピングを学習します。</p>
<p><strong>5. 言語処理</strong><br/>
言語モデルは、文脈、単語関係、文法規則、ドメイン固有の語彙を考慮することで、言語知識を適用して精度を向上させます。この段階では、似た音の複数の単語がある場合の曖昧さを解決します。</p>
<p><strong>6. テキスト生成</strong><br/>
システムは、句読点、大文字化、段落区切り、タイムスタンプを含む適切なフォーマットで最終的な文字起こしを生成します。高度なシステムは、話者ラベルを追加し、言語切り替えを検出し、各セグメントの信頼度スコアを提供します。</p>
<h3 id="動作モード">動作モード</h3>
<p><strong>リアルタイム処理</strong><br/>
音声が発生すると同時に即座に文字起こしを行い、ライブキャプション、音声コマンド、会話型AIに不可欠です。音声を受信しながら部分的な結果を生成するストリーミングアルゴリズムによる低遅延処理が必要です。</p>
<p><strong><a data-lb="1" href="/ja/glossary/batch-processing/" title="バッチ処理は、大量のデータを収集し、設定された期間ごとにグループ単位で処理するデータアプローチです。高スループットのAI、分析、ビジネスオペレーションに最適です。">バッチ処理</a></strong><br/>
事前録音された音声ファイルの文字起こしで、ポストプロダクション、会議の文字起こし、大規模コンテンツ処理に適しています。より高い精度のために、より計算集約的なモデルの使用が可能です。</p>
<p><strong>ストリーミングモード</strong><br/>
音声を受信しながら段階的な結果を提供する中間的なアプローチで、遅延と精度のバランスを取ります。部分的な結果がユーザーインタラクションを導く仮想アシスタントで一般的です。</p>
<h2 id="アルゴリズムとモデルアーキテクチャ">アルゴリズムとモデルアーキテクチャ</h2>
<h3 id="asrモデルの進化">ASRモデルの進化</h3>
<p><strong>従来のアプローチ(1970年代〜2000年代)</strong><br/>
初期のシステムは、音響モデリングにガウス混合モデルを用いた隠れマルコフモデル(HMM-GMM)、単語列予測のためのN-gram言語モデル、別個の発音辞書、広範な特徴エンジニアリングを使用していました。これらのシステムは、慎重な調整とコンポーネントの個別最適化が必要でした。</p>
<p><strong>深層学習時代(2010年代)</strong><br/>
深層ニューラルネットワークがハイブリッドHMM-DNNシステムでGMMを置き換え、大幅な精度向上をもたらしました。LSTMユニットを持つ再帰型ニューラルネットワークが時間的依存関係を捉えました。アテンションメカニズムにより、関連する入力セグメントへの焦点が可能になりました。これらのシステムは依然として明示的な音素モデリングが必要でした。</p>
<p><strong>現代のエンドツーエンドアーキテクチャ(2015年〜現在)</strong><br/>
現代のシステムは、音声からテキストへの直接マッピングを学習します:</p>
<ul>
<li>
<p><strong>コネクショニスト時間分類(CTC):</strong> 音声とテキスト間の明示的なアライメントなしでトレーニングを可能にし、可変長シーケンスを処理し、ストリーミング認識をサポートします。</p>
</li>
<li>
<p><strong>アテンション付きシーケンス・トゥ・シーケンス:</strong> アテンションメカニズムを持つエンコーダ・デコーダアーキテクチャが、文脈を考慮した文字起こしを提供し、長距離依存関係を処理し、複数言語をサポートします。</p>
</li>
<li>
<p><strong>トランスフォーマーベースモデル:</strong> セルフアテンションメカニズムがシーケンス全体を並列処理し、最先端の精度を達成します。Conformerのようなモデルは、最適な特徴抽出のために畳み込みとセルフアテンションを組み合わせます。</p>
</li>
<li>
<p><strong>ニューラルトランスデューサ(RNN-T):</strong> ストリーミングASR専用に設計され、高精度を維持しながら最小限の遅延で連続的な文字起こしを可能にします。</p>
</li>
</ul>
<h3 id="サポート技術">サポート技術</h3>
<p><strong>ニューラル言語モデル</strong><br/>
<a data-lb="1" href="/ja/glossary/large-language-models/" title="大規模言語モデル(LLM) の用語集ページ">大規模言語モデル</a>は強力な文脈理解を提供し、曖昧さの処理、ドメイン適応、エラー訂正の改善を通じて精度を劇的に向上させます。現代のシステムは、強化された言語処理のためにGPTスタイルのモデルを統合しています。</p>
<p><strong>話者適応</strong><br/>
システムは、ユーザー訂正からのオンライン学習、話者固有の音響モデル、パーソナライズされた語彙と言語パターンを通じて、個々の話者に適応します。</p>
<p><strong>マルチタスク学習</strong><br/>
音声認識、話者識別、言語識別、感情認識などの関連タスクで同時にトレーニングされたモデルは、多くの場合、より良い全体的なパフォーマンスを達成します。</p>
<h2 id="主要機能と能力">主要機能と能力</h2>
<h3 id="コア機能">コア機能</h3>
<p><strong>多言語サポート</strong><br/>
100以上の言語と方言の認識、自動言語検出、多言語話者のコードスイッチング処理、地域固有のアクセント適応。</p>
<p><strong>話者ダイアライゼーション</strong><br/>
複数人の会話における異なる話者の自動識別とラベル付けにより、会議、インタビュー、コールセンター録音での明確な帰属が可能になります。</p>
<p><strong>カスタム語彙</strong><br/>
技術用語、固有名詞、会社名や製品名、業界固有の略語を含むドメイン固有の用語のサポート。ユーザーは、特殊な文脈での精度を向上させるカスタム単語リストを定義できます。</p>
<p><strong>ノイズ耐性</strong><br/>
高度なノイズキャンセレーションは、背景の会話、交通や環境音、音楽や音声干渉、変化する音響条件を処理します。複数のマイクアレイにより、焦点を絞った音声キャプチャのためのビームフォーミングが可能になります。</p>
<p><strong>句読点とフォーマット</strong><br/>
ピリオド、カンマ、疑問符の自動挿入、固有名詞の大文字化、段落区切り、数字、日付、時刻のフォーマットにより、読みやすさが向上します。</p>
<p><strong>リアルタイム処理</strong><br/>
低遅延の文字起こしにより、100〜200msという低遅延でインタラクティブなアプリケーションが可能になり、即座のフィードバックのためのストリーミング部分結果、より多くの文脈が利用可能になるにつれての段階的な更新が実現します。</p>
<h3 id="高度な能力">高度な能力</h3>
<p><strong>音声コマンドと制御</strong><br/>
デバイス制御、アプリケーションコマンド、ナビゲーションと情報検索、複雑な複数ステップの指示のための自然言語理解。</p>
<p><strong>不適切な言葉のフィルタリング</strong><br/>
攻撃的な言語の自動検出とマスキング、設定可能な感度レベル、言語固有のフィルタ。</p>
<p><strong>信頼度スコアリング</strong><br/>
単語レベルおよびセグメントレベルの信頼度指標が、不確実な文字起こしを識別し、品質管理プロセスを導き、検証または訂正ワークフローをトリガーします。</p>
<p><strong>音声分析</strong><br/>
テキストを超えたメタデータの抽出には、話者の感情とセンチメント、発話速度と休止パターン、音質メトリクス、音響イベント検出(拍手、笑い、背景ノイズ)が含まれます。</p>
<p><strong>プライバシーとセキュリティ</strong><br/>
機密アプリケーション向けのデバイス上処理、暗号化された音声送信と保存、個人識別情報の匿名化、データ保護規制(GDPR、HIPAA、CCPA)への準拠。</p>
<h2 id="アプリケーションとユースケース">アプリケーションとユースケース</h2>
<h3 id="エンタープライズとビジネス">エンタープライズとビジネス</h3>
<p><strong>カスタマーサービス</strong><br/>
品質保証のためのコールセンター文字起こし、提案された応答を提供するリアルタイムエージェントアシスト、自動通話ルーティングとIVRシステム、顧客会話からのセンチメント分析、規制業界のコンプライアンス監視。</p>
<p><strong>会議とコラボレーション</strong><br/>
自動会議文字起こしと議事録、アクションアイテムの抽出と割り当て、検索可能な会議アーカイブ、タイムゾーンと言語を越えたリアルタイムコラボレーション、聴覚障害のある参加者のためのアクセシビリティ。</p>
<p><strong>医療文書化</strong><br/>
医療語彙を用いた臨床文書化、患者診察中のリアルタイムEHRデータ入力、処方と処置の口述、病理学と放射線学のレポート生成、遠隔医療の文字起こし。</p>
<h3 id="消費者向けアプリケーション">消費者向けアプリケーション</h3>
<p><strong>仮想アシスタント</strong><br/>
Siri、Alexa、Google Assistant、Cortanaは、音声コマンド、スマートホーム制御、情報検索、予定のスケジューリング、会話型AIインタラクションに音声認識を使用しています。</p>
<p><strong>音声入力と生産性</strong><br/>
ワードプロセッサやメッセージングアプリでの音声入力、メール作成、メモ取りと日記、モバイルデバイスでの文書作成、マルチタスク中のハンズフリー操作。</p>
<p><strong>メディアとエンターテインメント</strong><br/>
ビデオの自動字幕とキャプション生成、ポッドキャストの文字起こしとインデックス作成、アクセシビリティのための音声解説、カラオケと音楽アプリケーション、音声制御ゲーム。</p>
<h3 id="専門分野">専門分野</h3>
<p><strong>法律と司法</strong><br/>
法廷の文字起こしと訴訟記録、証言録取の録音と文字起こし、検索可能なアーカイブを通じた法律調査、証拠文書化、契約レビューと分析。</p>
<p><strong>教育と研究</strong><br/>
学生のための講義文字起こし、発音フィードバック付き言語学習、研究インタビューの文字起こし、自動評価と採点、障害のある学生のためのアクセシビリティサポート。</p>
<p><strong>交通と自動車</strong><br/>
ハンズフリーナビゲーションと目的地入力、車内エンターテインメント制御、安全重視の音声コマンド、ドライバーアシスタンス情報、車両からドライバーへの通信。</p>
<h3 id="アクセシビリティ">アクセシビリティ</h3>
<p><strong>支援技術</strong><br/>
聴覚障害者や難聴者のためのリアルタイムキャプション、運動障害のあるユーザーのための音声制御、スクリーンリーダー統合、言語障害のためのコミュニケーション支援、公共スペースでの環境アクセシビリティ。</p>
<h2 id="メリットと利点">メリットと利点</h2>
<h3 id="効率性と生産性">効率性と生産性</h3>
<p><strong>速度</strong><br/>
音声入力はタイピングよりも大幅に速く(話すのは毎分150語以上、タイピングは40〜50語)、迅速な文書化、素早いメモ取り、コンテンツ作成の加速を可能にします。</p>
<p><strong>ハンズフリー操作</strong><br/>
マルチタスクを可能にし、モバイル生産性、運転中や移動中の操作、反復性ストレス障害の軽減、身体的制限のあるユーザーのためのアクセシビリティを実現します。</p>
<p><strong>ワークフロー統合</strong><br/>
既存のアプリケーションとワークフローへのシームレスな統合、自動化された文書化プロセス、手動データ入力の削減、合理化されたビジネスプロセス。</p>
<h3 id="アクセシビリティとインクルージョン">アクセシビリティとインクルージョン</h3>
<p><strong>ユニバーサルアクセス</strong><br/>
障害のある個人のための技術使用を可能にし、多言語コミュニケーションをサポートし、年齢に配慮したインターフェースを提供し、音声インタラクションを通じて識字障壁を軽減します。</p>
<p><strong>費用対効果の高い配慮</strong><br/>
手動文字起こしサービスの必要性を削減し、独立した技術使用を可能にし、手頃な価格の支援技術ソリューションを提供し、包括的な職場環境をサポートします。</p>
<h3 id="ビジネス価値">ビジネス価値</h3>
<p><strong>コスト削減</strong><br/>
文字起こしを自動化して人件費を削減し、文書化時間を短縮し、トレーニング要件を低減し、リソース配分を改善します。</p>
<p><strong>データインサイト</strong><br/>
大規模な音声コミュニケーションの分析を可能にし、会話から実用的なインテリジェンスを抽出し、トレンドとパターンを識別し、データ駆動型の意思決定をサポートします。</p>
<p><strong>顧客体験</strong><br/>
便利な音声インターフェースを提供し、24時間365日のセルフサービスを可能にし、インタラクションの摩擦を軽減し、パーソナライズされた体験をサポートします。</p>
<h2 id="課題と制限">課題と制限</h2>
<h3 id="技術的課題">技術的課題</h3>
<p><strong>アクセントと方言の変動</strong><br/>
パフォーマンスは、アクセント、方言、地域の発話パターンによって大きく異なります。非ネイティブスピーカーは精度が低くなる可能性があります。トレーニングデータで過小評価されているアクセントは、偏ったパフォーマンスにつながります。</p>
<p><strong>音響条件</strong><br/>
背景ノイズ、マイク品質の低さ、残響とエコー、重複する話者、低品質の音声は、精度を大幅に低下させます。</p>
<p><strong>ドメイン適応</strong><br/>
汎用モデルは、専門語彙、業界用語、固有名詞、稀な単語、言語間のコードスイッチングに苦労する可能性があります。</p>
<p><strong>リアルタイム制約</strong><br/>
遅延要件がモデルの複雑さを制限し、ストリーミングは独特の課題をもたらし、ネットワーク遅延がクラウドベースのシステムに影響を与え、計算リソースの制約がデバイス上の能力を制限します。</p>
<h3 id="運用上の考慮事項">運用上の考慮事項</h3>
<p><strong>プライバシーの懸念</strong><br/>
音声データには個人識別情報が含まれ、録音は機密会話をキャプチャする可能性があり、クラウド処理はデータ主権の問題を提起し、規制コンプライアンス(GDPR、HIPAA)は複雑です。</p>
<p><strong>精度要件</strong><br/>
ミッションクリティカルなアプリケーション(医療、法律)は極めて高い精度を必要とし、エラーは深刻な結果をもたらす可能性があり、人間による検証はコストを追加し、100%の精度は達成不可能なままです。</p>
<p><strong>リソース要件</strong><br/>
高品質モデルは相当な計算リソースを必要とし、リアルタイム処理は低遅延インフラストラクチャを要求し、デバイス上の展開はメモリと電力の制約に直面し、継続的なモデル更新にはインフラストラクチャ投資が必要です。</p>
<p><strong><a data-lb="1" href="/ja/glossary/bias/" title="バイアス の用語集ページ">バイアス</a>と公平性</strong><br/>
トレーニングデータの不均衡はパフォーマンスの格差につながり、過小評価されている人口統計は精度が低くなり、アクセントバイアスは不平等を永続させ、人口統計的公平性には継続的な注意が必要です。</p>
<h2 id="進化と将来のトレンド">進化と将来のトレンド</h2>
<h3 id="歴史的発展">歴史的発展</h3>
<p><strong>1950年代〜1960年代:初期の基礎</strong><br/>
ベル研究所のAUDREY(1952年)は数字を認識し、IBM Shoebox(1962年)は16語を認識し、研究は限定語彙システムに焦点を当てていました。</p>
<p><strong>1970年代〜1980年代:統計的手法</strong><br/>
隠れマルコフモデルが標準となり、より大きな語彙(1,000語以上)が登場し、話者非依存システムが開発され、最初の商用アプリケーションが開始されました。</p>
<p><strong>1990年代〜2000年代:商業的拡大</strong><br/>
Dragon NaturallySpeakingが消費者に音声入力をもたらし、コールセンターの自動化が登場し、連続音声認識が改善され、精度が多くのアプリケーションで実用的な閾値に達しました。</p>
<p><strong>2010年代:深層学習革命</strong><br/>
深層ニューラルネットワークが精度を劇的に向上させ、モバイル仮想アシスタント(Siri、Google Now)が開始され、エンドツーエンドモデルがトレーニングを簡素化し、大規模展開が一般的になりました。</p>
<p><strong>2020年代〜現在:AI統合</strong><br/>
大規模言語モデルが理解を強化し、マルチモーダルAIが音声を視覚とテキストと組み合わせ、デバイス上処理がプライバシーを改善し、理想的な条件下で人間に近い精度を達成しました。</p>
<h3 id="新興トレンド">新興トレンド</h3>
<p><strong><a data-lb="1" href="/ja/glossary/multimodal/" title="マルチモーダルAIは、テキスト、画像、音声などの多様なデータタイプを処理・統合し、より豊かな理解を実現します。そのアーキテクチャ、メリット、課題、応用例について解説します。">マルチモーダルAI</a></strong><br/>
音声と視覚、テキスト、その他のモダリティの統合により、より豊かな文脈理解、ジェスチャーと読唇術の強化、視覚シーン理解、全体的なインタラクション体験が可能になります。</p>
<p><strong><a data-lb="1" href="/ja/glossary/personalization/" title="AIチャットボットと自動化におけるパーソナライゼーションは、高度なアルゴリズムを使用して、個々のユーザーの嗜好や行動に合わせてサービス、コンテンツ、インタラクションをカスタマイズします。">パーソナライゼーション</a>と適応</strong><br/>
ユーザーインタラクションからの継続的学習、話者固有のモデルファインチューニング、文脈を考慮した処理、パーソナライズされた語彙と言語パターンが、個々のユーザー体験を向上させます。</p>
<p><strong>エッジコンピューティング</strong><br/>
プライバシーと遅延のためのデバイス上処理、専用ニューラル処理ハードウェア、データ共有なしでモデル改善のための連合学習、リモートまたは機密アプリケーション向けのオフライン機能。</p>
<p><strong>感情的知性</strong><br/>
音声からの感情とセンチメントの検出、音声分析によるストレスと健康モニタリング、会話型AIでの共感的応答生成、メンタルヘルスにおける治療的応用。</p>
<p><strong><a data-lb="1" href="/ja/glossary/real-time-translation/" title="リアルタイム翻訳 の用語集ページ">リアルタイム翻訳</a></strong><br/>
言語間のライブ音声間翻訳、方言処理と正規化、文化的文脈適応、シームレスな多言語コミュニケーション。</p>
<p><strong>専門アプリケーション</strong><br/>
医療グレードの臨床文書化、法的認証された法廷文字起こし、音声による産業品質管理、生体認証とセキュリティ、音声制御ロボティクスと自動化。</p>
<h3 id="研究フロンティア">研究フロンティア</h3>
<p><strong>少数ショットとゼロショット学習</strong><br/>
転移学習とメタ学習アプローチを通じて、最小限のトレーニングデータで新しい言語、アクセント、またはドメインへの迅速な適応。</p>
<p><strong>自己<a data-lb="1" href="/ja/glossary/supervised-learning/" title="教師あり学習は、アルゴリズムがラベル付きデータから学習し、入力を望ましい出力にマッピングすることで、新しい未知のデータに対して正確な予測を行う、機械学習の基礎的なパラダイムです。">教師あり学習</a></strong><br/>
事前トレーニングのために膨大な量のラベルなし音声データを活用し、高価なラベル付きデータセットへの依存を減らします。</p>
<p><strong>公平性とバイアス軽減</strong><br/>
人口統計的バイアスを識別して修正し、集団全体で公平なパフォーマンスを確保するための体系的なアプローチ。</p>
<p><strong>説明可能なAI</strong><br/>
モデルの決定を理解し、エラーソースを識別し、ユーザーの信頼を構築し、体系的な改善を可能にします。</p>
<h2 id="実装の考慮事項">実装の考慮事項</h2>
<h3 id="ソリューションの選択">ソリューションの選択</h3>
<p><strong>要件評価</strong><br/>
精度要件と許容可能なエラー率を定義し、遅延制約を決定し、言語とアクセント要件を識別し、プライバシーとコンプライアンスのニーズを評価し、統合の複雑さを評価します。</p>
<p><strong>展開オプション</strong><br/>
クラウドベースのAPIは、簡単な統合、高精度、自動更新を提供しますが、データプライバシーの懸念を提起します。デバイス上ソリューションは、プライバシー、オフライン操作、低遅延を提供しますが、モデルの複雑さが制限されます。ハイブリッドアプローチは両方の利点のバランスを取ります。</p>
<p><strong>コスト要因</strong><br/>
API価格モデル(分単位、階層制、または定額制)、オンプレミス展開のインフラストラクチャコスト、開発と統合の労力、継続的なメンテナンスと更新、トレーニングとサポート要件。</p>
<h3 id="ベストプラクティス">ベストプラクティス</h3>
<p><strong>音質</strong><br/>
高品質マイクを使用し、背景ノイズを最小限に抑え、最適な録音距離(通常6〜12インチ)を維持し、ノイズキャンセリング技術を使用し、本番展開前に音質をテストします。</p>
<p><strong>モデル選択</strong><br/>
ユースケースに適したモデル(汎用対専門)を選択し、代表的なデータで精度を評価し、遅延要件を考慮し、計算リソースを評価し、モデル更新を計画します。</p>
<p><strong>ユーザー体験</strong><br/>
認識ステータスに関する明確なフィードバックを提供し、信頼度指標を表示し、エラーの簡単な修正を可能にし、代替入力方法を提供し、認識失敗からの回復を設計します。</p>
<p><strong>テストと検証</strong><br/>
多様な話者とアクセントでテストし、現実的なノイズ条件下で評価し、ドメイン固有のコンテンツで精度を測定し、ユーザー受け入れテストを実施し、パフォーマンスベンチマークを確立します。</p>
<p><strong>プライバシーとセキュリティ</strong><br/>
転送中および保存中のデータ暗号化を実装し、音声データの保持を最小限に抑え、データ使用に関する透明性を提供し、関連規制に準拠し、機密アプリケーション向けにデバイス上処理を提供します。</p>
<h2 id="よくある質問">よくある質問</h2>
<p><strong>音声認識の精度はどのくらいですか?</strong><br/>
現代のシステムは、明瞭な音声と標準的なアクセントを持つ理想的な条件下で95%以上の精度を達成します。実世界の精度は、音質、話者のアクセント、背景ノイズ、ドメインの専門化に基づいて変動します。</p>
<p><strong>音声認識はオフラインで動作しますか?</strong><br/>
多くの現代のソリューションは、オフライン使用のためのデバイス上処理を提供していますが、クラウドベースのシステムと比較して精度にいくらかのトレードオフがあります。オフライン機能は、ハードウェアの進歩とともに急速に改善されています。</p>
<p><strong>複数の話者を処理できますか?</strong><br/>
はい、話者ダイアライゼーション技術は、複数人の会話で異なる話者を自動的に識別してラベル付けし、会議やインタビューでの明確な帰属を可能にします。</p>
<p><strong>どの言語がサポートされていますか?</strong><br/>
主要なASRプラットフォームは100以上の言語と方言をサポートしていますが、精度はトレーニングデータの可用性と言語的複雑さに基づいて言語によって異なります。</p>
<p><strong>声紋認識とどう違いますか?</strong><br/>
音声認識は何が言われたかを文字起こしします。声紋認識は、声の特徴に基づいて誰が話しているかを識別します。それらは異なる目的を果たし、しばしば互いに補完します。</p>
<p><strong>私の音声データは安全ですか?</strong><br/>
データの安全性は、プロバイダーと展開モデルに依存します。クラウドベースのシステムは音声をサーバーに送信しますが、デバイス上システムはローカルで処理します。プライバシーポリシーを確認し、セキュリティ要件を満たすソリューションを選択してください。</p>
<h2 id="参考文献">参考文献</h2>
<ul>
<li><a href="https://www.twilio.com/en-us/blog/insights/ai/what-is-speech-recognition" rel="nofollow noopener noreferrer" target="_blank">Twilio: What is Speech Recognition?</a></li>
<li><a href="https://www.techtarget.com/searchcustomerexperience/definition/speech-recognition" rel="nofollow noopener noreferrer" target="_blank">TechTarget: What is Speech Recognition?</a></li>
<li><a href="https://en.wikipedia.org/wiki/Speech_recognition" rel="nofollow noopener noreferrer" target="_blank">Wikipedia: Speech Recognition</a></li>
<li><a href="https://www.ibm.com/think/topics/speech-recognition" rel="nofollow noopener noreferrer" target="_blank">IBM: Speech Recognition Overview</a></li>
<li><a href="https://www.shaip.com/blog/voice-recognition-overview-and-applications/" rel="nofollow noopener noreferrer" target="_blank">Shaip: Voice Recognition Overview and Applications</a></li>
<li><a href="https://opencv.org/blog/applications-of-speech-recognition/" rel="nofollow noopener noreferrer" target="_blank">OpenCV: Applications of Speech Recognition</a></li>
<li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2022/12/Advancing-end-to-end-automatic-speech-recognition-and-beyond_1hr.pdf" rel="nofollow noopener noreferrer" target="_blank">Microsoft Research: Advancing End-to-End ASR</a></li>
<li><a href="https://www.nature.com/articles/s41598-022-12260-y" rel="nofollow noopener noreferrer" target="_blank">Nature: Transformer-based End-to-End Speech Recognition</a></li>
<li><a href="https://www.sciencedirect.com/science/article/pii/S2666307424000573" rel="nofollow noopener noreferrer" target="_blank">ScienceDirect: Survey of Deep Learning in ASR</a></li>
<li><a href="https://www.ibm.com/think/insights/artificial-intelligence-advantages-disadvantages" rel="nofollow noopener noreferrer" target="_blank">IBM: AI Advantages &amp; Disadvantages</a></li>
<li><a href="https://www.ibm.com/cloud/watson-speech-to-text" rel="nofollow noopener noreferrer" target="_blank">IBM Watson Speech to Text</a></li>
<li><a href="https://azure.microsoft.com/en-us/products/ai-services/speech-to-text" rel="nofollow noopener noreferrer" target="_blank">Microsoft Azure Speech Services</a></li>
<li><a href="https://cloud.google.com/speech-to-text" rel="nofollow noopener noreferrer" target="_blank">Google Cloud Speech-to-Text</a></li>
<li><a href="https://aws.amazon.com/transcribe/" rel="nofollow noopener noreferrer" target="_blank">Amazon Transcribe</a></li>
</ul>
</div>
<div class="mt-16 sm:mt-20 border-t border-gray-200 dark:border-gray-800 pt-12 sm:pt-16">
<h2 class="text-2xl sm:text-3xl font-bold tracking-tight text-gray-900 dark:text-white mb-8 sm:mb-10">
        
          関連用語
        
      </h2>
<div class="grid gap-6 sm:gap-8 grid-cols-1 sm:grid-cols-2 lg:grid-cols-3">
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/gpu-acceleration/">
                    GPUアクセラレーション
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
<a data-lb="1" href="/ja/glossary/gpu-acceleration/" title="GPUアクセラレーションは、グラフィックス処理ユニット(GPU)を活用して大規模な並列処理を実現し、AI、ディープラーニング、データサイエンス、HPCなどの計算集約型ワークロードを大幅に高速化します。">GPUアクセラレーション</a>は、グラフィックス処理ユニット(GPU)を活用して大規模な並列処理を実現し、AI、ディープラーニング、データサイエンス、HPCなどの計算集約型ワークロードを大幅に高速化します。...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/gpu-acceleration/">
                    詳細を見る
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/voicebot/">
                    ボイスボット
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
                    ボイスボットの包括的なガイドをご紹介します。ASR、NLP、TTSなどのコア技術、動作原理、主要機能、種類、そしてカスタマーサービスと自動化におけるビジネス上のメリットについて解説します。...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/voicebot/">
                    詳細を見る
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/computational-resources/">
                    計算リソース
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
                    CPU、GPU、メモリ、ストレージ、ネットワーキングを含む計算リソースについて解説します。AI、データサイエンス、クラウドコンピューティングにおける役割と最適化のヒントを理解できます。...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/computational-resources/">
                    詳細を見る
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/continuous-learning/">
                    AIにおける継続学習
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
                    AIにおける継続学習を探求します。システムが忘却することなく段階的に適応し知識を獲得できるようにする技術です。そのプロセス、破滅的忘却などの課題、実世界での応用について理解を深めます。...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/continuous-learning/">
                    詳細を見る
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/n-gram/">
                    N-gram
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
                    N-gramとは、テキストや音声から抽出されるn個の連続したアイテム(単語、文字、記号)のシーケンスであり、自然言語処理における言語モデリングやテキスト分析の基礎となる手法です。...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/n-gram/">
                    詳細を見る
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/speech-to-text-node/">
                    Speech-to-Textノード
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
                    Speech-to-Textノードは、自動音声認識(ASR)を使用して音声言語を機械可読テキストに変換する、自動化プラットフォームやAIワークフローにおけるモジュール型コンポーネントです。...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/speech-to-text-node/">
                    詳細を見る
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
</div>
</div>
<div class="mt-12 sm:mt-16 py-8 border-t border-gray-200 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100 transition-colors" href="/ja/glossary/">
<svg class="mr-2 h-5 w-5" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M10 19l-7-7m0 0l7-7m-7 7h18" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
      
        用語集に戻る
      
    </a>
</div>
</article>
</main>
<footer style="background-color: #000000;">
<div id="cta-curves-container" style="
    position: relative;
    background: #000000;
    padding: 4rem 2rem;
    overflow: hidden;
  ">
<svg id="cta-curves-svg" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 1; opacity: 0.7;" xmlns="http://www.w3.org/2000/svg">
<defs>
<lineargradient id="curveGrad1" x1="0%" x2="100%" y1="0%" y2="0%">
<stop offset="0%" style="stop-color:rgba(99, 102, 241, 0); stop-opacity:0"></stop>
<stop offset="50%" style="stop-color:rgba(99, 102, 241, 0.9); stop-opacity:1"></stop>
<stop offset="100%" style="stop-color:rgba(99, 102, 241, 0); stop-opacity:0"></stop>
</lineargradient>
<lineargradient id="curveGrad2" x1="0%" x2="100%" y1="0%" y2="0%">
<stop offset="0%" style="stop-color:rgba(139, 92, 246, 0); stop-opacity:0"></stop>
<stop offset="50%" style="stop-color:rgba(139, 92, 246, 0.8); stop-opacity:1"></stop>
<stop offset="100%" style="stop-color:rgba(139, 92, 246, 0); stop-opacity:0"></stop>
</lineargradient>
<lineargradient id="curveGrad3" x1="0%" x2="100%" y1="0%" y2="0%">
<stop offset="0%" style="stop-color:rgba(59, 130, 246, 0); stop-opacity:0"></stop>
<stop offset="50%" style="stop-color:rgba(59, 130, 246, 0.7); stop-opacity:1"></stop>
<stop offset="100%" style="stop-color:rgba(59, 130, 246, 0); stop-opacity:0"></stop>
</lineargradient>
</defs>
<path class="curve" data-speed="0.8" fill="none" stroke="url(#curveGrad1)" stroke-width="2"></path>
<path class="curve" data-speed="1.2" fill="none" opacity="0.8" stroke="url(#curveGrad2)" stroke-width="2.5"></path>
<path class="curve" data-speed="0.6" fill="none" opacity="0.6" stroke="url(#curveGrad3)" stroke-width="1.5"></path>
<path class="curve" data-speed="1.5" fill="none" opacity="0.7" stroke="url(#curveGrad1)" stroke-width="2"></path>
<path class="curve" data-speed="0.9" fill="none" opacity="0.5" stroke="url(#curveGrad2)" stroke-width="3"></path>
<path class="curve" data-speed="1.3" fill="none" opacity="0.9" stroke="url(#curveGrad3)" stroke-width="1.8"></path>
<path class="curve" data-speed="0.7" fill="none" opacity="0.6" stroke="url(#curveGrad1)" stroke-width="2.2"></path>
<path class="curve" data-speed="1.1" fill="none" opacity="0.8" stroke="url(#curveGrad2)" stroke-width="2"></path>
<path class="curve" data-speed="1.4" fill="none" opacity="0.5" stroke="url(#curveGrad3)" stroke-width="2.5"></path>
<path class="curve" data-speed="0.85" fill="none" opacity="0.7" stroke="url(#curveGrad1)" stroke-width="1.5"></path>
<path class="curve" data-speed="1.0" fill="none" opacity="0.6" stroke="url(#curveGrad2)" stroke-width="2.8"></path>
<path class="curve" data-speed="1.25" fill="none" opacity="0.8" stroke="url(#curveGrad3)" stroke-width="2"></path>
<path class="curve" data-speed="0.95" fill="none" opacity="0.5" stroke="url(#curveGrad1)" stroke-width="2.3"></path>
<path class="curve" data-speed="1.35" fill="none" opacity="0.9" stroke="url(#curveGrad2)" stroke-width="1.7"></path>
<path class="curve" data-speed="0.75" fill="none" opacity="0.7" stroke="url(#curveGrad3)" stroke-width="2.5"></path>
</svg>
<div style="position: absolute; top: 0; left: 0; width: 50px; height: 50px; border-left: 2px solid rgba(99, 102, 241, 0.3); border-top: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div style="position: absolute; top: 0; right: 0; width: 50px; height: 50px; border-right: 2px solid rgba(99, 102, 241, 0.3); border-top: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div style="position: absolute; bottom: 0; left: 0; width: 50px; height: 50px; border-left: 2px solid rgba(99, 102, 241, 0.3); border-bottom: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div style="position: absolute; bottom: 0; right: 0; width: 50px; height: 50px; border-right: 2px solid rgba(99, 102, 241, 0.3); border-bottom: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div class="mx-auto max-w-2xl text-center" style="position: relative; z-index: 10;">
<h2 class="text-base/7 font-semibold text-indigo-400">今すぐ始めませんか？</h2>
<p class="mt-2 text-4xl font-semibold tracking-tight text-balance text-white sm:text-5xl">SmartWebで未来を創る</p>
<p class="mx-auto mt-6 max-w-xl text-lg/8 text-pretty text-gray-400">数千社の企業が私たちのソリューションでビジネスを変革しています。あなたも今日から始めましょう。</p>
<div class="mt-8 flex justify-center">
<a class="rounded-md bg-indigo-500 px-3.5 py-2.5 text-sm font-semibold text-white shadow-xs hover:bg-indigo-400 focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-indigo-400" href="/ja/blog/">無料で始める</a>
</div>
</div>
</div>
<script>
  (function() {
    'use strict';
    
    const container = document.getElementById('cta-curves-container');
    const svg = document.getElementById('cta-curves-svg');
    if (!container || !svg) return;
    
    const curves = svg.querySelectorAll('.curve');
    let mouseX = 0;
    let mouseY = 0;
    let targetMouseX = 0;
    let targetMouseY = 0;
    const mouseInfluence = 150;
    const mouseStrength = 80;
    
    const curveData = Array.from(curves).map((curve, i) => {
      const speed = parseFloat(curve.getAttribute('data-speed')) || 1;
      return {
        element: curve,
        baseY: 50 + (i * 25),
        offset: Math.random() * Math.PI * 2,
        speed: speed,
        amplitude: 30 + Math.random() * 40
      };
    });
    
    container.addEventListener('mousemove', (e) => {
      const rect = container.getBoundingClientRect();
      targetMouseX = e.clientX - rect.left;
      targetMouseY = e.clientY - rect.top;
    });
    
    container.addEventListener('mouseleave', () => {
      targetMouseX = -1000;
      targetMouseY = -1000;
    });
    
    let time = 0;
    
    function animate() {
      time += 0.01;
      
      mouseX += (targetMouseX - mouseX) * 0.15;
      mouseY += (targetMouseY - mouseY) * 0.15;
      
      const width = svg.clientWidth;
      const height = svg.clientHeight;
      
      curveData.forEach((data, index) => {
        const { baseY, offset, speed, amplitude } = data;
        const phase = time * speed + offset;
        
        let path = `M -200,${baseY}`;
        
        for (let x = -200; x <= width + 200; x += 50) {
          const normalY = baseY + Math.sin((x * 0.005) + phase) * amplitude;
          
          const dx = x - mouseX;
          const dy = normalY - mouseY;
          const distance = Math.sqrt(dx * dx + dy * dy);
          
          let y = normalY;
          if (distance < mouseInfluence) {
            const influence = (1 - distance / mouseInfluence);
            const pushY = (normalY - mouseY) * influence * mouseStrength * 0.01;
            y = normalY + pushY;
          }
          
          const nextX = x + 50;
          const controlX = x + 25;
          const controlY = y;
          path += ` Q ${controlX},${controlY} ${nextX},${y}`;
        }
        
        data.element.setAttribute('d', path);
      });
      
      requestAnimationFrame(animate);
    }
    
    animate();
  })();
  </script>
<div class="mx-auto max-w-7xl px-6 py-16 sm:py-24 lg:px-8 lg:py-32">
<div class="mt-24 border-t border-white/10 pt-12 xl:grid xl:grid-cols-3 xl:gap-8">
<picture class="lazy-picture" data-maxwidth="200">
<source data-original-src="/images/interwork-logo-white-1.webp" data-srcset="/images/interwork-logo-white-1.webp 568w" sizes="200px" type="image/webp">
<img alt="Interwork" class="lazy-image h-9" data-original-src="/images/interwork-logo-white-1.webp" data-src="/images/interwork-logo-white-1.webp" decoding="async" loading="lazy"/>
</source></picture>
<div class="mt-16 grid grid-cols-2 gap-8 xl:col-span-2 xl:mt-0">
<div class="md:grid md:grid-cols-2 md:gap-8">
<div>
<h3 class="text-sm/6 font-semibold text-white">サービス</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">AIソリューション</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">Webサイト制作</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">システム開発</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">コンサルティング</a>
</li>
</ul>
</div>
<div class="mt-10 md:mt-0">
<h3 class="text-sm/6 font-semibold text-white">サポート</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="https://support.smartweb.jp/">サポートポータル</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">ドキュメント</a>
</li>
</ul>
</div>
</div>
<div class="md:grid md:grid-cols-2 md:gap-8">
<div>
<h3 class="text-sm/6 font-semibold text-white">会社情報</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="https://www.intwk.co.jp/about/">会社概要</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="/ja/blog/">ブログ</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">採用情報</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">ニュース</a>
</li>
</ul>
</div>
<div class="mt-10 md:mt-0">
<h3 class="text-sm/6 font-semibold text-white">ポリシー</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="/ja/privacy-policy/">プライバシーポリシー</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="/ja/ai-chatbot-terms-of-use/">AIチャットボット利用規約</a>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="language-selector mt-12 border-t border-white/10 pt-8 md:flex md:items-center md:justify-between">
<div>
<p class="text-sm/6 font-semibold text-white mb-4">利用可能な言語</p>
<div class="language-selector">
<div class="flex flex-wrap items-center justify-center gap-3">
<span class="inline-flex items-center text-sm opacity-50" title="日本語">
<img alt="日本語" class="rounded" height="18" src="/flags/jp.png" width="24"/>
</span>
<a aria-label="English" class="inline-flex items-center text-sm hover:opacity-75 transition-opacity" href="/en/glossary/speech-recognition/" hreflang="en" title="English">
<img alt="English" class="rounded" height="18" src="/flags/gb.png" width="24"/>
</a>
</div>
</div>
</div>
</div>
<div class="mt-12 border-t border-white/10 pt-8 md:flex md:items-center md:justify-between">
<div class="flex gap-x-6 md:order-2">
<a class="text-gray-400 hover:text-gray-300" href="https://github.com">
<span class="sr-only">GitHub</span>
</a>
<a class="text-gray-400 hover:text-gray-300" href="https://x.com">
<span class="sr-only">X</span>
</a>
<a class="text-gray-400 hover:text-gray-300" href="https://youtube.com">
<span class="sr-only">YouTube</span>
</a>
</div>
<p class="mt-8 text-sm/6 text-gray-400 md:mt-0" style="text-align: center; animation: copyrightGlow 3s ease-in-out infinite;">© 2026 Interwork Corporation All rights reserved.</p>
</div>
</div>
<style>
    @keyframes copyrightGlow {
      0%, 100% {
        opacity: 0.6;
        text-shadow: 0 0 10px rgba(99, 102, 241, 0);
      }
      50% {
        opacity: 1;
        text-shadow: 0 0 20px rgba(99, 102, 241, 0.5), 0 0 30px rgba(99, 102, 241, 0.3);
      }
    }
  </style>
</footer>
<div class="pointer-events-none fixed inset-x-0 bottom-0 px-6 pb-6 z-50 dark" data-cookie-consent-banner="" id="cookie-consent-banner">
<div class="pointer-events-auto max-w-xl rounded-xl section-bg-light dark:section-bg-dark p-6 ring-1 shadow-lg ring-gray-900/10">
<p class="text-secondary text-sm/6"><strong class="text-heading text-md mb-4 font-semibold">クッキーの同意</strong><br/> 閲覧体験を向上させ、トラフィックを分析するためにクッキーを使用します。 See our <a class="font-semibold text-primary hover:text-primary-500" href="/ja/privacy-policy/">privacy policy</a>.</p>
<div class="mt-4 flex items-center gap-x-3 flex-wrap">
<a aria-label="すべてを受け入れる" class="btn-primary dark:btn-primary-dark px-3 py-2 text-sm not-prose group" data-cookie-consent="accept-all" href="#" target="_self">
      すべてを受け入れる
      
      
    </a>
<a aria-label="必要なものだけを受け入れる" class="btn-secondary dark:btn-secondary-dark px-3 py-2 text-sm not-prose group" data-cookie-consent="accept-necessary" href="#" target="_self">
      必要なものだけを受け入れる
      
      
    </a>
<a aria-label="クッキー設定" class="btn-text dark:btn-text-dark px-3 py-2 text-sm not-prose group" data-cookie-consent="settings" href="#" target="_self">
      クッキー設定
      
      
    </a>
</div>
</div>
</div>
<div class="fixed inset-0 z-50 hidden dark" id="cookie-settings-modal">
<div class="absolute inset-0 bg-black bg-opacity-50" data-cookie-settings-close=""></div>
<div class="relative mx-auto max-w-xl p-4 sm:p-6 section-bg-light dark:section-bg-dark rounded-xl shadow-xl mt-20">
<div class="flex justify-between items-center mb-4">
<h2 class="text-heading text-xl font-bold">クッキー設定</h2>
<button class="text-gray-400 hover:text-gray-500 dark:text-gray-300 dark:hover:text-white" data-cookie-settings-close="" type="button">
<span class="sr-only">閉じる</span>
<svg class="h-6 w-6" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</button>
</div>
<div class="space-y-4">
<div class="border-gray-200 dark:border-gray-700 border-b pb-4">
<div class="flex items-center justify-between">
<div>
<h3 class="text-heading text-lg font-medium">必要なクッキー</h3>
<p class="text-tertiary text-sm">これらのクッキーはウェブサイトの機能に必要であり、無効にすることはできません。</p>
</div>
<div class="ml-3 flex h-5 items-center">
<input checked="" class="h-4 w-4 rounded-xl border-gray-300 text-primary focus:ring-primary dark:border-gray-600 dark:bg-gray-700" disabled="" id="necessary-cookies" name="necessary-cookies" type="checkbox"/>
</div>
</div>
</div>
<div class="border-gray-200 dark:border-gray-700 border-b pb-4">
<div class="flex items-center justify-between">
<div>
<h3 class="text-heading text-lg font-medium">分析クッキー</h3>
<p class="text-tertiary text-sm">これらのクッキーは、訪問者がウェブサイトとどのように相互作用しているかを理解するのに役立ちます。</p>
</div>
<div class="ml-3 flex h-5 items-center">
<input class="h-4 w-4 rounded-xl border-gray-300 text-primary focus:ring-primary dark:border-gray-600 dark:bg-gray-700" id="analytics-cookies" name="analytics-cookies" type="checkbox"/>
</div>
</div>
</div>
</div>
<div class="mt-6 flex justify-end gap-x-3">
<a aria-label="キャンセル" class="btn-secondary dark:btn-secondary-dark px-3 py-2 not-prose group" data-cookie-settings-close="" href="#" target="_self">
      キャンセル
      
      
    </a>
<a aria-label="設定を保存" class="btn-primary dark:btn-primary-dark px-3 py-2 not-prose group" data-cookie-settings-save="" href="#" target="_self">
      設定を保存
      
      
    </a>
</div>
</div>
</div>
<button aria-label="Back to Top" class="fixed bottom-8 right-8 z-[100] p-3 rounded-full bg-indigo-600 text-white shadow-lg transition-all duration-300 transform translate-y-12 opacity-0 invisible hover:bg-indigo-700 hover:shadow-xl focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:ring-offset-2 dark:bg-indigo-500 dark:hover:bg-indigo-400" id="back-to-top-btn" onclick="window.scrollTo({top: 0, behavior: 'smooth'});">
<svg class="h-6 w-6" fill="none" stroke="currentColor" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
<path d="M5 10l7-7m0 0l7 7m-7-7v18" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</button>
<script>
document.addEventListener('DOMContentLoaded', () => {
  const backToTopBtn = document.getElementById('back-to-top-btn');
  if (!backToTopBtn) return;

  const scrollThreshold = 300;

  const toggleVisibility = () => {
    if (window.scrollY > scrollThreshold) {
      backToTopBtn.classList.remove('translate-y-12', 'opacity-0', 'invisible');
      backToTopBtn.classList.add('translate-y-0', 'opacity-100', 'visible');
    } else {
      backToTopBtn.classList.remove('translate-y-0', 'opacity-100', 'visible');
      backToTopBtn.classList.add('translate-y-12', 'opacity-0', 'invisible');
    }
  };

  let ticking = false;
  window.addEventListener('scroll', () => {
    if (!ticking) {
      window.requestAnimationFrame(() => {
        toggleVisibility();
        ticking = false;
      });
      ticking = true;
    }
  });
});
</script>
<script src="/js/app.js?v=20260111190816"></script>
</body>
</html>