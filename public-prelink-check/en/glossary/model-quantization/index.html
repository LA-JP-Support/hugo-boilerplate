<!DOCTYPE html>
<html dir="ltr" lang="en">
<head>
<meta content="strict-origin-when-cross-origin" name="referrer"/>
<meta charset="utf-8"/>
<meta content="minimum-scale=1, width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport"/>
<title>Model Quantization: A Comprehensive Guide | SmartWeb</title>
<link href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/model-quantization/" rel="canonical"/>
<link href="/images/faivicon.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="/images/faivicon.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="/images/faivicon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="/images/faivicon.png" rel="shortcut icon"/>
<link href="https://main.d1jtfhinlastnr.amplifyapp.com/glossary/model-quantization/" hreflang="en" rel="alternate"/>
<link href="https://main.d1jtfhinlastnr.amplifyapp.com/ja/glossary/model-quantization/" hreflang="ja" rel="alternate"/>
<link href="https://main.d1jtfhinlastnr.amplifyapp.com/glossary/model-quantization/" hreflang="x-default" rel="alternate"/>
<meta content="Model quantization is a technique that reduces the precision of AI model numbers to make them smaller and faster, enabling them to run on phones and edge devices with less memory and power." name="description"/>
<meta content="model quantization, machine learning, deep learning, LLMs, AI optimization" name="keywords"/>
<meta content="website" property="og:type"/>
<meta content="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/model-quantization/" property="og:url"/>
<meta content="Model Quantization: A Comprehensive Guide | SmartWeb" property="og:title"/>
<meta content="Model quantization is a technique that reduces the precision of AI model numbers to make them smaller and faster, enabling them to run on phones and edge devices with less memory and power." property="og:description"/>
<meta content="" property="og:image"/>
<meta content="1200" property="og:image:width"/>
<meta content="630" property="og:image:height"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/model-quantization/" name="twitter:url"/>
<meta content="Model Quantization: A Comprehensive Guide | SmartWeb" name="twitter:title"/>
<meta content="Model quantization is a technique that reduces the precision of AI model numbers to make them smaller and faster, enabling them to run on phones and edge devices with less memory and power." name="twitter:description"/>
<meta content="" name="twitter:image"/>
<style>
  :root {
     
    --color-primary: #1a73e8;
    --color-primary-light: #4285f4;
    --color-primary-dark: #1557b0;

    --color-secondary: #34a853;
    --color-accent: #fbbc05;

    --color-text: #202124;
    --color-background: #ffffff;

     
    --gradient-primary: linear-gradient(to right, var(--color-primary), var(--color-primary-light));
  }

   
  .bg-gradient-primary {
    background-image: var(--gradient-primary);
  }

  .text-gradient,
  .text-gradient-primary {
    background-image: var(--gradient-primary);
    background-clip: text;
    -webkit-background-clip: text;
    color: transparent;
    -webkit-text-fill-color: transparent;
  }
</style>
<link as="font" crossorigin="anonymous" href="/fonts/inter/Inter-VariableFont_opsz,wght.woff2" rel="preload" type="font/woff2"/>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;500;700&amp;family=Noto+Serif+JP:wght@400;500;600;700&amp;display=swap" rel="stylesheet"/>
<link crossorigin="anonymous" href="/css/main.css?v=20260111190821" rel="stylesheet"/>
<link crossorigin="anonymous" href="/css/custom-code-blockquote.css?v=20260111190821" rel="stylesheet"/>
<script defer="" src="/js/main.js?v=20260111190821"></script>
</head>
<body class="antialiased bg-white">
<header class="bg-white">
<nav aria-label="Global" class="mx-auto flex max-w-7xl items-center justify-between gap-x-6 p-6 lg:px-8">
<div class="flex lg:flex-1">
<a class="-m-1.5 p-1.5" href="/en/">
<span class="sr-only">SmartWeb</span>
<picture class="lazy-picture" data-maxwidth="200">
<source data-original-src="/images/smartweb-logo.png" data-srcset="/images/smartweb-logo.png 466w" sizes="200px" type="image/png">
<img alt="SmartWeb Logo" class="lazy-image h-6 sm:h-10 md:h-12 w-auto" data-original-src="/images/smartweb-logo.png" data-src="/images/smartweb-logo.png" decoding="async" loading="lazy"/>
</source></picture>
</a>
</div>
<div class="hidden lg:flex lg:gap-x-12"><a class="text-sm/6 font-semibold text-gray-900" href="/en/">Home</a><a class="text-sm/6 font-semibold text-gray-900" href="/en/blog/">Blog</a><a class="text-sm/6 font-semibold text-gray-900" href="/en/glossary/">Glossary</a><a class="text-sm/6 font-semibold text-gray-900" href="https://www.intwk.co.jp/about/">Company</a></div>
<div class="flex flex-1 items-center justify-end gap-x-6">
<a class="hidden text-sm/6 font-semibold text-gray-900 lg:block" href="https://support.smartweb.jp/">Support</a>
<a class="rounded-md bg-indigo-600 px-3 py-2 text-sm font-semibold text-white shadow-xs hover:bg-indigo-500 focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-indigo-600" href="/en/blog/">Get Started</a>
</div>
<div class="flex lg:hidden">
<button aria-controls="mobile-menu-1768126101320965000" aria-expanded="false" class="-m-2.5 inline-flex items-center justify-center rounded-xl p-2.5 text-gray-700" type="button">
<span class="sr-only">Open main menu</span>
<svg aria-hidden="true" class="size-6" data-slot="icon" fill="none" stroke="currentColor" stroke-width="1.5" viewbox="0 0 24 24">
<path d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
</svg>
</button>
</div>
</nav>
<div aria-modal="true" class="lg:hidden hidden relative z-50" id="mobile-menu-1768126101320965000" role="dialog">
<div class="fixed inset-0 z-50 bg-black bg-opacity-25"></div>
<div class="fixed inset-y-0 right-0 z-50 w-full overflow-y-auto bg-white px-6 py-6 sm:max-w-sm sm:ring-1 sm:ring-gray-900/10 transform transition-transform duration-300 ease-in-out translate-x-full">
<div class="flex items-center gap-x-6">
<a class="-m-1.5 p-1.5" href="/en/">
<span class="sr-only">SmartWeb</span>
<picture class="lazy-picture" data-maxwidth="3000">
<source data-original-src="/images/smartweb-logo.png" data-srcset="/images/smartweb-logo.png 466w" sizes="(max-width: 466px) 466px, 3000px" type="image/png">
<img alt="SmartWeb Logo" class="lazy-image h-6 sm:h-10 md:h-12 w-auto" data-original-src="/images/smartweb-logo.png" data-src="/images/smartweb-logo.png" decoding="async" loading="lazy"/>
</source></picture>
</a>
<a class="ml-auto rounded-md bg-indigo-600 px-3 py-2 text-sm font-semibold text-white shadow-xs hover:bg-indigo-500 focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-indigo-600" href="/en/blog/">Get Started</a>
<button class="-m-2.5 rounded-xl p-2.5 text-gray-700 close-mobile-menu" type="button">
<span class="sr-only">Close menu</span>
<svg aria-hidden="true" class="size-6" data-slot="icon" fill="none" stroke="currentColor" stroke-width="1.5" viewbox="0 0 24 24">
<path d="M6 18 18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
</svg>
</button>
</div>
<div class="mt-6 flow-root">
<div class="-my-6 divide-y divide-gray-500/10">
<div class="space-y-2 py-6"><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="/en/">Home</a><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="/en/blog/">Blog</a><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="/en/glossary/">Glossary</a><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="https://www.intwk.co.jp/about/">Company</a></div>
<div class="py-6">
<a class="-mx-3 block rounded-lg px-3 py-2.5 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="https://support.smartweb.jp/">Support</a>
</div>
</div>
</div>
</div>
</div>
</header>
<script>
  document.addEventListener('DOMContentLoaded', function() {
    const mobileMenuButton = document.querySelector('[aria-controls="mobile-menu-1768126101320965000"]');
    const mobileMenu = document.getElementById('mobile-menu-1768126101320965000');
    const closeButtons = document.querySelectorAll('.close-mobile-menu');
    const mobileMenuContent = mobileMenu.querySelector('.fixed.inset-y-0');
    
    if (mobileMenuButton && mobileMenu) {
      mobileMenuButton.addEventListener('click', function() {
        const expanded = mobileMenuButton.getAttribute('aria-expanded') === 'true';
        
        if (expanded) {
          closeMobileMenu();
        } else {
          openMobileMenu();
        }
      });
      
      
      closeButtons.forEach(button => {
        button.addEventListener('click', closeMobileMenu);
      });
      
      
      mobileMenu.addEventListener('click', function(event) {
        if (event.target === mobileMenu) {
          closeMobileMenu();
        }
      });
      
      
      mobileMenuContent.addEventListener('click', function(event) {
        event.stopPropagation();
      });
      
      function openMobileMenu() {
        mobileMenuButton.setAttribute('aria-expanded', 'true');
        mobileMenu.classList.remove('hidden');
        
        
        mobileMenuContent.offsetHeight;
        
        mobileMenuContent.classList.remove('translate-x-full');
        document.body.classList.add('overflow-hidden');
      }
      
      function closeMobileMenu() {
        mobileMenuButton.setAttribute('aria-expanded', 'false');
        mobileMenuContent.classList.add('translate-x-full');
        
        
        setTimeout(() => {
          mobileMenu.classList.add('hidden');
          document.body.classList.remove('overflow-hidden');
        }, 300);
      }
    }
  });
</script>
<main class="w-full">
<article class="mx-auto max-w-5xl px-4 sm:px-6 lg:px-8">
<header class="py-12 sm:py-16">
<div class="mx-auto max-w-4xl">
<div class="mb-8">
<nav class="text-sm hidden sm:block">
<ol class="flex items-center space-x-2 text-gray-400 dark:text-gray-500">
<li class="flex items-center">
<a class="hover:text-gray-900 dark:hover:text-gray-300 transition-colors flex items-center" href="/en/">
<img alt="Home" class="h-4 w-4 opacity-60" src="/images/home-icon.png"/>
</a>
</li>
<li><span class="mx-2 text-gray-300 dark:text-gray-600">/</span></li>
<li>
<a class="hover:text-gray-900 dark:hover:text-gray-300 transition-colors" href="/en/glossary/">
                Glossary
              </a>
</li>
<li><span class="mx-2 text-gray-300 dark:text-gray-600">/</span></li>
<li class="text-gray-600 dark:text-gray-400 truncate max-w-xs">Model Quantization: A Comprehensive Guide</li>
</ol>
</nav>
</div>
<div class="mb-6">
<span class="inline-flex items-center text-xs font-medium tracking-wider uppercase text-gray-500 dark:text-gray-400 border-b border-gray-300 dark:border-gray-600 pb-1">
<svg class="mr-2 h-3.5 w-3.5" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M7 7h.01M7 3h5c.512 0 1.024.195 1.414.586l7 7a2 2 0 010 2.828l-7 7a2 2 0 01-2.828 0l-7-7A1.994 1.994 0 013 12V7a4 4 0 014-4z" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
            AI Infrastructure &amp; Deployment
          </span>
</div>
<h1 class="text-2xl font-bold tracking-tight text-gray-900 dark:text-white sm:text-3xl md:text-4xl leading-tight mb-2">
        Model Quantization: A Comprehensive Guide
      </h1>
<div class="mb-6"></div>
<p class="text-base sm:text-lg leading-relaxed text-gray-600 dark:text-gray-300 font-light max-w-3xl">
          Model quantization is a technique that reduces the precision of AI model numbers to make them smaller and faster, enabling them to run on phones and edge devices with less memory and power.
        </p>
<div class="mt-6 mb-4 border-t border-gray-100 dark:border-gray-800"></div>
<div class="flex flex-col sm:flex-row sm:items-center sm:justify-between gap-4">
<div class="flex flex-wrap gap-2">
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                model quantization
              </span>
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                machine learning
              </span>
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                deep learning
              </span>
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                LLMs
              </span>
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                AI optimization
              </span>
</div>
<div class="text-sm text-gray-500 dark:text-gray-400 flex flex-col items-end gap-y-1 text-right">
<span class="inline-flex items-center justify-end">
<svg class="mr-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M8 7V5a3 3 0 013-3h2a3 3 0 013 3v2m4 0h-16a2 2 0 00-2 2v9a2 2 0 002 2h16a2 2 0 002-2V9a2 2 0 00-2-2z" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
      
        Created: December 18, 2025
      
    </span>
</div>
</div>
</div>
</header>
<div class="prose prose-base sm:prose-lg dark:prose-invert mx-auto max-w-4xl py-6 sm:py-8">
<h2 id="what-is-model-quantization">What is Model Quantization?</h2>
<p>Model quantization is an optimization technique reducing the numerical <a data-lb="1" href="/en/glossary/precision/" title="Precision glossary entry">precision</a> of machine learning model parameters (weights) and activations. Instead of using high-precision floating-point numbers—32-bit (FP32) or 16-bit (FP16)—quantization maps these values to lower-precision representations including 8-bit (INT8) or 4-bit (INT4) integers or fixed-point formats.</p>
<p>This process yields significantly smaller models, faster computations, lower power consumption, and enables deployment on resource-constrained hardware including edge devices, mobile phones, and embedded systems. Quantization is key enabler for running large <a data-lb="1" href="/en/glossary/neural-networks/" title="Neural Networks glossary entry">neural networks</a> efficiently on edge and embedded hardware including CPUs, GPUs, AI accelerators, and IoT devices.</p>
<h2 id="why-use-quantization">Why Use Quantization?</h2>
<h3 id="memory-efficiency">Memory Efficiency</h3>
<p>Lower-precision numbers require fewer bits, drastically reducing memory footprint. Quantizing from FP32 to INT8 cuts memory usage by 75%. For <a data-lb="1" href="/blog/how-to-use-large-language-models-effectively/" title="Learn practical applications of large language models like ChatGPT, explore different LLM platforms, understand how these models work under the hood, and discover how to leverage them effectively in your daily work and life.">large language models</a> with tens or hundreds of billions of parameters, this reduction is critical for fitting models into smaller GPUs or edge devices.</p>
<p><strong>Example:</strong> 70-billion parameter LLM requires approximately 280GB in FP32 precision. Quantizing to INT8 can shrink this to about 70GB—making it possible to run on single high-end GPU or smaller devices.</p>
<h3 id="faster-inference">Faster Inference</h3>
<p>Integer arithmetic is more efficient than floating-point on most hardware. Quantized models can achieve 2–3x speedup in inference, and up to 16x increase in performance per watt on specialized accelerators.</p>
<h3 id="lower-power-consumption">Lower Power Consumption</h3>
<p>Smaller, quantized models consume less energy—important factor for battery-powered devices and sustainability-conscious deployments.</p>
<h3 id="edge-deployment">Edge Deployment</h3>
<p>Many edge devices (IoT, smartphones, wearables) lack hardware to support high-precision operations. Quantization enables running advanced AI models on resource-constrained hardware.</p>
<h3 id="cost-reduction">Cost Reduction</h3>
<p>By reducing computational and memory requirements, quantization lowers operational costs in cloud and datacenter deployments.</p>
<h2 id="mathematical-foundations">Mathematical Foundations</h2>
<p>Quantization maps high-precision values to lower-precision domain by scaling and discretizing continuous values into finite set. Most common scheme is affine quantization.</p>
<p>For floating-point value x in range [a, b]:</p>
<p><strong>Scale (S):</strong> Determines how continuous floating-point range maps to discrete integer range.</p>
<p><strong>Zero-point (Z):</strong> Allows floating-point zero to be exactly represented as integer, crucial for correct neural network computation.</p>
<p><strong>Quantizing:</strong></p>
<pre tabindex="0"><code>x_q = round(x/S + Z)
</code></pre><p>where x_q is quantized integer value.</p>
<p><strong>Dequantizing:</strong></p>
<pre tabindex="0"><code>x = S × (x_q - Z)
</code></pre><p>where x is reconstructed floating-point value.</p>
<h3 id="symmetric-vs-asymmetric-quantization">Symmetric vs. Asymmetric Quantization</h3>
<p><strong>Symmetric:</strong> Integer range centered at zero (Z=0); best for data centered around zero.</p>
<p><strong>Asymmetric (Affine):</strong> Z can be any integer, allowing floating-point zero to align with arbitrary integer; useful for skewed distributions.</p>
<h3 id="per-tensor-vs-per-channel-quantization">Per-Tensor vs. Per-Channel Quantization</h3>
<p><strong>Per-tensor:</strong> Same S and Z apply to whole tensor (all weights in layer).</p>
<p><strong>Per-channel:</strong> Each channel (convolutional filter) gets own S and Z; improves accuracy, especially in CNNs.</p>
<h2 id="quantization-techniques">Quantization Techniques</h2>
<h3 id="post-training-quantization-ptq">Post-Training Quantization (PTQ)</h3>
<p>Quantization applied to trained model without retraining.</p>
<p><strong>Static PTQ:</strong></p>
<ul>
<li>Uses calibration dataset to estimate activation ranges</li>
<li>Quantizes weights and activations ahead of inference</li>
<li>Better accuracy but requires calibration data</li>
</ul>
<p><strong>Dynamic PTQ:</strong></p>
<ul>
<li>Quantizes weights statically, activations on-the-fly during inference</li>
<li>No calibration data needed</li>
<li>Slightly lower accuracy and slower than static, easier to implement</li>
</ul>
<p><strong>Use Case:</strong> When retraining not possible or limited data available; suitable for many NLP transformer models.</p>
<h3 id="quantization-aware-training-qat">Quantization-Aware Training (QAT)</h3>
<p>Simulates quantization effects during model training by inserting “fake quantization” operations in computational graph. Model learns to compensate for quantization errors, generally achieving higher post-quantization accuracy, especially at very low bit-widths (INT4).</p>
<p><strong>Use Case:</strong> When maximum accuracy required and retraining feasible; often used for computer vision and edge deployment scenarios.</p>
<h3 id="uniform-vs-non-uniform-quantization">Uniform vs. Non-Uniform Quantization</h3>
<p><strong>Uniform:</strong> Divides range into equal-sized intervals (linear mapping).</p>
<p><strong>Non-Uniform:</strong> Uses variable-sized intervals (logarithmic scales, k-means clustering) allocating more precision where data is dense or critical.</p>
<h3 id="specialized-techniques">Specialized Techniques</h3>
<p><strong>GPTQ (Gradient Post-Training Quantization):</strong> Layer-wise quantization for transformers, minimizing mean squared error between original and quantized outputs. Often uses mixed INT4/FP16 precision.</p>
<p><strong>QLoRA (Quantized Low-Rank Adaptation):</strong> Combines low-rank adaptation (LoRA) with quantization, enabling efficient fine-tuning of LLMs.</p>
<p><strong>Advanced Methods:</strong> ZeroQAT, FlatQuant for quantizing LLMs with minimal accuracy loss.</p>
<h2 id="implementation-example">Implementation Example</h2>
<p>Practical workflow using <a data-lb="1" href="/en/glossary/hugging-face/" title="Hugging Face glossary entry">Hugging Face</a> Transformers and BitsAndBytes for 4-bit quantization:</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> transformers <span style="color:#fff;font-weight:bold">import</span> AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># Model Selection</span>
</span></span><span style="display:flex;"><span>model_id = <span style="color:#0ff;font-weight:bold">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># Quantization Configuration</span>
</span></span><span style="display:flex;"><span>bnb_config = BitsAndBytesConfig(
</span></span><span style="display:flex;"><span>    load_in_4bit=<span style="color:#fff;font-weight:bold">True</span>,
</span></span><span style="display:flex;"><span>    bnb_4bit_use_double_quant=<span style="color:#fff;font-weight:bold">True</span>,
</span></span><span style="display:flex;"><span>    bnb_4bit_quant_type=<span style="color:#0ff;font-weight:bold">"nf4"</span>,
</span></span><span style="display:flex;"><span>    bnb_4bit_compute_dtype=torch.float16
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># Load Model and Tokenizer</span>
</span></span><span style="display:flex;"><span>tokenizer = AutoTokenizer.from_pretrained(model_id)
</span></span><span style="display:flex;"><span>model = AutoModelForCausalLM.from_pretrained(
</span></span><span style="display:flex;"><span>    model_id,
</span></span><span style="display:flex;"><span>    quantization_config=bnb_config,
</span></span><span style="display:flex;"><span>    device_map=<span style="color:#0ff;font-weight:bold">"auto"</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007f7f"># Inference</span>
</span></span><span style="display:flex;"><span>prompt = <span style="color:#0ff;font-weight:bold">"Explain advantages of 4-bit quantization"</span>
</span></span><span style="display:flex;"><span>inputs = tokenizer(prompt, return_tensors=<span style="color:#0ff;font-weight:bold">"pt"</span>).to(model.device)
</span></span><span style="display:flex;"><span>outputs = model.generate(**inputs, max_new_tokens=<span style="color:#ff0;font-weight:bold">128</span>)
</span></span><span style="display:flex;"><span>response = tokenizer.decode(outputs[<span style="color:#ff0;font-weight:bold">0</span>], skip_special_tokens=<span style="color:#fff;font-weight:bold">True</span>)
</span></span></code></pre></div><h2 id="quantization-effects">Quantization Effects</h2>
<table>
<thead>
<tr>
<th>Precision</th>
<th>Model Size Reduction</th>
<th>Speedup</th>
<th>Accuracy Drop</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>FP32</strong></td>
<td>1x</td>
<td>1x</td>
<td>None</td>
</tr>
<tr>
<td><strong>FP16</strong></td>
<td>2x</td>
<td>1.5–2x</td>
<td>&lt;0.5%</td>
</tr>
<tr>
<td><strong>INT8</strong></td>
<td>4x</td>
<td>2–3x</td>
<td>&lt;1%</td>
</tr>
<tr>
<td><strong>INT4</strong></td>
<td>8x</td>
<td>3–5x</td>
<td>1–2% (with QAT)</td>
</tr>
</tbody>
</table>
<h2 id="challenges-and-trade-offs">Challenges and Trade-offs</h2>
<p><strong>Accuracy Loss:</strong> Reducing precision introduces quantization error potentially degrading performance, especially in sensitive layers (attention mechanisms in transformers). QAT and advanced calibration help mitigate.</p>
<p><strong>Outlier Sensitivity:</strong> Large outlier values skew quantization range making it hard to represent common values faithfully. Techniques like outlier channel splitting and percentile calibration address this.</p>
<p><strong>Calibration Complexity:</strong> Choosing appropriate scale and zero-point parameters for each layer or channel is non-trivial. Poor calibration leads to severe accuracy degradation.</p>
<p><strong>Hardware Constraints:</strong> Not all hardware supports all quantization types (INT4, INT8, FP8). Quantization scheme must match hardware capabilities for optimal speedup.</p>
<p><strong>Fairness and <a data-lb="1" href="/en/glossary/bias/" title="Bias glossary entry">Bias</a>:</strong> Improper calibration or quantization can introduce or amplify biases, especially if calibration data is unrepresentative.</p>
<h2 id="applications">Applications</h2>
<p><strong>Edge and Embedded Devices:</strong> Deploying vision models, <a data-lb="1" href="/en/glossary/speech-recognition/" title="Speech Recognition glossary entry">speech recognition</a>, and LLMs on smartphones, IoT sensors, drones, and wearables.</p>
<p><strong>Healthcare:</strong> Running diagnostic models on portable medical devices for real-time analysis.</p>
<p><strong>Autonomous Vehicles:</strong> Real-time object detection and sensor fusion requiring fast, efficient inference on embedded hardware.</p>
<p><strong>Voice Assistants:</strong> Quantized neural networks power on-device speech recognition and natural language understanding in products like Alexa, Siri, Google Assistant.</p>
<p><strong>Industrial IoT:</strong> Anomaly detection, predictive maintenance, and control systems with strict <a data-lb="1" href="/en/glossary/latency/" title="Latency glossary entry">latency</a> and power requirements.</p>
<p><strong>Cloud Inference:</strong> Large-scale LLMs and recommender systems benefit from reduced memory bandwidth and faster serving.</p>
<h2 id="hardware-and-framework-support">Hardware and Framework Support</h2>
<h3 id="hardware">Hardware</h3>
<p><strong>CPUs:</strong> Modern CPUs support INT8 and increasingly INT4 operations (Intel AVX-512 VNNI, AMD Zen4, Apple Silicon, ARM NEON).</p>
<p><strong>GPUs:</strong> NVIDIA (Tensor Cores, Hopper FP8), AMD (Radeon AI), Apple Neural Engine support various quantization formats.</p>
<p><strong>AI Accelerators:</strong> Google Edge TPU, Intel Gaudi, AWS Inferentia, Qualcomm Hexagon, dedicated AI chips for mobile/edge devices.</p>
<p><strong>FPGAs/ASICs:</strong> Custom hardware often supports flexible quantization with user-specified bit-widths.</p>
<h3 id="frameworks">Frameworks</h3>
<p><strong>PyTorch:</strong> Native quantization APIs (QAT/PTQ), torch.quantization, support for INT8/FP16.</p>
<p><strong>TensorFlow Lite:</strong> Focused on post-training quantization and edge deployment.</p>
<p><strong>ONNX Runtime:</strong> Cross-platform with quantization extensions.</p>
<p><strong>Hugging Face Optimum:</strong> Integrates quantization for Transformers and ONNX.</p>
<p><strong>BitsAndBytes:</strong> Focused on LLMs and 4-bit/8-bit quantization.</p>
<h2 id="best-practices">Best Practices</h2>
<p><strong>Start with PTQ:</strong> Attempt post-training quantization first as it requires no retraining.</p>
<p><strong>Use Calibration Data:</strong> For static PTQ, ensure calibration dataset represents production data distribution.</p>
<p><strong>Monitor Accuracy:</strong> Evaluate quantized model thoroughly on validation set, especially for fairness across demographic groups.</p>
<p><strong>Consider QAT for Low Bit-widths:</strong> For INT4 or aggressive quantization, QAT typically achieves better accuracy.</p>
<p><strong>Match Hardware:</strong> Choose quantization format supported by target deployment hardware.</p>
<p><strong>Profile Performance:</strong> Measure actual inference speedup and memory reduction on target hardware.</p>
<p><strong>Document Quantization:</strong> Include quantization details in <a data-lb="1" href="/en/glossary/model-cards/" title="Model Cards glossary entry">model cards</a> for transparency.</p>
<h2 id="references">References</h2>
<ul>
<li><a href="https://huggingface.co/docs/optimum/en/concept_guides/quantization" rel="nofollow noopener noreferrer" target="_blank">Hugging Face Optimum: Quantization Guide</a></li>
<li><a href="https://www.ibm.com/think/topics/quantization" rel="nofollow noopener noreferrer" target="_blank">IBM: What is Quantization?</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/model-quantization-large-language-models" rel="nofollow noopener noreferrer" target="_blank">DigitalOcean: Model Quantization in LLMs</a></li>
<li><a href="https://www.clarifai.com/blog/model-quantization" rel="nofollow noopener noreferrer" target="_blank">Clarifai: Model Quantization – Meaning, Benefits &amp; Techniques</a></li>
<li><a href="https://www.geeksforgeeks.org/deep-learning/quantization-in-deep-learning/" rel="nofollow noopener noreferrer" target="_blank">GeeksforGeeks: Quantization in Deep Learning</a></li>
<li><a href="https://arxiv.org/abs/1712.05877" rel="nofollow noopener noreferrer" target="_blank">arXiv: Quantization and Training of Neural Networks</a></li>
<li><a href="https://leimao.github.io/article/Neural-Networks-Quantization/" rel="nofollow noopener noreferrer" target="_blank">Lei Mao: Neural Networks Quantization</a></li>
<li><a href="https://arxiv.org/abs/2411.02530" rel="nofollow noopener noreferrer" target="_blank">arXiv: Comprehensive Study on Quantization Techniques for LLMs</a></li>
<li><a href="https://huggingface.co/docs/transformers/en/quantization/bitsandbytes" rel="nofollow noopener noreferrer" target="_blank">Hugging Face: BitsAndBytes Quantization</a></li>
<li><a href="https://pytorch.org/docs/stable/quantization.html" rel="nofollow noopener noreferrer" target="_blank">PyTorch: Quantization Documentation</a></li>
</ul>
</div>
<div class="mt-16 sm:mt-20 border-t border-gray-200 dark:border-gray-800 pt-12 sm:pt-16">
<h2 class="text-2xl sm:text-3xl font-bold tracking-tight text-gray-900 dark:text-white mb-8 sm:mb-10">
        
          Related Terms
        
      </h2>
<div class="grid gap-6 sm:gap-8 grid-cols-1 sm:grid-cols-2 lg:grid-cols-3">
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/backpropagation/">
                    Backpropagation
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
                    A fundamental algorithm that trains neural networks by calculating how much each parameter contribut...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/backpropagation/">
                    View details
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/data-augmentation/">
                    Data Augmentation
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
                    A technique that creates new training examples by modifying existing data, helping AI models learn b...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/data-augmentation/">
                    View details
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/adversarial-robustness/">
                    Adversarial Robustness
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
                    An AI model's ability to work correctly even when given deliberately manipulated or tricky inputs de...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/adversarial-robustness/">
                    View details
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/artificial-intelligence/">
                    Artificial Intelligence (AI)
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
                    Technology that enables computers to learn from experience and make decisions like humans do, rather...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/artificial-intelligence/">
                    View details
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/deep-learning/">
                    Deep Learning
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
                    A machine learning technology that uses layered artificial networks inspired by the human brain to a...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/deep-learning/">
                    View details
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/large-language-models/">
                    Large Language Models (LLMs)
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
<a data-lb="1" href="/en/glossary/large-language-models/" title="Large Language Models (LLMs) glossary entry">Large Language Models (LLMs)</a> are <a data-lb="1" href="/en/glossary/artificial-intelligence/" title="Artificial Intelligence (AI) glossary entry">AI systems</a> trained on vast amounts of text data to understand and g...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/large-language-models/">
                    View details
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
</div>
</div>
<div class="mt-12 sm:mt-16 py-8 border-t border-gray-200 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100 transition-colors" href="/en/glossary/">
<svg class="mr-2 h-5 w-5" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M10 19l-7-7m0 0l7-7m-7 7h18" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
      
        Back to Glossary
      
    </a>
</div>
</article>
</main>
<footer style="background-color: #000000;">
<div id="cta-curves-container" style="
    position: relative;
    background: #000000;
    padding: 4rem 2rem;
    overflow: hidden;
  ">
<svg id="cta-curves-svg" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 1; opacity: 0.7;" xmlns="http://www.w3.org/2000/svg">
<defs>
<lineargradient id="curveGrad1" x1="0%" x2="100%" y1="0%" y2="0%">
<stop offset="0%" style="stop-color:rgba(99, 102, 241, 0); stop-opacity:0"></stop>
<stop offset="50%" style="stop-color:rgba(99, 102, 241, 0.9); stop-opacity:1"></stop>
<stop offset="100%" style="stop-color:rgba(99, 102, 241, 0); stop-opacity:0"></stop>
</lineargradient>
<lineargradient id="curveGrad2" x1="0%" x2="100%" y1="0%" y2="0%">
<stop offset="0%" style="stop-color:rgba(139, 92, 246, 0); stop-opacity:0"></stop>
<stop offset="50%" style="stop-color:rgba(139, 92, 246, 0.8); stop-opacity:1"></stop>
<stop offset="100%" style="stop-color:rgba(139, 92, 246, 0); stop-opacity:0"></stop>
</lineargradient>
<lineargradient id="curveGrad3" x1="0%" x2="100%" y1="0%" y2="0%">
<stop offset="0%" style="stop-color:rgba(59, 130, 246, 0); stop-opacity:0"></stop>
<stop offset="50%" style="stop-color:rgba(59, 130, 246, 0.7); stop-opacity:1"></stop>
<stop offset="100%" style="stop-color:rgba(59, 130, 246, 0); stop-opacity:0"></stop>
</lineargradient>
</defs>
<path class="curve" data-speed="0.8" fill="none" stroke="url(#curveGrad1)" stroke-width="2"></path>
<path class="curve" data-speed="1.2" fill="none" opacity="0.8" stroke="url(#curveGrad2)" stroke-width="2.5"></path>
<path class="curve" data-speed="0.6" fill="none" opacity="0.6" stroke="url(#curveGrad3)" stroke-width="1.5"></path>
<path class="curve" data-speed="1.5" fill="none" opacity="0.7" stroke="url(#curveGrad1)" stroke-width="2"></path>
<path class="curve" data-speed="0.9" fill="none" opacity="0.5" stroke="url(#curveGrad2)" stroke-width="3"></path>
<path class="curve" data-speed="1.3" fill="none" opacity="0.9" stroke="url(#curveGrad3)" stroke-width="1.8"></path>
<path class="curve" data-speed="0.7" fill="none" opacity="0.6" stroke="url(#curveGrad1)" stroke-width="2.2"></path>
<path class="curve" data-speed="1.1" fill="none" opacity="0.8" stroke="url(#curveGrad2)" stroke-width="2"></path>
<path class="curve" data-speed="1.4" fill="none" opacity="0.5" stroke="url(#curveGrad3)" stroke-width="2.5"></path>
<path class="curve" data-speed="0.85" fill="none" opacity="0.7" stroke="url(#curveGrad1)" stroke-width="1.5"></path>
<path class="curve" data-speed="1.0" fill="none" opacity="0.6" stroke="url(#curveGrad2)" stroke-width="2.8"></path>
<path class="curve" data-speed="1.25" fill="none" opacity="0.8" stroke="url(#curveGrad3)" stroke-width="2"></path>
<path class="curve" data-speed="0.95" fill="none" opacity="0.5" stroke="url(#curveGrad1)" stroke-width="2.3"></path>
<path class="curve" data-speed="1.35" fill="none" opacity="0.9" stroke="url(#curveGrad2)" stroke-width="1.7"></path>
<path class="curve" data-speed="0.75" fill="none" opacity="0.7" stroke="url(#curveGrad3)" stroke-width="2.5"></path>
</svg>
<div style="position: absolute; top: 0; left: 0; width: 50px; height: 50px; border-left: 2px solid rgba(99, 102, 241, 0.3); border-top: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div style="position: absolute; top: 0; right: 0; width: 50px; height: 50px; border-right: 2px solid rgba(99, 102, 241, 0.3); border-top: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div style="position: absolute; bottom: 0; left: 0; width: 50px; height: 50px; border-left: 2px solid rgba(99, 102, 241, 0.3); border-bottom: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div style="position: absolute; bottom: 0; right: 0; width: 50px; height: 50px; border-right: 2px solid rgba(99, 102, 241, 0.3); border-bottom: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div class="mx-auto max-w-2xl text-center" style="position: relative; z-index: 10;">
<h2 class="text-base/7 font-semibold text-indigo-400">Ready to get started?</h2>
<p class="mt-2 text-4xl font-semibold tracking-tight text-balance text-white sm:text-5xl">Start using our services today</p>
<p class="mx-auto mt-6 max-w-xl text-lg/8 text-pretty text-gray-400">Join thousands of satisfied customers who have transformed their business with our solutions.</p>
<div class="mt-8 flex justify-center">
<a class="rounded-md bg-indigo-500 px-3.5 py-2.5 text-sm font-semibold text-white shadow-xs hover:bg-indigo-400 focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-indigo-400" href="/en/blog/">Get started</a>
</div>
</div>
</div>
<script>
  (function() {
    'use strict';
    
    const container = document.getElementById('cta-curves-container');
    const svg = document.getElementById('cta-curves-svg');
    if (!container || !svg) return;
    
    const curves = svg.querySelectorAll('.curve');
    let mouseX = 0;
    let mouseY = 0;
    let targetMouseX = 0;
    let targetMouseY = 0;
    const mouseInfluence = 150;
    const mouseStrength = 80;
    
    const curveData = Array.from(curves).map((curve, i) => {
      const speed = parseFloat(curve.getAttribute('data-speed')) || 1;
      return {
        element: curve,
        baseY: 50 + (i * 25),
        offset: Math.random() * Math.PI * 2,
        speed: speed,
        amplitude: 30 + Math.random() * 40
      };
    });
    
    container.addEventListener('mousemove', (e) => {
      const rect = container.getBoundingClientRect();
      targetMouseX = e.clientX - rect.left;
      targetMouseY = e.clientY - rect.top;
    });
    
    container.addEventListener('mouseleave', () => {
      targetMouseX = -1000;
      targetMouseY = -1000;
    });
    
    let time = 0;
    
    function animate() {
      time += 0.01;
      
      mouseX += (targetMouseX - mouseX) * 0.15;
      mouseY += (targetMouseY - mouseY) * 0.15;
      
      const width = svg.clientWidth;
      const height = svg.clientHeight;
      
      curveData.forEach((data, index) => {
        const { baseY, offset, speed, amplitude } = data;
        const phase = time * speed + offset;
        
        let path = `M -200,${baseY}`;
        
        for (let x = -200; x <= width + 200; x += 50) {
          const normalY = baseY + Math.sin((x * 0.005) + phase) * amplitude;
          
          const dx = x - mouseX;
          const dy = normalY - mouseY;
          const distance = Math.sqrt(dx * dx + dy * dy);
          
          let y = normalY;
          if (distance < mouseInfluence) {
            const influence = (1 - distance / mouseInfluence);
            const pushY = (normalY - mouseY) * influence * mouseStrength * 0.01;
            y = normalY + pushY;
          }
          
          const nextX = x + 50;
          const controlX = x + 25;
          const controlY = y;
          path += ` Q ${controlX},${controlY} ${nextX},${y}`;
        }
        
        data.element.setAttribute('d', path);
      });
      
      requestAnimationFrame(animate);
    }
    
    animate();
  })();
  </script>
<div class="mx-auto max-w-7xl px-6 py-16 sm:py-24 lg:px-8 lg:py-32">
<div class="mt-24 border-t border-white/10 pt-12 xl:grid xl:grid-cols-3 xl:gap-8">
<picture class="lazy-picture" data-maxwidth="200">
<source data-original-src="/images/interwork-logo-white-1.webp" data-srcset="/images/interwork-logo-white-1.webp 568w" sizes="200px" type="image/webp">
<img alt="Interwork" class="lazy-image h-9" data-original-src="/images/interwork-logo-white-1.webp" data-src="/images/interwork-logo-white-1.webp" decoding="async" loading="lazy"/>
</source></picture>
<div class="mt-16 grid grid-cols-2 gap-8 xl:col-span-2 xl:mt-0">
<div class="md:grid md:grid-cols-2 md:gap-8">
<div>
<h3 class="text-sm/6 font-semibold text-white">Services</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">AI Solutions</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">Web Development</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">System Development</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">Consulting</a>
</li>
</ul>
</div>
<div class="mt-10 md:mt-0">
<h3 class="text-sm/6 font-semibold text-white">Support</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="https://support.smartweb.jp/">Support Portal</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">Documentation</a>
</li>
</ul>
</div>
</div>
<div class="md:grid md:grid-cols-2 md:gap-8">
<div>
<h3 class="text-sm/6 font-semibold text-white">Company</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="https://www.intwk.co.jp/about/">About</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="/en/blog/">Blog</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">Careers</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">News</a>
</li>
</ul>
</div>
<div class="mt-10 md:mt-0">
<h3 class="text-sm/6 font-semibold text-white">Legal</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="/en/privacy-policy/">Privacy Policy</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="/en/ai-chatbot-terms-of-use/">AI Chatbot Terms of Use</a>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="language-selector mt-12 border-t border-white/10 pt-8 md:flex md:items-center md:justify-between">
<div>
<p class="text-sm/6 font-semibold text-white mb-4">Available Languages</p>
<div class="language-selector">
<div class="flex flex-wrap items-center justify-center gap-3">
<a aria-label="日本語" class="inline-flex items-center text-sm hover:opacity-75 transition-opacity" href="/ja/glossary/model-quantization/" hreflang="ja" title="日本語">
<img alt="日本語" class="rounded" height="18" src="/flags/jp.png" width="24"/>
</a>
<span class="inline-flex items-center text-sm opacity-50" title="English">
<img alt="English" class="rounded" height="18" src="/flags/gb.png" width="24"/>
</span>
</div>
</div>
</div>
</div>
<div class="mt-12 border-t border-white/10 pt-8 md:flex md:items-center md:justify-between">
<div class="flex gap-x-6 md:order-2">
<a class="text-gray-400 hover:text-gray-300" href="https://github.com">
<span class="sr-only">GitHub</span>
</a>
<a class="text-gray-400 hover:text-gray-300" href="https://x.com">
<span class="sr-only">X</span>
</a>
<a class="text-gray-400 hover:text-gray-300" href="https://youtube.com">
<span class="sr-only">YouTube</span>
</a>
</div>
<p class="mt-8 text-sm/6 text-gray-400 md:mt-0" style="text-align: center; animation: copyrightGlow 3s ease-in-out infinite;">© 2026 Interwork Corporation All rights reserved.</p>
</div>
</div>
<style>
    @keyframes copyrightGlow {
      0%, 100% {
        opacity: 0.6;
        text-shadow: 0 0 10px rgba(99, 102, 241, 0);
      }
      50% {
        opacity: 1;
        text-shadow: 0 0 20px rgba(99, 102, 241, 0.5), 0 0 30px rgba(99, 102, 241, 0.3);
      }
    }
  </style>
</footer>
<div class="pointer-events-none fixed inset-x-0 bottom-0 px-6 pb-6 z-50 dark" data-cookie-consent-banner="" id="cookie-consent-banner">
<div class="pointer-events-auto max-w-xl rounded-xl section-bg-light dark:section-bg-dark p-6 ring-1 shadow-lg ring-gray-900/10">
<p class="text-secondary text-sm/6"><strong class="text-heading text-md mb-4 font-semibold">Cookie Consent</strong><br/> We use cookies to enhance your browsing experience and analyze our traffic. See our <a class="font-semibold text-primary hover:text-primary-500" href="/en/privacy-policy/">privacy policy</a>.</p>
<div class="mt-4 flex items-center gap-x-3 flex-wrap">
<a aria-label="Accept All" class="btn-primary dark:btn-primary-dark px-3 py-2 text-sm not-prose group" data-cookie-consent="accept-all" href="#" target="_self">
      Accept All
      
      
    </a>
<a aria-label="Reject All" class="btn-secondary dark:btn-secondary-dark px-3 py-2 text-sm not-prose group" data-cookie-consent="accept-necessary" href="#" target="_self">
      Reject All
      
      
    </a>
<a aria-label="Cookie Settings" class="btn-text dark:btn-text-dark px-3 py-2 text-sm not-prose group" data-cookie-consent="settings" href="#" target="_self">
      Cookie Settings
      
      
    </a>
</div>
</div>
</div>
<div class="fixed inset-0 z-50 hidden dark" id="cookie-settings-modal">
<div class="absolute inset-0 bg-black bg-opacity-50" data-cookie-settings-close=""></div>
<div class="relative mx-auto max-w-xl p-4 sm:p-6 section-bg-light dark:section-bg-dark rounded-xl shadow-xl mt-20">
<div class="flex justify-between items-center mb-4">
<h2 class="text-heading text-xl font-bold">Cookie Settings</h2>
<button class="text-gray-400 hover:text-gray-500 dark:text-gray-300 dark:hover:text-white" data-cookie-settings-close="" type="button">
<span class="sr-only">Close</span>
<svg class="h-6 w-6" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</button>
</div>
<div class="space-y-4">
<div class="border-gray-200 dark:border-gray-700 border-b pb-4">
<div class="flex items-center justify-between">
<div>
<h3 class="text-heading text-lg font-medium">Necessary Cookies</h3>
<p class="text-tertiary text-sm">These cookies are required for the website to function and cannot be disabled.</p>
</div>
<div class="ml-3 flex h-5 items-center">
<input checked="" class="h-4 w-4 rounded-xl border-gray-300 text-primary focus:ring-primary dark:border-gray-600 dark:bg-gray-700" disabled="" id="necessary-cookies" name="necessary-cookies" type="checkbox"/>
</div>
</div>
</div>
<div class="border-gray-200 dark:border-gray-700 border-b pb-4">
<div class="flex items-center justify-between">
<div>
<h3 class="text-heading text-lg font-medium">Analytics Cookies</h3>
<p class="text-tertiary text-sm">These cookies help us understand how visitors interact with our website.</p>
</div>
<div class="ml-3 flex h-5 items-center">
<input class="h-4 w-4 rounded-xl border-gray-300 text-primary focus:ring-primary dark:border-gray-600 dark:bg-gray-700" id="analytics-cookies" name="analytics-cookies" type="checkbox"/>
</div>
</div>
</div>
</div>
<div class="mt-6 flex justify-end gap-x-3">
<a aria-label="Cancel" class="btn-secondary dark:btn-secondary-dark px-3 py-2 not-prose group" data-cookie-settings-close="" href="#" target="_self">
      Cancel
      
      
    </a>
<a aria-label="Save Preferences" class="btn-primary dark:btn-primary-dark px-3 py-2 not-prose group" data-cookie-settings-save="" href="#" target="_self">
      Save Preferences
      
      
    </a>
</div>
</div>
</div>
<button aria-label="Back to Top" class="fixed bottom-8 right-8 z-[100] p-3 rounded-full bg-indigo-600 text-white shadow-lg transition-all duration-300 transform translate-y-12 opacity-0 invisible hover:bg-indigo-700 hover:shadow-xl focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:ring-offset-2 dark:bg-indigo-500 dark:hover:bg-indigo-400" id="back-to-top-btn" onclick="window.scrollTo({top: 0, behavior: 'smooth'});">
<svg class="h-6 w-6" fill="none" stroke="currentColor" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
<path d="M5 10l7-7m0 0l7 7m-7-7v18" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</button>
<script>
document.addEventListener('DOMContentLoaded', () => {
  const backToTopBtn = document.getElementById('back-to-top-btn');
  if (!backToTopBtn) return;

  const scrollThreshold = 300;

  const toggleVisibility = () => {
    if (window.scrollY > scrollThreshold) {
      backToTopBtn.classList.remove('translate-y-12', 'opacity-0', 'invisible');
      backToTopBtn.classList.add('translate-y-0', 'opacity-100', 'visible');
    } else {
      backToTopBtn.classList.remove('translate-y-0', 'opacity-100', 'visible');
      backToTopBtn.classList.add('translate-y-12', 'opacity-0', 'invisible');
    }
  };

  let ticking = false;
  window.addEventListener('scroll', () => {
    if (!ticking) {
      window.requestAnimationFrame(() => {
        toggleVisibility();
        ticking = false;
      });
      ticking = true;
    }
  });
});
</script>
<script src="/js/app.js?v=20260111190821"></script>
</body>
</html>