#!/usr/bin/env python3
"""
ãƒ–ãƒ­ã‚°MDãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€æ‹¬ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- å£Šã‚ŒãŸå¤–éƒ¨ãƒªãƒ³ã‚¯ã®ä¿®æ­£
- é‡è¤‡ãƒ†ã‚­ã‚¹ãƒˆã®ä¿®æ­£
- FlowHunt/LiveAgentã®å¤–éƒ¨ãƒªãƒ³ã‚¯ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
- å£Šã‚ŒãŸç”¨èªé›†ãƒªãƒ³ã‚¯ã®å‰Šé™¤
"""

import re
from pathlib import Path

def fix_content(content: str, filename: str) -> tuple[str, list[str]]:
    """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä¿®æ­£ã—ã€å¤‰æ›´ç‚¹ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    changes = []
    original = content
    
    # 1. é‡è¤‡ãƒ†ã‚­ã‚¹ãƒˆã®ä¿®æ­£
    duplicates = [
        ('ChatGPTChatGP', 'ChatGPT'),
        ('OpenAIOpenA', 'OpenAI'),
        ('GoogleGoogl', 'Google'),
        ('AnthropicAnthropi', 'Anthropic'),
        ('FlowHuntFlowHun', 'FlowHunt'),
        ('YouTubeYouTub', 'YouTube'),
        ('LiveAgentLiveAgent', 'LiveAgent'),
        ('FacebookFacebook', 'Facebook'),
        ('InstagramInstagram', 'Instagram'),
        ('CAGRCAG', 'CAGR'),
        ('GDPRGDP', 'GDPR'),
        ('APIAPI', 'API'),
        ('FAQFAQ', 'FAQ'),
        ('WhatsAppWhatsApp', 'WhatsApp'),
    ]
    
    for old, new in duplicates:
        if old in content:
            content = content.replace(old, new)
            changes.append(f"é‡è¤‡ä¿®æ­£: {old} â†’ {new}")
    
    # 2. FlowHunt/LiveAgentã®å¤–éƒ¨ãƒªãƒ³ã‚¯ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
    # ãƒ‘ã‚¿ãƒ¼ãƒ³: [FlowHunt](https://...) ã‚„ [LiveAgent](https://...)
    external_link_patterns = [
        (r'\[FlowHunt\]\(https?://[^)]+\)', 'FlowHunt'),
        (r'\[LiveAgent\]\(https?://[^)]+\)', 'LiveAgent'),
    ]
    
    for pattern, replacement in external_link_patterns:
        matches = re.findall(pattern, content)
        if matches:
            content = re.sub(pattern, replacement, content)
            changes.append(f"å¤–éƒ¨ãƒªãƒ³ã‚¯å‰Šé™¤: {pattern[:30]}... â†’ {replacement}")
    
    # 3. å£Šã‚ŒãŸå¤–éƒ¨ãƒªãƒ³ã‚¯ï¼ˆä¸å®Œå…¨ãªURLï¼‰
    broken_links = [
        (r'\[FlowHunt\]\(https://www\.flowhunt\.i(?!o)[^)]*', 'FlowHunt'),
        (r'\[LiveAgent\]\(https://www\.liveagent\.co(?!m)[^)]*', 'LiveAgent'),
    ]
    
    for pattern, replacement in broken_links:
        if re.search(pattern, content):
            content = re.sub(pattern, replacement, content)
            changes.append(f"å£Šã‚ŒãŸãƒªãƒ³ã‚¯ä¿®æ­£: â†’ {replacement}")
    
    # 4. ç”¨èªé›†ãƒªãƒ³ã‚¯ã®æ®‹éª¸ãƒ‘ã‚¿ãƒ¼ãƒ³
    # ãƒ‘ã‚¿ãƒ¼ãƒ³: ãƒ†ã‚­ã‚¹ãƒˆSlug/) ã‚„ ãƒ†ã‚­ã‚¹ãƒˆSlug/) **
    glossary_remnants = [
        # æ—¥æœ¬èª+è‹±èªã‚¹ãƒ©ãƒƒã‚°+/) ãƒ‘ã‚¿ãƒ¼ãƒ³
        (r'([ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾¯A-Za-z]+)[A-Za-z0-9_-]+/\)\s*\*\*', r'\1'),
        (r'([ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾¯A-Za-z]+)[A-Za-z0-9_-]+/\)', r'\1'),
        # [text](/ja/glossary/...) ãƒ‘ã‚¿ãƒ¼ãƒ³
        (r'\[([^\]]+)\]\(/ja/glossary/[^)]+\)', r'\1'),
    ]
    
    for pattern, replacement in glossary_remnants:
        matches = re.findall(pattern, content)
        if matches:
            content = re.sub(pattern, replacement, content)
            changes.append(f"ç”¨èªé›†æ®‹éª¸å‰Šé™¤: {len(matches)}ä»¶")
    
    # 5. å£Šã‚ŒãŸå†…éƒ¨ãƒªãƒ³ã‚¯ï¼ˆç”¨èªé›†ã®èª¬æ˜æ–‡ãŒæ··å…¥ï¼‰
    # ãƒ‘ã‚¿ãƒ¼ãƒ³: TextText/ "èª¬æ˜æ–‡") ã‚„ artificial-intelligence/ "èª¬æ˜...
    broken_internal_patterns = [
        # AIartificial-intelligence/ "äººå·¥çŸ¥èƒ½... ãƒ‘ã‚¿ãƒ¼ãƒ³
        (r'AI(?:artificial-intelligence/[^)]+\)){1,}', 'AI'),
        # FAQã‚ˆãã‚ã‚‹è³ªå•FAQ/ "èª¬æ˜..." ãƒ‘ã‚¿ãƒ¼ãƒ³  
        (r'FAQ[^F]*FAQ/[^)]+\)\)', 'FAQ'),
        (r'FAQ[ã€,][^ã€Œã€\n]+ã€Œ[^ã€]+ã€\)', 'FAQ'),
        # LiveAgentLiveAgent/ "èª¬æ˜..." ãƒ‘ã‚¿ãƒ¼ãƒ³
        (r'LiveAgent/ "[^"]+"[)\s]*', 'LiveAgent'),
        # FlowHuntFlowHunt/ "èª¬æ˜..." ãƒ‘ã‚¿ãƒ¼ãƒ³
        (r'FlowHunt/ "[^"]+"[)\s]*', 'FlowHunt'),
        # FacebookFacebook/ "èª¬æ˜..." ãƒ‘ã‚¿ãƒ¼ãƒ³
        (r'Facebook/ "[^"]+"[)\s]*', 'Facebook'),
        # InstagramInstagram/ "èª¬æ˜..." ãƒ‘ã‚¿ãƒ¼ãƒ³
        (r'Instagram/ "[^"]+"[)\s]*', 'Instagram'),
        # YouTubeYouTube/ "èª¬æ˜..." ãƒ‘ã‚¿ãƒ¼ãƒ³  
        (r'YouTube/ "[^"]+"[)\s]*', 'YouTube'),
    ]
    
    for pattern, replacement in broken_internal_patterns:
        if re.search(pattern, content):
            content = re.sub(pattern, replacement, content)
            changes.append(f"å£Šã‚ŒãŸå†…éƒ¨ãƒªãƒ³ã‚¯ä¿®æ­£: â†’ {replacement}")
    
    # 6. å£Šã‚ŒãŸå¤ªå­—ãƒ‘ã‚¿ãƒ¼ãƒ³
    # ãƒ‘ã‚¿ãƒ¼ãƒ³: ãƒ†ã‚­ã‚¹ãƒˆ** å‹** â†’ **ãƒ†ã‚­ã‚¹ãƒˆå‹**
    bold_fixes = [
        (r'ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹\*\* å‹\*\*', '**ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹å‹**'),
        (r'æ¥­å‹™åŠ¹ç‡\*\* åŒ–\*\*', '**æ¥­å‹™åŠ¹ç‡åŒ–**'),
        (r'ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾ç­–\*\* -', '**ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾ç­–** -'),
        (r'\*\*æ¥­å‹™åŠ¹ç‡åŒ–\*\* -', '**æ¥­å‹™åŠ¹ç‡åŒ–** -'),
    ]
    
    for pattern, replacement in bold_fixes:
        if re.search(pattern, content):
            content = re.sub(pattern, replacement, content)
            changes.append(f"å¤ªå­—ä¿®æ­£: â†’ {replacement[:20]}...")
    
    # 7. è¤‡é›‘ãªå£Šã‚ŒãŸãƒªãƒ³ã‚¯ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆFAQãªã©ï¼‰
    # FAQã€ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã€...ã®ã‚ˆã†ãªé•·ã„èª¬æ˜æ–‡
    complex_faq_pattern = r'FAQ[ã€,][^ã€Œã€\n]{10,}[ã€Œã€][^ã€\n]+[ã€][)]*[)]*'
    if re.search(complex_faq_pattern, content):
        content = re.sub(complex_faq_pattern, 'FAQ', content)
        changes.append("è¤‡é›‘ãªFAQãƒªãƒ³ã‚¯ä¿®æ­£")
    
    # 8. ç”»åƒãƒªãƒ³ã‚¯ã®å£Šã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³
    # <img src="/images/blog/AIartificial-intelligence/...
    img_pattern = r'<img src="[^"]*artificial-intelligence/[^"]*"'
    if re.search(img_pattern, content):
        # ã“ã®å ´åˆã¯æ‰‹å‹•ç¢ºèªãŒå¿…è¦ãªã®ã§ãƒ­ã‚°ã ã‘
        changes.append("âš ï¸ å£Šã‚ŒãŸç”»åƒãƒªãƒ³ã‚¯ã‚ã‚Šï¼ˆæ‰‹å‹•ç¢ºèªæ¨å¥¨ï¼‰")
    
    # 9. status.liveagentLiveAgent/ ãƒ‘ã‚¿ãƒ¼ãƒ³
    status_pattern = r'status\.liveagentLiveAgent/ "[^"]+"'
    if re.search(status_pattern, content):
        content = re.sub(status_pattern, 'status.liveagent', content)
        changes.append("status.liveagentãƒªãƒ³ã‚¯ä¿®æ­£")
    
    # 10. ã€Œã¨ã€ã§çµ‚ã‚ã‚‹ä¸å®Œå…¨ãªæ–‡
    incomplete_patterns = [
        (r'ã€ŒFlowHuntã€ã¨ã€Œ', 'ã€ŒFlowHuntã€ã¨ã€ŒLiveAgentã€'),
        (r'LiveAgentã¨\nã‚’çµ„ã¿åˆã‚ã›', 'LiveAgentã¨FlowHuntã‚’çµ„ã¿åˆã‚ã›'),
        (r'LiveAgentã¨ã‚’çµ„ã¿åˆã‚ã›', 'LiveAgentã¨FlowHuntã‚’çµ„ã¿åˆã‚ã›'),
        (r'FlowHuntã¨ã‚’çµ„ã¿åˆã‚ã›', 'FlowHuntã¨LiveAgentã‚’çµ„ã¿åˆã‚ã›'),
    ]
    
    for pattern, replacement in incomplete_patterns:
        if pattern in content or re.search(pattern, content):
            content = content.replace(pattern, replacement) if pattern in content else re.sub(pattern, replacement, content)
            changes.append(f"ä¸å®Œå…¨æ–‡ä¿®æ­£: â†’ {replacement[:30]}...")
    
    # 11. WhatsAppã‚’æ´»ç”¨ã—ãŸ â†’ WhatsAppã‚’æ´»ç”¨ã—ãŸ
    whatsapp_pattern = r'ã‚’æ´»ç”¨ã—ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ'
    if 'WhatsApp' not in content and whatsapp_pattern in content:
        # æ–‡è„ˆç¢ºèªãŒå¿…è¦
        pass
    
    return content, changes


def main():
    blog_dir = Path('/Users/TM-MBP1/Documents/GitHub/hugo-boilerplate/content/ja/blog')
    
    print("=" * 60)
    print("ãƒ–ãƒ­ã‚°MDãƒ•ã‚¡ã‚¤ãƒ«ä¸€æ‹¬ä¿®æ­£")
    print("=" * 60)
    
    total_changes = 0
    
    for md_file in sorted(blog_dir.glob('*.md')):
        if md_file.name == '.DS_Store':
            continue
            
        content = md_file.read_text(encoding='utf-8')
        fixed_content, changes = fix_content(content, md_file.name)
        
        if changes:
            print(f"\nğŸ“„ {md_file.name}")
            for change in changes:
                print(f"   âœ“ {change}")
            total_changes += len(changes)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
            md_file.write_text(fixed_content, encoding='utf-8')
    
    print("\n" + "=" * 60)
    print(f"å®Œäº†: {total_changes}ä»¶ã®ä¿®æ­£ã‚’é©ç”¨ã—ã¾ã—ãŸ")
    print("=" * 60)


if __name__ == '__main__':
    main()
