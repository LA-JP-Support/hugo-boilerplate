---
title: "Chroma"
date: 2025-12-18
lastmod: 2025-12-18
translationKey: "chroma"
description: "An open-source database that stores AI data as numbers, helping applications find similar information and understand meaning quickly."
keywords: ["Chroma", "vector database", "embeddings", "AI-native applications", "semantic search"]
category: "General"
type: "glossary"
draft: false
---

## What Is Chroma?

Chroma is an open-source vector (embedding) database engineered for AI-native applications, particularly those using large language models (LLMs) and multimodal AI. Unlike traditional databases, Chroma specializes in storing, indexing, and retrieving high-dimensional vector embeddings—numerical representations of text, images, and other unstructured data.

Chroma's core mission is to make it easy for developers and organizations to add semantic search, recommendation, RAG, and AI-native capabilities to their applications, with minimal setup and maximum flexibility.

**Key Features:**- Native support for storing and searching embeddings alongside documents and metadata
- Fast approximate nearest neighbor (ANN) search via HNSW indexing
- Multimodal support (text, images, and more)
- Hybrid queries: semantic + keyword search, plus metadata filtering
- Developer-friendly APIs (Python, JS), and native integrations with frameworks like LangChain and LlamaIndex
- Open-source Apache 2.0 licensing
- Both self-hosted and managed cloud options

## Core Concepts

### Embeddings
Embeddings are dense vectors that encode the semantic meaning of data. For example, a sentence, image, or audio clip can be transformed into a vector of hundreds or thousands of numbers. Similar data points in meaning will have similar embeddings (i.e., be "close" in vector space), even if the raw data is very different.

Chroma supports embeddings generated by popular models, including:
- OpenAI's text-embedding models (e.g., `text-embedding-3-small`)
- HuggingFace models (e.g., `all-MiniLM-L6-v2`)
- Cohere, OpenCLIP, and custom embeddings

This is foundational for semantic search, recommendations, and retrieval-augmented generation.

### Collections
A collection in Chroma is a logical grouping of documents, embeddings, and their associated metadata. Each collection has its own configuration, including embedding function/model, storage location (in-memory or persistent), and optional custom settings for performance or filtering.

This allows separate AI applications or projects to run side-by-side, each tuned for its specific needs.

### Metadata and Hybrid Search
Chroma allows arbitrary key-value metadata to be associated with each document or vector. This enables hybrid search: filtering results by metadata (e.g., author, date, tags) and ranking them by vector similarity.

Supported operators include equality and inequality, range queries (`$gt`, `$lt`), set membership (`$in`), and logical combinations (`$and`, `$or`).

## How Chroma Works

### Vector Indexing & Similarity Search
Chroma uses Hierarchical Navigable Small World (HNSW) graphs for fast, approximate nearest neighbor (ANN) search. HNSW is a state-of-the-art algorithm for high-dimensional vector similarity search, balancing recall (accuracy) and speed, and scaling to millions of vectors.

**Key Properties:**- Sublinear search time for large datasets
- High recall/accuracy (configurable)
- Supports dynamic inserts and efficient deletion

### Document and Metadata Storage
Each entry in Chroma includes the raw document/content (text, image URI, etc.), the vector embedding, and associated metadata (arbitrary key-value JSON). This enables hybrid queries and full semantic search.

Chroma can store data:
- In-memory (fastest, non-persistent)
- On disk (SQLite for metadata, binary files for vectors)
- In Chroma Cloud (fully managed)

### APIs and Client Libraries
Chroma provides a minimal, intuitive API with four main operations:
- **Add:**Insert documents (optionally with embeddings and metadata)
- **Update:**Modify stored entries
- **Delete:**Remove entries
- **Query:**Retrieve similar documents via vector search, with optional metadata filters

Client libraries exist for Python (`chromadb`) and JavaScript/TypeScript. Chroma integrates natively with frameworks like LangChain and LlamaIndex.

## Architecture & Deployment

### Open-Source (Self-Hosted)
Chroma can be run locally or on your own infrastructure in three modes:

**In-memory:**Fast, ephemeral, ideal for prototyping or testing  
**Persistent:**Stores data on disk (SQLite + binary vector files), suitable for local/small production  
**Client-server:**Run as a standalone server, connect via HTTP API (supports multi-user, multi-process)

**Example Server Start:**```shell
chroma run --path ./db --port 8000
```

**Python Client:**```python
import chromadb
client = chromadb.HttpClient(host="localhost", port=8000)
```

### Chroma Cloud (Serverless)
Chroma Cloud is a fully managed, serverless deployment. It handles elastic scaling, automatic backup & high availability, and maintenance and monitoring.

**Connect Example:**```python
import chromadb
client = chromadb.HttpClient(
    host="api.trychroma.com",
    headers={"Authorization": f"Bearer {CHROMA_API_KEY}"}
)
```

## Setup and Integration

### Installation

**Python:**```bash
pip install chromadb
```

For LangChain integration:
```bash
pip install langchain-chroma
```

### Basic Usage Example

```python
import chromadb

client = chromadb.Client()
collection = client.create_collection("documents")

collection.add(
    documents=[
        "Artificial intelligence is transforming healthcare diagnostics",
        "Machine learning models predict patient outcomes with increasing accuracy",
        "Neural networks analyze medical imaging faster than radiologists"
    ],
    ids=["doc1", "doc2", "doc3"]
)

results = collection.query(
    query_texts=["AI applications in medicine"],
    n_results=2
)

print(results)
```

This code creates a collection, inserts documents, and runs a semantic search query.

### Embedding Function Configuration
Chroma collections can use different embedding models. To use OpenAI embeddings:

```python
from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction

openai_ef = OpenAIEmbeddingFunction(
    api_key="your-api-key",
    model_name="text-embedding-3-small"
)

collection = client.create_collection(
    name="openai_embeddings",
    embedding_function=openai_ef
)
```

### LangChain Integration
LangChain provides a native wrapper for Chroma, supporting advanced workflows like RAG, chatbots, and memory.

**Example:**```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
vector_store = Chroma(
    collection_name="example_collection",
    embedding_function=embeddings,
    persist_directory="./chroma_langchain_db",
)
```

## Core Features

**Open-source Apache 2.0**- No lock-in, extensible, community-driven (GitHub Stars 24k+)  
**Fast ANN search**- HNSW graph indexing for sublinear search time  
**Document & metadata storage**- Each embedding relates to a document and user-defined metadata  
**Hybrid search**- Combine semantic (vector) and keyword search  
**Multimodal support**- Store/search text, images, and more  
**Batch ops**- Bulk insert and query for efficiency  
**Simple API**- Add, update, delete, search  
**Integration**- Native with LangChain, LlamaIndex, OpenAI, HuggingFace, Cohere, OpenCLIP  
**Flexible deployment**- In-memory, persistent, client-server, and managed cloud  
**Active community**- Discord, GitHub, docs

## Key Use Cases

### Semantic Search
Chroma powers semantic search by comparing embeddings, not just keywords. Applications include e-commerce (search for "comfortable summer shoes" returns relevant results, even with different wording), knowledge management (search across internal wikis, support tickets, codebases), and healthcare (find similar cases, research, or diagnostic images).

### Recommendation Systems
Find similar items/users by embedding similarity. Enables personalized product/news/article recommendations and item-to-item or user-to-user matching.

### Retrieval-Augmented Generation (RAG)
RAG allows LLMs to access external knowledge bases in real time, improving accuracy and reducing hallucinations. Chatbots cite specific documents, assistants answer with up-to-date company knowledge.

### Image, Audio, and Multimodal Search
Embed images, text, and more into a shared vector space. Enables visual search (find similar images), cross-modal (search images with text, vice versa), and organizing multimedia datasets.

### Chatbots and AI Applications
Chroma acts as persistent, semantic memory for LLMs and chatbots. Retrieve conversation history or relevant knowledge snippets, power context-aware responses.

### Data Science and Analysis
Support exploratory data analysis on high-dimensional data, anomaly detection in financial/security logs, and building knowledge graphs or semantic maps.

## Performance Optimization

Chroma is designed for developer speed and efficiency, but optimization tips include:

**Batch Operations**- Insert/query in bulk to reduce overhead  
**Embedding Dimensionality**- Lower-dimension vectors use less memory, faster search (at possible cost to accuracy)  
**Index Compaction**- Compact HNSW index after frequent deletes/updates  
**Metadata Pre-Filtering**- Filter by metadata before similarity to reduce computation

**Example:**```python
collection.add(
    documents=large_document_list,
    ids=id_list,
    metadatas=metadata_list
)
```

## Comparisons and Alternatives

### Chroma vs. Pinecone, Faiss, Weaviate, Qdrant, Milvus

| Feature | Chroma | Pinecone | Faiss | Weaviate | Qdrant | Milvus |
|---------|--------|----------|-------|----------|--------|--------|
| **Open-source**| ✅ | ❌ | ✅ | ✅ | ✅ | ✅ |
| **Ease of setup**| Very simple | Managed, easy | Complex | Moderate | Moderate | Moderate |
| **Language support**| Python, JS | Python, JS, Go | Python, C++ | Python, JS, Go | Python, REST | Python, REST |
| **Vector indexing**| HNSW | Multiple | Multiple | HNSW, others | HNSW | IVF, HNSW |
| **Document storage**| Built-in | No | No | Built-in | Built-in | Built-in |
| **Metadata filtering**| Yes | Yes | Limited | Yes | Yes | Yes |
| **Hybrid search**| Yes | No | No | Yes | No | No |
| **Cloud/serverless**| Chroma Cloud | Yes | No | Yes | Yes | Yes |
| **RBAC/Multi-tenancy**| No | Yes | No | Yes | Yes | Yes |
| **Scale**| Single-node | Distributed | Local, dist. | Distributed | Distributed | Distributed |
| **Best for**| Dev velocity, prototyping | Large scale | Research, custom ML | Enterprise search | High perf | Massive scale |

**Ecosystem Snapshot:**- **Chroma:**OSS, easy setup, hybrid search, best for prototyping/dev velocity
- **Pinecone:**Managed, distributed, enterprise-grade, multi-index support, high scale
- **Faiss:**OSS, research/ML focus, C++/Python, not a database (no doc/meta storage)
- **Weaviate:**OSS, distributed, hybrid search, schema, multi-tenant
- **Qdrant:**OSS, distributed, filtering, REST/gRPC, high perf
- **Milvus:**OSS, cloud-native, GPU support, very high scale

## References


1. Chroma. (n.d.). Chroma GitHub Repository. GitHub. URL: https://github.com/chroma-core/chroma

2. Chroma. (n.d.). Chroma Documentation. Chroma Docs. URL: https://docs.trychroma.com/

3. LangChain. (n.d.). LangChain Chroma Integration. LangChain Documentation. URL: https://docs.langchain.com/oss/python/integrations/providers/chroma

4. Netflix. (n.d.). Netflix Chaos Monkey. Netflix GitHub. URL: https://netflix.github.io/chaosmonkey/

5. Pinecone. (n.d.). Pinecone Documentation. Pinecone. URL: https://www.pinecone.io/

6. Facebook Research. (n.d.). Faiss GitHub Repository. GitHub. URL: https://github.com/facebookresearch/faiss

7. Weaviate. (n.d.). Weaviate Documentation. Weaviate. URL: https://weaviate.io/

8. Qdrant. (n.d.). Qdrant Documentation. Qdrant. URL: https://qdrant.tech/

9. Milvus. (n.d.). Milvus Documentation. Milvus. URL: https://milvus.io/
