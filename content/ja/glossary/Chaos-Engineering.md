---
title: カオスエンジニアリング
date: '2025-12-19'
lastmod: '2025-12-19'
translationKey: chaos-engineering
description: カオスエンジニアリングは、システムの弱点を発見し、その回復力に対する信頼性を構築するために、意図的にシステムに実験を行う手法です。脆弱性を事前に特定する方法を学びましょう。
keywords:
- カオスエンジニアリング
- システムレジリエンス
- 障害注入
- 分散システム
- SRE
category: AI Infrastructure & Deployment
type: glossary
draft: false
e-title: Chaos Engineering
term: かおすえんじにありんぐ
url: "/ja/glossary/Chaos-Engineering/"
---
## カオスエンジニアリングとは?
カオスエンジニアリングは、制御された障害を意図的に注入することで、ソフトウェアシステムの弱点を発見し、レジリエンス(回復力)を向上させることに焦点を当てた体系的な規律です。システムをランダムに破壊するのではなく、科学的で仮説駆動型の実験を通じて、システムの動作に関する前提を検証し、インシデントになる前に脆弱性を積極的に特定します。特に分散型、クラウドネイティブ、マイクロサービスベースのアーキテクチャにおいて重要です。これらの環境では、創発的な相互作用と依存関係により、障害の予測が困難になります。

この方法論は、事後対応型のインシデント対応を、積極的なレジリエンスエンジニアリングに変革します。意図的に制御されたカオス(サーバー障害、ネットワーク障害、リソース枯渇)を導入することで、チームは実世界の条件に耐えるシステムの能力を検証し、安全で管理された方法で隠れた弱点を発見します。

## カオスエンジニアリングの使用方法

カオスエンジニアリングは、さまざまなIT環境で適用されます:

<strong>分散システム</strong>1つのサービスまたはノードの障害が、複雑なアーキテクチャ全体にどのように波及するかを特定します。サービスメッシュのレジリエンス、フェイルオーバーメカニズム、サーキットブレーカーをテストします。

<strong>クラウドネイティブアプリケーション</strong>オートスケーリング、エフェメラルインフラストラクチャ、マネージドサービスを持つ環境でのレジリエンスを検証します。クラウドサービスが利用できなくなった場合の優雅な機能低下を確保します。

<strong>本番環境</strong>実際のトラフィックでの制御された実験は、最も現実的な洞察をもたらしますが、慎重な影響範囲の管理と堅牢な監視が必要です。

<strong>本番前/テスト環境</strong>カオスプラクティスに不慣れなチームにとって安全な出発点であり、本番デプロイ前に技術を洗練させることができます。

<strong>CI/CDパイプライン</strong>カオステストを組み込むことで、新しいコードやインフラストラクチャの変更がシステムのレジリエンスを低下させないことを保証します。自動化されたカオステストは、早期にリグレッションを検出します。

<strong>主要な実践者:</strong>サイト信頼性エンジニア(SRE)、DevOpsおよびプラットフォームチーム、QA/パフォーマンスエンジニア、セキュリティ/インシデント対応チーム。

## 中核原則

カオスエンジニアリングは、実験が科学的、制御的、価値あるものであることを保証する原則に基づいています:

### 1. 定常状態に関する仮説を構築する
観測可能なメトリクス(エラー率、レイテンシ、スループット)で「正常な」システム動作を定義します。健全な動作を表すベースラインKPIを確立します。

### 2. 実世界のイベントをシミュレートする
もっともらしい障害を注入します:サーバークラッシュ、ネットワークパーティション、依存関係の停止、負荷スパイク。本番環境で発生した、または合理的に発生する可能性のあるシナリオに焦点を当てます。

### 3. (安全な場合)本番環境で実験を実行する
本番環境での実験は、真のユーザートラフィックと依存関係を反映します。最小限の影響範囲から始め、信頼が高まるにつれて拡大します。フィーチャーフラグと監視を使用して範囲を制御します。

### 4. 自動化して継続的に実行する
自動化により、システムが進化してもレジリエンスが維持されます。継続的なカオスエンジニアリングは、新しいデプロイによって導入されたリグレッションを検出します。

### 5. 影響範囲を最小化する
サービスまたはユーザーのサブセットをターゲットにし、フィーチャーフラグを使用し、時間制限を設定し、明確な中止/ロールバック手順を確立します。安全メカニズムは交渉の余地がありません。

## カオスエンジニアリングの方法論

カオスエンジニアリングは、科学的で反復的なアプローチに従います:

### 1. 定常状態とKPIを定義する
健全なシステム動作を表すベースラインメトリクスを確立します(例:レイテンシ < 200ms、エラー率 < 0.1%、可用性99.9%)。

### 2. 仮説を策定する
明確でテスト可能な声明を作成します。例:「サービスXが失敗した場合、バックアップ認証サービスが起動するため、ユーザーログイン率は影響を受けない。」

### 3. 実験を計画する
どの障害を注入するか、どのコンポーネントをターゲットにするか、システムの応答をどのように監視するかを決定します。期待される結果と中止条件を文書化します。

### 4. 安全対策を準備する
堅牢な可観測性、アラート、ロールバック/中止制御を確保します。実験のタイミングと範囲について関係者とコミュニケーションを取ります。

### 5. 実験を実行する
ツールを使用して、制御された方法で障害を注入します(例:プロセスを終了する、レイテンシを導入する、帯域幅を制限する)。

### 6. 監視してデータを収集する
実験中および実験後のメトリクス、ログ、トレース、アプリケーションの動作を観察します。予期しないカスケード障害に注意します。

### 7. 結果を分析する
実際のシステム動作を仮説と比較します。発見事項、予期しない動作、パフォーマンスの問題を文書化します。

### 8. 改善して反復する
コードの変更、インフラストラクチャの改善、または運用手順を通じて、発見された弱点に対処します。将来の実験の範囲または複雑さを拡大します。

<strong>例:</strong>サードパーティの決済サービスに依存するeコマースアプリケーションが停止をシミュレートします。仮説は、システムが注文をキューに入れ、ユーザーに通知するというものです。代わりに、テストは未処理の例外を明らかにし、改善されたエラー処理と再試行ロジックを促します。

## カオスエンジニアリング実験の種類

カオス実験は、実世界の障害シナリオをシミュレートします:

<strong>レイテンシ注入</strong>ネットワーク通信またはサービス応答を人為的に遅延させ、タイムアウト処理とユーザーエクスペリエンスの低下をテストします。

<strong>障害注入</strong>サーバークラッシュ、プロセス終了、ハードウェア障害、データベース利用不可などのエラーを強制します。

<strong>負荷生成</strong>トラフィックスパイクをシミュレートして、スケーリングメカニズム、オートスケーリングポリシー、レート制限をテストします。

<strong>リソース枯渇</strong>リソース(CPU、メモリ、ディスク、ネットワーク)を消費して、ストレス動作とリソース割り当てポリシーを観察します。

<strong>ネットワークパーティション/停止</strong>ネットワーク障害、パケット損失、またはスプリットブレインシナリオをシミュレートして、分散システムのコンセンサスとパーティション耐性を検証します。

<strong>依存関係障害シミュレーション</strong>外部API、データベース、またはマイクロサービスを利用不可または遅くして、フォールバックメカニズムとサーキットブレーカーをテストします。

<strong>カナリアテスト</strong>完全なロールアウト前に、ユーザー/サービスのサブセットに変更をデプロイして影響を検証します。

<strong>セキュリティカオスエンジニアリング</strong>セキュリティインシデントをシミュレートして、検出と対応能力をテストします。

## 一般的なツールとテクノロジー

さまざまなオープンソースおよび商用ツールが利用可能です:

<strong>Chaos Monkey</strong>Netflixのクラウドインスタンスをランダムに終了するオリジナルツール。カオスエンジニアリング運動の先駆者。

<strong>Gremlin</strong>包括的な安全制御を備えた、幅広い制御された障害と統合を提供する商用プラットフォーム。

<strong>Chaos Toolkit</strong>宣言的な実験定義を持つ、カオス実験のためのオープンソースで拡張可能なフレームワーク。

<strong>Chaos Mesh</strong>オペレーターベースの管理を備えた、コンテナ化環境での障害をシミュレートするKubernetesネイティブプラットフォーム。

<strong>Pumba</strong>ネットワーク遅延、パケット損失、コンテナ再起動をサポートするDockerコンテナ用のオープンソースツール。

<strong>LitmusChaos</strong>広範なコミュニティ貢献実験を持つ、Kubernetesカオステスト用のCNCFプロジェクト。

<strong>AWS Fault Injection Simulator (FIS)</strong>ネイティブAWS統合を備えた、カオステスト用のマネージドAWSサービス。

<strong>Google DiRT</strong>大規模なレジリエンス検証のためのGoogleの内部災害テストプログラム。

## 例とユースケース

### 業界の例

<strong>Netflix</strong>クラウドベースのグローバルストリーミングサービスのレジリエンスを検証するために、Chaos MonkeyとSimian Armyを開発しました。継続的な可用性を確保するために、本番システムを定期的にテストします。

<strong>Amazon (AWS)</strong>AWS Fault Injection Simulatorと内部プラクティスを使用して、大規模なクラウドサービスの信頼性を確保します。

<strong>Google</strong>DiRT(災害復旧テスト)演習を実行し、データセンター全体のシャットダウンをシミュレートして、マルチリージョンフェイルオーバーを検証します。

### 典型的なユースケース

<strong>オートスケーリングとフェイルオーバーの検証</strong>障害後にトラフィックが健全なノードに再ルーティングされ、オートスケーリングが負荷の変化に適切に応答することを確保します。

<strong>災害復旧訓練</strong>停止またはリージョン障害をシミュレートして、バックアップシステムと復旧手順を検証します。

<strong>インシデント対応の検証</strong>SRE GameDaysの一環として検出と修復を実践し、チームをトレーニングし、ランブックを検証します。

<strong>規制コンプライアンス</strong>稼働時間SLAが契約上の義務である金融、医療、その他の規制セクターのレジリエンスを実証します。

<strong>単一障害点の特定</strong>冗長性または適切なフェイルオーバーメカニズムが欠如している重要な依存関係を明らかにします。

<strong>CI/CDの安全性</strong>自動化されたカオステストゲートを通じて、本番デプロイ前にリグレッションを検出します。

## メリット

カオスエンジニアリングは、重要なメリットをもたらします:

<strong>システムレジリエンスの向上</strong>ユーザーに影響を与える前に、弱点を積極的に特定して解決します。

<strong>ダウンタイムと停止コストの削減</strong>実践された対応手順により、実際のインシデント中の検出、診断、復旧が高速化されます。

<strong>インシデント対応の強化</strong>チームは制御された環境で障害を処理する経験を積み、実際のインシデント中のパニックを軽減します。

<strong>スケーラビリティとパフォーマンスの向上</strong>容量制限に達する前に、ボトルネックとスケーリングの問題が露呈され、対処されます。

<strong>文化的変革</strong>非難ではなく障害から学ぶ文化を奨励し、継続的な改善を促進します。

<strong>規制/契約コンプライアンス</strong>災害復旧と事業継続能力の証拠を提供します。

<strong>顧客の信頼</strong>停止の減少、復旧の高速化、より良いユーザーエクスペリエンスが、サービスの信頼性への信頼を構築します。

## 課題とリスク

カオスエンジニアリングに関連するリスクと課題:

<strong>組織的抵抗</strong>顧客への影響や経営陣の懸念から、本番システムを「壊す」ことへの躊躇。

<strong>潜在的な顧客への影響</strong>安全メカニズムが失敗した場合、範囲が不適切な実験は実際の停止を引き起こす可能性があります。

<strong>分散システムの複雑さ</strong>数千の相互依存関係を持つシステムでのカスケード障害を予測することは困難です。

<strong>定常状態の定義</strong>システムの健全性を正確に表す関連メトリクスを特定して監視することは困難です。

<strong>リソース要件</strong>熟練した人材、包括的な可観測性インフラストラクチャ、専用のテスト容量が必要です。

<strong>安全性の懸念</strong>中止メカニズム、ロールバック手順、明確なコミュニケーションプロトコルを持つことが重要です。

## ベストプラクティス

推奨されるベストプラクティス:

<strong>小さく始める</strong>信頼を構築し、手順を洗練させるために、非クリティカルまたは本番前環境から始めます。

<strong>監視とロールバックを自動化する</strong>実験がうまくいかない場合の迅速な検出と復旧のために、可観測性と自動化を使用します。

<strong>影響範囲を最小化する</strong>最初はサービスまたはユーザーの小さなサブセットをターゲットにし、徐々に範囲を拡大します。

<strong>明確にコミュニケーションする</strong>実験を実行する前に、すべての関係者に通知します。透明性は、インシデント中の混乱を防ぎます。

<strong>CI/CDと統合する</strong>カオステストをデプロイサイクルの定期的な部分にして、リグレッションを自動的に検出します。

<strong>学習を文書化して共有する</strong>徹底的な記録とポストモーテムを維持します。チーム間で洞察を共有して、実験の価値を倍増させます。

<strong>継続的に反復する</strong>信頼が高まり、システムが進化するにつれて、実験を拡大して洗練させます。

## カオスエンジニアリングの開始

### ステップバイステップのガイダンス

<strong>1. チームを教育する</strong>エンジニアと関係者にカオスの原則とメリットについてトレーニングします。

<strong>2. 準備状況を評価する</strong>堅牢な可観測性とロールバックメカニズムが整っていることを確認します。

<strong>3. 重要なコンポーネントを特定する</strong>ビジネスクリティカルなユーザージャーニーと依存関係に焦点を当てます。

<strong>4. 定常状態メトリクスを定義する</strong>システムの健全性を表す実行可能なKPIを選択します。

<strong>5. 仮説を策定する</strong>「もし〜だったら」シナリオから始めます(例:「データベースを5分間失ったらどうなるか?」)。

<strong>6. ツールを選択して設定する</strong>スタックに適したカオスツールを選択します。

<strong>7. 小規模な実験を設計して実行する</strong>テスト環境での単純な障害から始めます。

<strong>8. 監視、分析、文書化する</strong>発見事項を記録し、インシデント対応手順とアーキテクチャドキュメントを更新します。

<strong>9. 反復して範囲を拡大する</strong>徐々に実験の複雑さと本番環境への露出を増やします。

<strong>10. 組織に統合する</strong>カオスエンジニアリングを信頼性、セキュリティ、開発プロセスに組み込みます。

## 参考文献


1. Principles of Chaos Engineering. (n.d.). Principles of Chaos Engineering. URL: https://principlesofchaos.org/

2. IBM. (n.d.). What is Chaos Engineering?. IBM Think Topics. URL: https://www.ibm.com/think/topics/chaos-engineering

3. eG Innovations. (n.d.). What is Chaos Engineering?. eG Innovations Glossary. URL: https://www.eginnovations.com/glossary/chaos-engineering

4. phoenixNAP. (n.d.). Chaos Engineering – Definition, Principles, Best Practices. phoenixNAP Blog. URL: https://phoenixnap.com/blog/chaos-engineering

5. Gremlin. (n.d.). Chaos Engineering. Gremlin. URL: https://www.gremlin.com/chaos-engineering

6. Gremlin. (n.d.). Security Chaos Engineering. Gremlin. URL: https://www.gremlin.com/chaos-engineering/security/

7. Gremlin. (n.d.). GameDay Chaos Engineering Exercises. Gremlin. URL: https://www.gremlin.com/gameday/

8. Netflix. (n.d.). Chaos Monkey. Netflix GitHub. URL: https://netflix.github.io/chaosmonkey/

9. Netflix. (n.d.). The Netflix Simian Army. Netflix Tech Blog. URL: https://netflixtechblog.com/the-netflix-simian-army-16e57fbab116

10. Chaos Toolkit. (n.d.). Chaos Toolkit Documentation. URL: https://chaostoolkit.org/

11. Chaos Mesh. (n.d.). Chaos Mesh. URL: https://chaos-mesh.org/

12. Pumba. (n.d.). Pumba GitHub Repository. URL: https://github.com/alexei-led/pumba

13. LitmusChaos. (n.d.). LitmusChaos. URL: https://litmuschaos.io/

14. AWS. (n.d.). Fault Injection Simulator (FIS). AWS. URL: https://aws.amazon.com/fis/

15. Google. (n.d.). SRE Book: Disaster Testing (DiRT). Google SRE Book. URL: https://sre.google/sre-book/disaster-testing-dirt/

16. Dynatrace. (n.d.). What is Chaos Engineering?. Dynatrace News Blog. URL: https://www.dynatrace.com/news/blog/what-is-chaos-engineering/

17. Google Cloud. (n.d.). Chaos Engineering Recipes. Google Cloud GitHub. URL: https://github.com/GoogleCloudPlatform/chaos-engineering/blob/main/Chaos-Engineering-Recipes-Book.md
