---
title: ゼロショット思考連鎖
date: 2025-11-25
translationKey: zero-shot-chain-of-thought
description: ゼロショット思考連鎖(CoT)は、LLMのためのプロンプトエンジニアリング技術であり、例を示さずにモデルに段階的な推論を指示することで、複雑な問題解決能力を向上させます。
keywords: ["ゼロショット思考連鎖", "プロンプトエンジニアリング", "LLM", "AIチャットボット", "推論"]
category: AI Chatbot & Automation
type: glossary
draft: false
e-title: Zero-Shot Chain of Thought
term: ゼロショットしこうれんさ
reading: ゼロショット思考連鎖
kana_head: さ
---
## 定義

**Zero-Shot Chain of Thought (CoT)** は、大規模言語モデル(LLM)で使用されるプロンプトエンジニアリング技術です。プロンプトに解答例が提供されていない場合でも、モデルに問題を段階的に推論するよう指示します。これは通常、ユーザーの質問に **「Let's think step by step」** などのフレーズを追加することで実現されます。

- **Zero-shot:** プロンプトにタスク固有の例やデモンストレーションは含まれません。
- **Chain of Thought (CoT):** モデルは最終的な答えだけを出力するのではなく、中間的な推論ステップを生成するよう明示的に求められます。

このアプローチは [Kojima et al. (2022)](https://arxiv.org/abs/2205.11916) によって形式化され、この最小限のプロンプト追加により、LLMが新しいドメインやタスクにおいても論理的で段階的な推論チェーンを生成できることが実証されました。特に、Zero-Shot CoTは算術、常識推論、記号推論タスクにおいて、厳選された例が利用できない場合でもパフォーマンスを向上させることが示されています。

**要約:**  
Zero-Shot CoTは、記憶された例ではなく一般的な訓練を活用して、LLMに新しい問題に対する思考プロセスを透明に表示させます([LearnPrompting.org](https://learnprompting.org/docs/intermediate/zero_shot_cot))。

## 仕組み

Zero-Shot CoTは、モデルに問題を論理的なステップに分解するよう促すことで、モデルの汎化能力を活用します。ワークフローは以下の通りです:

1. **タスクの理解:**  
   モデルは質問または問題を含むプロンプトを受け取ります。  
   *入力例:*  
   「オレンジを15個持っていて、7個あげたら、残りは何個ですか?」

2. **段階的推論の指示:**  
   「Let's think step by step」などのフレーズを含めることで、プロンプトはLLMにタスクを順次的で論理的なステップに分解するよう信号を送ります。

3. **推論ステップの生成:**  
   モデルは、事前訓練中に学習した内部知識と推論スキルを活用して、複数ステップの説明を生成します。Few-shot学習とは異なり、明示的なタスクのデモンストレーションに依存しません。

4. **最終回答の抽出:**  
   推論チェーンの最後に、LLMは最終的な答えを提供します。一部の実装では、生成された推論から答えを抽出するために2番目のプロンプトが使用されます([Kojima et al., 2022](https://arxiv.org/abs/2205.11916))。

**主要な技術的詳細:**  
Zero-Shot CoTはコンテキスト内の例示を必要としません。代わりに、モデルは事前訓練された知識を利用して段階的推論をシミュレートするよう促されます。これは、複数の注釈付き例に依存する従来のCoTプロンプティングとは対照的です。
## Chain of Thoughtプロンプティングの種類

Chain of Thoughtは、LLMから中間的な推論を引き出すために設計されたプロンプティング戦略のファミリーです。以下は、学術文献とエンタープライズガイドに基づく拡張された類型です([IBM Chain of Thought Prompting](https://www.ibm.com/think/topics/chain-of-thoughts)):

| プロンプティングタイプ | 例の提供 | 推論ステップ | 典型的な使用例                          |
|---------------------|---------|------------|----------------------------------------|
| **Zero-Shot**       | なし    | なし       | 直接的な事実Q&A、基本的なクエリ         |
| **Zero-Shot CoT**   | なし    | あり       | 未知の推論、数学、論理タスク            |
| **Few-Shot**        | あり    | なし       | フォーマットガイダンス、軽いコンテキスト |
| **Few-Shot CoT**    | あり    | あり       | 複雑、微妙、または専門的なタスク        |
| **Auto-CoT**        | 自動選択 | あり       | スケーラブルで自動化されたマルチタスク設定 |

**詳細:**
- **Zero-Shotプロンプティング:** 例なし、推論ステップなし。モデルは直接答えることが期待されます(例:「フランスの首都は何ですか?」)。
- **Zero-Shot CoT:** 例はないが、推論の明示的な手がかりがあります(例:「15 - 7は何ですか? Let's think step by step.」)。
- **Few-Shot CoT:** 複数の例示Q&Aペアがプロンプトに提供され、それぞれに推論ステップが含まれます。モデルはフォーマットと推論パターンの両方を推測します。
- **Auto-CoT:** 例示は自動的に選択または生成されます([Auto-CoT: Automatic Chain-of-Thought Prompting in Large Language Models](https://arxiv.org/abs/2302.00923)を参照)。

**さらなる読み物:**  
- [Prompting Guide: Chain-of-Thought Techniques](https://www.promptingguide.ai/techniques/cot)

## 例

**標準Zero-Shot vs. Zero-Shot CoT**

*タスク:*  
「市場に行ってリンゴを10個買いました。隣人に2個、修理工に2個あげました。その後、さらに5個買って1個食べました。今、リンゴは何個ありますか?」

- **標準Zero-Shotプロンプト:**  
  ```
  市場に行ってリンゴを10個買いました。隣人に2個、修理工に2個あげました。その後、さらに5個買って1個食べました。今、リンゴは何個ありますか?
  ```
  **出力:**  
  ```
  11個のリンゴ
  ```
  *(不正解。推論ステップは示されていません。)*

- **Zero-Shot Chain of Thoughtプロンプト:**  
  ```
  市場に行ってリンゴを10個買いました。隣人に2個、修理工に2個あげました。その後、さらに5個買って1個食べました。今、リンゴは何個ありますか?
  Let's think step by step.
  ```
  **出力:**  
  ```
  まず、10個のリンゴから始めました。
  隣人に2個、修理工に2個あげたので、6個残りました。
  その後、さらに5個買ったので、11個になりました。
  最後に1個食べたので、10個残ります。
  ```
  *(正解。推論ステップが示されています。)*

**数学的推論の例**

- **プロンプト:**  
  ```
  5 + 7 + 9 - 12の値は何ですか?
  Let's solve this step by step.
  ```
- **出力:**  
  ```
  1. 最初の2つの数字、5と7から始めます: 5 + 7 = 12
  2. 9を足します: 12 + 9 = 21
  3. 12を引きます: 21 - 12 = 9
  したがって、値は9です。
  ```

**論理的推論の例**

- **プロンプト:**  
  ```
  AがBより背が高く、BがCより背が高い場合、誰が一番背が高いですか?
  Let's think step by step.
  ```
- **出力:**  
  ```
  まず、AはBより背が高いです。
  BはCより背が高いです。
  したがって、背の高い順は A > B > C です。
  よって、Aが一番背が高いです。
  ```

**常識推論の例**

- **プロンプト:**  
  ```
  雨が降っていて傘を持っていない場合、濡れないようにするにはどうすればよいですか?
  Let's think step by step.
  ```
- **出力:**  
  ```
  雨が降っている場合、外に出ると濡れます。
  傘を持っていないので、濡れないための代替方法を探す必要があります。
  雨が止むまで待つか、避難場所を見つけるか、レインコートやバッグなど他の物を使って身を覆うことができます。
  したがって、濡れないようにするには、避難場所を探すか雨が止むのを待つべきです。
  ```

**インタラクティブデモ:**  
- [LearnPrompting.orgで独自のZero-Shot CoTプロンプトを試す](https://learnprompting.org/docs/intermediate/zero_shot_cot)

## 比較表: Zero-Shot CoT vs. その他のプロンプティング

以下の表は、標準zero-shot、zero-shot CoT、few-shot CoTの実用的な違いをまとめたものです。特に最近のLLMで観察されたものです([arXiv:2506.14641](https://arxiv.org/abs/2506.14641)、[IBM](https://www.ibm.com/think/topics/chain-of-thoughts)):

| 側面                          | 標準Zero-Shot      | Zero-Shot CoT           | Few-Shot CoT                |
|------------------------------|-------------------|-------------------------|-----------------------------|
| プロンプト内の例              | なし              | なし                    | あり                        |
| 段階的推論                    | なし              | あり                    | あり                        |
| 新しいタスクへの汎化          | 良好              | 推論でより良好          | 非常に複雑なタスクで最良    |
| モデル要件                    | 一般的なLLM       | 推論能力を持つLLM       | 十分なコンテキストを持つLLM |
| 実装の容易さ                  | 最も簡単          | 簡単                    | より難しい(例が必要)        |
| プロンプト指示                | なし/直接         | "Let's think step by step" | 例 + 指示               |
| トークンコスト(出力長)        | 低い              | 中程度                  | 高い                        |
| 数学/論理でのパフォーマンス   | 低い              | 良好                    | 最良(例が良い場合)          |

**最近の知見:**  
高度なモデル(例: Qwen2.5、GPT-4)では、Zero-Shot CoTは多くの推論タスクでfew-shot CoTと同等またはそれを上回るパフォーマンスを発揮できます。モデルは例示よりも指示に依存するようになっています([arXiv:2506.14641](https://arxiv.org/abs/2506.14641))。

## メリット

- **未知のタスクへの汎化:**  
  Zero-Shot CoTは、一般的な事前訓練を活用して、新しい、以前に見たことのない問題に対して強力なパフォーマンスを実現します([LearnPrompting](https://learnprompting.org/docs/intermediate/zero_shot_cot))。

- **例示データ不要:**  
  プロンプトはコンパクトなまま。労力のかかる例の収集やメンテナンスは不要です。

- **問題解決能力の向上:**  
  段階的推論により、複雑な数学、論理、常識推論問題での結果が改善されます([Kojima et al., 2022](https://arxiv.org/abs/2205.11916))。

- **透明性とデバッグ可能性:**  
  中間ステップによりモデルの推論が可視化され、エラーや誤解を明確に追跡できます。

- **迅速な展開:**  
  デモンストレーションの収集やエンジニアリングなしに、新しいドメインに迅速に適用できます。

- **幅広い適用性:**  
  算術、記号計算、論理パズル、意思決定、科学的説明に有用です。

- **最新のLLMで機能:**  
  最近の研究では、最新のLLMにおいて、Zero-Shot CoTが多くの推論ベンチマークでfew-shotメソッドに匹敵またはそれを超えることが示されています([arXiv:2506.14641](https://arxiv.org/abs/2506.14641))。

## 制限と課題

- **誤った推論の可能性:**  
  モデルの段階的推論は必ずしも論理的に健全または正確ではありません。もっともらしいが欠陥のあるチェーンを生成する可能性があります。

- **限定的なドメイン理解:**  
  深い、ニッチな、または専門的な知識を必要とするタスクでは、例や外部ツールなしではZero-Shot CoTが失敗する可能性があります。

- **モデルサイズの重要性:**  
  大幅な改善は主に大規模モデル(例: GPT-3、GPT-4、Qwen2.5)で見られます。小規模モデルは不完全または非論理的なステップを生成することが多いです([LearnPrompting](https://learnprompting.org/docs/intermediate/zero_shot_cot))。

- **コストとレイテンシの増加:**  
  段階的な説明の生成は出力長を増加させ、より高い計算コストとより遅い応答時間を招きます。

- **過度な説明のリスク:**  
  ネイティブに段階的に推論する高度なLLMの場合、明示的なCoTキューは冗長であるか、パフォーマンスを低下させる可能性があります。

- **ハルシネーションの可能性:**  
  モデルは、特に曖昧、敵対的、または不十分に指定されたプロンプトに対して、もっともらしいが真実ではない推論チェーンを作成する可能性があります。

- **抽出ステップがタスク固有の場合がある:**  
  一部のドメインでは、推論ステップから最終回答を抽出するために追加のプロンプトエンジニアリングが必要です([LearnPrompting](https://learnprompting.org/docs/intermediate/zero_shot_cot))。

## アプリケーションと使用例

- **数学的問題解決:**  
  算術、代数、文章題は、例示なしで段階的に解決できます([Kojima et al., 2022](https://arxiv.org/abs/2205.11916))。

- **自然言語理解:**  
  モデルは、複雑なクエリ、指示を解釈したり、追跡可能な方法で構造化された情報抽出を実行できます。

- **論理パズルと記号推論:**  
  演繹的、帰納的、仮説的推論タスクは、透明な中間ステップから恩恵を受けます。

- **意思決定:**  
  モデルは、ビジネス、金融、サポートのために、説明可能な論理でオプションを比較検討し、選択を正当化できます([IBM](https://www.ibm.com/think/topics/chain-of-thoughts))。

- **科学的推論:**  
  仮説生成、実験設計、段階的な科学的説明は、事前に書かれた例示なしで処理できます。

- **AIチャットボットと仮想アシスタント:**  
  複雑なユーザークエリに対する透明で説明可能な回答を提供でき、信頼とユーザー満足度を向上させます。

- **自動採点と個別指導:**  
  モデルは、段階的な論理を示し、エラーを特定することで、学生の解答にフィードバックを提供できます。

- **法的およびコンプライアンス分析:**  
  段階的推論は、透明性が求められる法的ケース分析や規制コンプライアンスに価値があります。

**さらなる探求:**  
- [Vellum: Chain of Thought Prompting Explained](https://www.vellum.ai/blog/chain-of-thought-prompting-cot-everything-you-need-to-know)

## ベストプラクティス

- **明確な指示を使用:**  
  「Let's think step by step」、「Let's solve this step by step」、または「Let's reason this out」などの明示的な手がかりを含めます。

- **モデル機能をテスト:**  
  最適な結果を得るために、大規模で最先端のLLMでZero-Shot CoTを適用します。特定のタスクでパフォーマンスを検証します。

- **コストとレイテンシを監視:**  
  改善された推論と増加したトークン使用量またはより遅い応答とのトレードオフを考慮します。

- **自己一貫性と組み合わせる:**  
  重要なアプリケーションでは、複数の推論チェーンを生成し、最も一般的な答えを選択します(「自己一貫性」アプローチ。[Wei et al., 2022](https://arxiv.org/abs/2201.11903)を参照)。

- **過度なプロンプティングを避ける:**  
  一部のモデルはデフォルトで段階的推論を行います。最良の結果を得るために、明示的なCoT指示の有無の両方でテストします。

- **出力表示を管理:**  
  本番システムでは、観察可能性のために推論ステップをキャプチャしますが、簡潔さが必要な場合はエンドユーザーには最終回答のみを表示します。

- **デバッグ:**  
  段階的な出力を使用して、特定の推論エラーを特定、診断、修正します。

**高度なヒント:**  
代替指示(例:「Let's solve this by splitting into steps」または「Let's think about this logically.」)を試してみてください。ただし、研究によると「Let's think step by step」が一般的に最も効果的です([LearnPrompting](https://learnprompting.org/docs/intermediate/zero_shot_cot))。

## よくある質問(FAQ)

**Q1: Zero-ShotとZero-Shot CoTの違いは何ですか?**  
*A:*  
Zero-Shotプロンプトは直接的な答えを求めます。Zero-Shot CoTプロンプトは「Let's think step by step」などの手がかりで中間的な推論ステップも要求します([LearnPrompting](https://learnprompting.org/docs/intermediate/zero_shot_cot))。

**Q2: なぜ「Let's think step by step」が機能するのですか?**  
*A:*  
これはモデルに段階的推論を出力するようトリガーし、訓練中に学習したパターン(多くの場合、指示に従うことや説明が豊富なデータから)を活用します([Kojima et al., 2022](https://arxiv.org/abs/2205.11916))。

**Q3: Few-Shot CoTの代わりにZero-Shot CoTをいつ使用すべきですか?**  
*A:*  
関連する例が利用できない場合、広範に汎化する必要がある場合、または多様なタスクにわたる迅速なプロトタイピングの場合にZero-Shot CoTを使用します([arXiv:2506.14641](https://arxiv.org/abs/2506.14641))。

**Q4: Zero-Shot CoTは常に精度を向上させますか?**  
*A:*  
いいえ。その効果はタスクの複雑さとモデルサイズに依存します。複数ステップまたは曖昧な問題に最適ですが、単純なクエリやデフォルトで良好に推論する高度なモデルでは冗長になる可能性があります。

**Q5: Zero-Shot CoTを他の技術と組み合わせることはできますか?**  
*A:*  
はい。自己一貫性、回答検証、自動例示選択(Auto-CoT)とうまく組み合わせることができます。

**Q6: コードでZero-Shot CoTを実装するにはどうすればよいですか?**