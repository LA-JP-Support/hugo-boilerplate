---
title: 適合率と再現率
translationKey: precision-and-recall
description: 適合率と再現率は、分類システムや情報検索システムを評価するための中核的な指標です。適合率は正しい陽性予測を測定し、再現率はすべての実際の陽性を見つけ出します。
keywords:
- 適合率
- 再現率
- 機械学習
- 分類指標
- 混同行列
category: AI Chatbot & Automation
type: glossary
date: '2025-12-19'
lastmod: '2025-12-19'
draft: false
e-title: Precision and Recall
term: てきごうりつとさいげんりつ
url: "/ja/glossary/Precision-and-Recall/"
---
## 適合率と再現率とは?
適合率と再現率は、教師あり機械学習において最も広く使用される評価指標の2つであり、特に分類や情報検索タスクにおいて重要です。これらは、精度だけでは捉えきれないモデルのパフォーマンスに関する補完的な洞察を提供します。特に、不均衡なデータセットや、異なるタイプのエラーが異なるコストを伴うシナリオにおいて有効です。

<strong>適合率(Precision)</strong>は、正と予測したもののうち実際に正しかったものの割合を測定します。「モデルが正と分類したインスタンスのうち、実際に正であったものはいくつか?」という問いに答えます。適合率が高いということは、偽陽性が少ないことを意味します。つまり、モデルが何かを正と予測した場合、それは通常正しいということです。

<strong>再現率(Recall)</strong>(感度または真陽性率とも呼ばれる)は、実際の正例のうちモデルが正しく識別した割合を測定します。「データ内のすべての真の正例のうち、モデルが捉えたものはいくつか?」という問いに答えます。再現率が高いということは、偽陰性が少ないことを意味します。つまり、モデルは実際の正例のほとんどを見つけるということです。

これらの指標は、データセットが不均衡な場合、偽陽性と偽陰性のコストが大きく異なる場合、または特定のビジネス要件が特定のタイプのエラーを最小化することを要求する場合に、モデルを評価するために不可欠です。適合率と再現率を理解しバランスを取ることは、F1スコアやROC-AUCなどの関連指標とともに、AIおよび自動化システムの堅牢でコンテキストに応じた評価と展開を保証します。

## 混同行列の基礎

適合率と再現率は、どちらも混同行列から導出されます。混同行列は、分類結果を2×2の表にまとめたものです:

|  | 正と予測 | 負と予測 |
|---|---|---|
| <strong>実際は正</strong>| 真陽性(TP) | 偽陰性(FN) |
| <strong>実際は負</strong>| 偽陽性(FP) | 真陰性(TN) |

<strong>真陽性(TP):</strong>モデルが正のインスタンスを正しく予測した

<strong>偽陽性(FP):</strong>モデルが誤って正と予測した(実際は負)

<strong>真陰性(TN):</strong>モデルが負のインスタンスを正しく予測した

<strong>偽陰性(FN):</strong>モデルが誤って負と予測した(実際は正)

混同行列は、適合率、再現率、F1スコア、精度、特異度を含むほぼすべての分類評価指標の出発点です。

## 適合率:定義と計算式

### 定義

適合率は、正の予測の正確さを測定します。予測された正例のうち、実際に正であるものの割合を定量化します。

### 計算式

```
適合率 = TP / (TP + FP)
```

### 直感的理解

適合率は、モデルが偽陽性エラーをほとんど起こさない場合に高くなります。「正」と予測した場合、通常それは正しいということです。

<strong>高い適合率:</strong>誤警報が少ない。正の予測のほとんどが真である

<strong>低い適合率:</strong>誤警報が多い。正の予測がしばしば間違っている

### 適合率が重要な場合

適合率は、偽陽性のコストが高い場合に特に重要です:

- <strong>スパム検出:</strong>高い適合率により、正当なメールがスパムとしてマークされることがほとんどない
- <strong>法的文書レビュー:</strong>関連性のない文書を関連性があると誤ってラベル付けすると、高額な弁護士の時間が無駄になる
- <strong>医療スクリーニング:</strong>偽陽性は不必要なストレス、フォローアップ手続き、コストを引き起こす

### 制限事項

適合率を過度に最適化すると、モデルが多くの真陽性を見逃し、再現率が低下する可能性があります。モデルが非常に確信がある場合にのみ「正」と予測すると、正の予測をほとんど行わなくなり、適合率は高いが再現率は低くなります。

## 再現率:定義と計算式

### 定義

再現率は、モデルがすべての実際の正のインスタンスを見つける能力を測定します。実際の正例のうち、モデルが正しく識別したものの割合を定量化します。

### 計算式

```
再現率 = TP / (TP + FN)
```

### 直感的理解

再現率は、モデルが実際の正例をほとんど見逃さない場合に高くなります。

<strong>高い再現率:</strong>モデルはほとんどの正例を見つける(偽陰性が少ない)

<strong>低い再現率:</strong>モデルは多くの正例を見逃す(偽陰性が多い)

### 再現率が重要な場合

再現率は、正例を見逃すことが高いコストを伴う場合に重要です:

- <strong>医療診断:</strong>病気を見逃すこと(偽陰性)は致命的になる可能性がある。高い再現率により、ほとんどの病気の患者が発見される
- <strong>不正検出:</strong>不正な取引を見逃すことはコストがかかる
- <strong>安全性が重要なシステム:</strong>危険を検出できないことは深刻な被害を引き起こす可能性がある

### 制限事項

再現率を過度に最適化すると、モデルが多くの偽陽性エラーを起こし、適合率が低下する可能性があります。モデルがほぼすべてを正としてラベル付けすると、再現率は高くなりますが、適合率は低下します。

## 適合率と再現率の計算:例

<strong>シナリオ:</strong>不正なクレジットカード取引の検出

- <strong>データセット:</strong>1,000件の取引。50件が不正(正クラス)、950件が正当
- <strong>モデルの予測:</strong>40件の取引を不正と予測
  - 30件は真に不正(TP = 30)
  - 10件は正当だがフラグ付けされた(FP = 10)
- 50件の実際の不正のうち、20件が見逃された(FN = 20)
- モデルは940件を正当と正しく識別(TN = 940)

<strong>混同行列:</strong>|  | 不正と予測 | 正当と予測 |
|---|---|---|
| <strong>実際は不正</strong>| 30(TP) | 20(FN) |
| <strong>実際は正当</strong>| 10(FP) | 940(TN) |

<strong>計算:</strong>

<strong>適合率:</strong>TP / (TP + FP) = 30 / (30 + 10) = 0.75または75%
- *解釈:不正としてフラグ付けされた取引の75%が真に不正であった*

<strong>再現率:</strong>TP / (TP + FN) = 30 / (30 + 20) = 0.60または60%
- *解釈:モデルはすべての不正ケースの60%を識別した*

## 適合率と再現率のトレードオフ

適合率と再現率は通常、互いにトレードオフの関係にあります:

| 指標 | 最適化すべき場合 | 単独で最大化した場合のリスク | 適用例 |
|--------|---------------|------------------------|---------------------|
| 適合率 | 偽陽性がコストが高い | 真陽性を見逃す(低い再現率) | スパム検出、法的レビュー |
| 再現率 | 偽陰性がコストが高い | 多くの偽陽性(低い適合率) | 医療スクリーニング、不正検出 |

### 適合率と再現率のバランス

<strong>高い適合率、低い再現率:</strong>モデルはめったに正の予測を行わないが、それらはほとんど正しい

<strong>高い再現率、低い適合率:</strong>モデルはほとんどの正例を見つけるが、多くの負例も誤って正としてラベル付けする

### 閾値依存性

適合率と再現率のバランスは、モデルの決定閾値を使用して調整できます:

- <strong>閾値を下げる</strong>と再現率が増加するが適合率が減少する
- <strong>閾値を上げる</strong>と適合率が増加するが再現率が減少する

適合率-再現率曲線は、さまざまな閾値での適合率と再現率をプロットし、最適な動作点を特定するのに役立ちます。

## 適合率、再現率、または両方を使用する場合

<strong>適合率に焦点を当てる場合:</strong>- 偽陽性が高いコストを伴う(例:重要なメールをスパムとしてマークする)
- 予測を調査するためのリソースが限られている
- ユーザーの信頼が予測の正確さに依存している

<strong>再現率に焦点を当てる場合:</strong>- 偽陰性が高いコストを伴う(例:がん診断を見逃す)
- 誤警報に関係なく、すべての正例を見つけることが重要
- フォローアッププロセスが偽陽性を効率的にフィルタリングできる

<strong>両方のバランスを取る場合:</strong>- ほとんどの実世界の問題では両方の指標を考慮する必要がある
- 偽陽性と偽陰性の両方に結果がある
- 最適化にはF1スコアまたは適合率-再現率曲線を使用する

## 関連指標

### F1スコア

F1スコアは、適合率と再現率の調和平均です:

```
F1 = 2 × (適合率 × 再現率) / (適合率 + 再現率)
```

適合率と再現率のバランスを取る単一の指標が必要な場合、特に不均衡なデータセットに使用します。

### 精度

```
精度 = (TP + TN) / (TP + FP + TN + FN)
```

<strong>制限事項:</strong>クラスが不均衡な場合、誤解を招く可能性があります。99:1の不均衡なデータセットですべてを負と予測するモデルは、99%の精度を達成しますが、再現率は0%です。

### ROC-AUC

<strong>ROC曲線:</strong>異なる閾値での真陽性率(再現率)と偽陽性率をプロットする

<strong>AUC:</strong>ROC曲線の下の面積。すべての閾値にわたってクラスを区別するモデルの能力を測定する

モデルを比較し、トレードオフを視覚化するのに有用です。

### 特異度

```
特異度 = TN / (TN + FP)
```

実際の負例のうち正しく識別されたものの割合を測定します。医療診断において特に関連性があり、しばしば再現率(感度)とともに使用されます。

## ベストプラクティス

<strong>両方の指標を評価する</strong>精度だけでなく、適合率と再現率の両方を報告します。単一の指標では重要な弱点を隠す可能性があります。

<strong>混同行列を使用する</strong>指標を最適化する前に、混同行列を通じてモデルのエラーを理解します。

<strong>F1スコアを要約として報告する</strong>F1スコアを含めますが、完全な理解のために常に適合率と再現率を個別に示します。

<strong>パフォーマンスを視覚化する</strong>適合率-再現率曲線とROC曲線を使用して、閾値全体のパフォーマンスを理解します。

<strong>閾値を調整する</strong>デフォルト値ではなく、ビジネスまたは安全要件を満たすように決定閾値を設定します。

<strong>コストに基づいて指標を選択する</strong>アプリケーションにおける異なるエラータイプの実世界のコストに基づいて最適化目標を選択します。

<strong>追加の指標で補完する</strong>徹底的な評価のために、特異度、ROC-AUC、平均適合率を含めます。

## よくある落とし穴

<strong>クラス不均衡を無視する</strong>高い精度は、稀なクラスでの低いパフォーマンスを隠す可能性があります。適合率と再現率はより良い洞察を提供します。

<strong>1つの指標のみを報告する</strong>重要な弱点を隠す可能性があります。常に適合率と再現率の両方を報告します。

<strong>閾値感度</strong>適合率と再現率の値は決定閾値に依存します。複数の閾値で評価するか、曲線を使用します。

<strong>未定義の値</strong>正の予測がない場合(TP + FP = 0)、適合率は未定義です。エッジケースを適切に処理します。

## ユースケースの例

| 領域 | ユースケース | 優先度 | 理由 |
|--------|----------|----------|---------|
| 医療診断 | 疾患スクリーニング | 再現率 | 病気の患者を見逃すことは非常に重大な結果を招く |
| スパム検出 | メールフィルタリング | 適合率 | 本物のメールをスパムとしてマークすることは破壊的 |
| 不正検出 | 取引監視 | 再現率 | 不正を見逃すことはコストがかかる |
| 検索エンジン | 文書検索 | 両方 | ユーザーはすべての関連結果と少ない無関係な結果を望む |
| 画像認識 | 物体検出 | 文脈依存 | 見逃しまたは余分な検出のコストに依存 |

## 参考文献


1. Google. (n.d.). ML Crash Course: Accuracy, Precision, Recall. Google Developers.

2. EvidentlyAI. (n.d.). Accuracy vs Precision vs Recall. EvidentlyAI Blog.

3. EvidentlyAI. (n.d.). Confusion Matrix Explained. EvidentlyAI Blog.

4. EvidentlyAI. (n.d.). Classification Metrics Guide. EvidentlyAI Blog.

5. GeeksforGeeks. (n.d.). Precision and Recall in Machine Learning. GeeksforGeeks.

6. DeepAI. (n.d.). Precision and Recall. DeepAI Machine Learning Glossary.

7. DeepAI. (n.d.). ROC Curve. DeepAI Machine Learning Glossary.

8. BuiltIn. (n.d.). Precision and Recall. BuiltIn.

9. BuiltIn. (n.d.). F1 Score and Advanced Metrics. BuiltIn.

10. Lyzr. (n.d.). Glossary - Precision and Recall. Lyzr.

11. scikit-learn. (n.d.). Precision-Recall Curves. scikit-learn Documentation.

12. StatQuest. (n.d.). Precision and Recall Clearly Explained. YouTube.

13. Corey Schafer. (n.d.). Precision and Recall Explained. YouTube.
