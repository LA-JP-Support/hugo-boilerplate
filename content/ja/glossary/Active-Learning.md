---
title: アクティブラーニング
date: 2025-12-19
translationKey: active-learning
description: アクティブラーニングは、モデルが人間によるラベリングのために最も有益なデータポイントを戦略的に選択する機械学習アプローチです。インテリジェントなサンプリング戦略により、アノテーションコストを大幅に削減しながら、モデルの精度を向上させます。
keywords:
- アクティブラーニング
- 機械学習
- データラベリング
- ヒューマンインザループ
- モデルトレーニング
- 不確実性サンプリング
- クエリ戦略
- アノテーション効率
category: AI Chatbot & Automation
type: glossary
draft: false
e-title: Active Learning
url: /ja/glossary/active-learning/
aliases:
- /ja/glossary/Active-Learning/
term: アクティブラーニング
---

## アクティブラーニングとは?
アクティブラーニングは、機械学習における変革的なパラダイムであり、アルゴリズムが人間によるアノテーション(注釈付け)が必要なデータポイントを戦略的に選択することで、自身のトレーニングプロセスにおいて知的かつ積極的な役割を果たします。提供されたラベル付きデータを受動的に受け入れる従来の教師あり学習アプローチとは異なり、アクティブラーニングシステムは、ラベルなしデータプールから最も有益で、不確実性が高く、または代表的な例を特定するために、洗練されたクエリ戦略を採用します。これらの高価値データポイントに人間のラベリング作業を集中させることで、アクティブラーニングは、ラベル付き例を劇的に少なくしながら、同等またはそれ以上のモデル性能を達成します。多くの場合、ランダムサンプリングアプローチと比較して、アノテーション要件を50〜90%削減します。

アクティブラーニングを推進する基本的な洞察は、すべてのデータポイントがモデル改善に等しく貢献するわけではないということです。一部の例は、モデルがすでに自信を持って実行している特徴空間の十分に理解された領域にありますが、他の例は境界領域を占め、まれなエッジケースを表し、またはモデルの決定境界を大幅に洗練できる特性を示します。アクティブラーニングアルゴリズムは、不確実性サンプリング、委員会によるクエリ、期待されるモデル変更など、さまざまなクエリ戦略を採用して、これらの影響力の高い例を体系的に特定します。人間の専門家(アクティブラーニング文献では「オラクル」と呼ばれることが多い)は、これらの慎重に選択されたインスタンスにのみラベルを提供し、ラベル付き例あたりの学習を最大化する非常に効率的なトレーニングループを作成します。

このアプローチは、ラベリングコストが法外に高い、専門家の時間が不足している、またはラベルなしデータが利用可能なアノテーションを大幅に上回るドメインで特に価値があります。医療画像解析、法的文書レビュー、自然言語処理、コンピュータビジョン、不正検出、科学研究はすべて、アクティブラーニング手法から大きな恩恵を受けます。ラベリングリソースを最も有益な例に知的に割り当てることで、組織は従来のアプローチで必要とされるアノテーション予算のわずかな部分で高性能な機械学習システムを構築でき、リソースに制約のある環境での機械学習へのアクセスを民主化し、AIアプリケーションの開発サイクルを加速します。

## 主要概念

**クエリ戦略**  
次にラベル付けすべきラベルなし例を選択するための体系的な方法。不確実性サンプリングは、モデルが最も自信がないインスタンスを選択し、マージンサンプリングは決定境界近くの例をターゲットにし、エントロピーベースのアプローチは、すべてのクラスにわたって最大の予測不確実性を持つ例を選択します。

**不確実性サンプリング**  
最も一般的なアクティブラーニング戦略で、現在のモデルが最も高い予測不確実性を示すデータポイントを選択します。分類の場合、これは多くの場合、二値分類では0.5に最も近い確率を持つ例、または多クラスシナリオでは最大エントロピーを持つ例を選択することを意味します。

**委員会によるクエリ**  
同じデータでトレーニングされたモデルのアンサンブルを維持し、委員会メンバーが最も強く意見が分かれる例を選択します。高い不一致は、追加のトレーニングがモデルの合意に大きく貢献する特徴空間の領域を示します。

**期待されるモデル変更**  
ラベル付けされてトレーニングデータに追加されると、モデルパラメータに最大の変更を引き起こす例を選択します。この前向きな戦略は、どのラベルがモデルを最も劇的に改善するかを予測します。

**情報密度**  
予測の不確実性だけでなく、例がより広範なラベルなしデータセットをどれだけ代表しているかも考慮します。不確実な例の活用と特徴空間の多様な領域の探索のバランスを取ります。

**バッチモードアクティブラーニング**  
一度に1つの例をクエリする代わりに、例のバッチを同時に選択します。このアプローチは、本番システムにとってより実用的であり、バッチ内の冗長なクエリを避けるために多様性基準を組み込むことができます。

**ヒューマン・イン・ザ・ループ**  
選択された例に対して真のラベルを提供するオラクルまたは人間の専門家。アクティブラーニングは、効率的な人間とAIのコラボレーションに根本的に依存し、専門家の時間利用を最適化します。

**プールベース vs ストリームベース**  
プールベースのアクティブラーニングは、クエリを選択するためにラベルなしデータのプール全体を評価しますが、ストリームベースのアプローチは、個々の例が順次到着するときに即座に決定を下します。

## アクティブラーニングの仕組み

アクティブラーニングサイクルは、体系的で反復的なプロセスに従います:

**初期化**  
初期モデルをトレーニングするのに十分な少数のラベル付き例から始めます。このシードセットには、ランダムに選択された例、または特徴空間の主要領域をカバーする慎重にキュレーションされたインスタンスが含まれる場合があります。

**モデルトレーニング**  
現在利用可能なラベル付きデータで機械学習モデルをトレーニングします。このモデルは、ラベルなし例の予測と不確実性推定を提供することで、その後のクエリ選択をガイドします。

**クエリ選択**  
選択したクエリ戦略を適用して、プール内のすべてのラベルなし例を評価します。各例を、その有益性に応じてスコア付けします。通常、予測の不確実性、期待される情報利得、または潜在的なモデル改善に基づいています。

**オラクルラベリング**  
最高スコアの例を人間のオラクルに提示してラベリングします。オラクルは、専門知識に基づいて真のアノテーションを提供し、それがラベル付きトレーニングセットに追加されます。

**データセット更新**  
新しくラベル付けされた例をトレーニングセットに組み込み、ラベルなしプールから削除します。この拡張されたトレーニングセットには、クエリ戦略によって特定された最も有益なインスタンスが含まれるようになります。

**収束チェック**  
停止基準が満たされているかどうかを評価します。目標性能レベルの達成、ラベリング予算の使い果たし、または追加のクエリが最小限の改善しか提供しない収穫逓減に達したかどうかです。

**反復**  
停止基準が満たされていない場合は、拡張されたラベル付きデータセットでモデルを再トレーニングし、サイクルを繰り返します。各反復は、高価値の例でトレーニングセットを戦略的に成長させます。

**ワークフローの例:**  
医療画像システムは、100枚のラベル付きX線から始まります。トレーニング後、アクティブラーニングシステムは20の不確実なケース、つまり放射線科医が意見が分かれる画像や分類が決定境界近くにある画像を特定します。放射線科医がこれらの20のケースにラベルを付け、トレーニングセットを120の例に拡張します。モデルは再トレーニングされ、以前は不確実だった領域で大幅な精度向上を示します。このサイクルは、従来のアプローチが必要とする可能性のある5,000のランダムな例ではなく、おそらく500の慎重に選択された例で目標性能に達するまで繰り返されます。

## メリット

**ラベリングコストの削減**  
ランダムサンプリングと比較して、大幅に少ないラベル付き例で目標モデル性能を達成します。多くの場合、50〜90%の削減です。これは、専門家のラベリングが高価なドメインで大幅なコスト削減につながります。

**ラベル効率の向上**  
モデルの弱点や不確実性に最も直接的に対処するインスタンスに焦点を当てることで、ラベル付き例あたりに得られる情報を最大化します。すべてのラベリング作業がモデル改善に有意義に貢献します。

**開発の加速**  
専門家の時間を効率的に活用することで、本番環境対応のモデル性能により早く到達します。必要なラベルが少ないということは、ラベリングキャンペーンが短く、反復サイクルが速いことを意味します。

**専門家時間の最適化**  
明白または冗長な例に専門知識を浪費するのではなく、真に挑戦的または有益なケースに希少な専門家の注意を集中させます。これは、ドメイン専門家が高価または供給が限られている場合に特に価値があります。

**モデル性能の向上**  
決定境界とエッジケースに対処する戦略的に選択された例でトレーニングすることで、アクティブラーニングは、同じサイズのランダムに選択されたデータでトレーニングされたモデルよりも一般化が優れたモデルを生成することがよくあります。

**アノテーション疲労の軽減**  
興味深く挑戦的な例にラベルを付けることは、反復的で明白なケースをレビューするよりも、人間のアノテーターにとってより魅力的であることが証明されています。これにより、アノテーションの品質が向上し、アノテーターの燃え尽き症候群を軽減できます。

**大規模データセットへのスケーラビリティ**  
完全なアノテーションが不可能な大規模なラベルなしデータセットでの機械学習開発を可能にします。アクティブラーニングは、必要なラベルを劇的に削減することで、以前は扱いにくかった問題を実現可能にします。

**適応学習**  
モデルが進化するにつれて、クエリ戦略は残りの不確実性または弱点の領域に焦点を当てるように適応し、モデル知識の最も重要なギャップに自然に対処します。

## 一般的なユースケース

**医療画像解析**  
放射線科医は、アクティブラーニングアルゴリズムによって特定された最も診断的に挑戦的なX線、CTスキャン、またはMRIのみにラベルを付けます。このアプローチは、放射線科医の時間の希少性を尊重しながら、正確な疾患検出システムを構築します。

**自然言語処理**  
テキスト分類、固有表現認識、感情分析モデルは、アノテーションのために最も曖昧または代表的な文書を選択します。専門知識が必要なドメイン固有のテキストを処理する場合に特に価値があります。

**コンピュータビジョン**  
物体検出、画像セグメンテーション、視覚検査システムは、人間のアノテーションのために境界ケース、まれな物体タイプ、または異常な視角を特定します。自動運転車システムは、運転シナリオのエッジケースを特定するためにアクティブラーニングを使用します。

**不正検出**  
金融機関は、正当な活動と不正な活動の間の決定境界近くにある疑わしい取引にラベルを付けます。アクティブラーニングは、不正パターンが進化するにつれて正確なモデルを維持するのに役立ちます。

**法的文書レビュー**  
法律専門家は、アクティブラーニングシステムがケースに最も関連性が高い、または分類において最も不確実であると特定した文書のみをレビューします。これにより、訴訟とコンプライアンスにおける文書レビュー時間が劇的に削減されます。

**科学研究**  
科学者は、理解を最も進めるであろう実験結果、天文観測、またはゲノム配列にラベルを付けます。アクティブラーニングは、高価な実験リソースを最適化します。

**音声認識**  
言語学者は、挑戦的な音声特性、まれな単語、または地域のアクセントを示すオーディオサンプルのみを転写します。このアプローチは、多様な話者にわたって堅牢な音声認識を構築します。

**製薬創薬**  
化学者は、構造活性相関に関する情報利得を最大化するためにアクティブラーニングモデルによって選択された化合物をテストします。高価な合成とスクリーニングコストを削減します。

## クエリ戦略の比較

| 戦略 | 最適な用途 | 計算コスト | ラベル効率 |
|----------|----------|-------------------|------------------|
| **不確実性サンプリング** | 汎用、単一モデル | 低 | 高 |
| **委員会によるクエリ** | 多様なモデルアンサンブル | 中〜高 | 非常に高い |
| **期待されるモデル変更** | 勾配ベースモデル | 高 | 非常に高い |
| **情報密度** | 多様で代表的なカバレッジ | 中 | 高 |
| **バッチモード** | 本番システム、並列ラベリング | 中 | 高 |
| **多様性ベース** | 特徴空間の探索 | 中 | 中〜高 |

## 課題と考慮事項

**初期モデル品質**  
アクティブラーニングの効果は、合理的に有能な初期モデルから始めることに依存します。初期化が不十分だと、初期の間違いを強化する偏ったクエリ選択につながる可能性があります。

**オラクルノイズ**  
人間のラベラーは、特にアクティブラーニングがしばしば選択する真に困難な例で、エラーを犯します。オラクルノイズは、適切に管理されない場合、学習プロセスを誤った方向に導く可能性があります。

**計算コスト**  
大規模なラベルなしプール全体でクエリ戦略を評価することは、特に委員会によるクエリや期待されるモデル変更など、複数のモデル評価を必要とする方法では、計算コストが高くなる可能性があります。

**クラス不均衡**  
不確実性ベースの戦略は、マイノリティクラスまたは境界領域をオーバーサンプリングし、十分に表現されたクラスをアンダーサンプリングする可能性があり、トレーニングセットの不均衡を引き起こす可能性があります。

**停止基準**  
追加のクエリが収穫逓減を提供する時期、つまりアクティブラーニングサイクルをいつ停止するかを決定することは、明確な性能プラトーがなければ依然として困難です。

**クエリ戦略の選択**  
特定の問題に適したクエリ戦略を選択するには、計算コスト、ラベル効率、ドメイン特性間のトレードオフを理解する必要があります。

**バッチ選択の多様性**  
例のバッチを選択する場合、バッチ内の多様性を確保することで、非常に類似した例に対する冗長なクエリを防ぎます。

**モデル更新頻度**  
モデルを再トレーニングする頻度と計算コストおよびラベリングワークフローの実用性のバランスを取ることは、全体的なシステム効率に影響します。

## 実装のベストプラクティス

**品質の高いシードから始める**  
初期ラベル付きデータセットが主要なクラスをカバーし、最初のモデルに十分な基盤を提供することを確認します。初期ラベルの層別または目的的サンプリングは、不適切な開始点を防ぎます。

**適切なクエリ戦略を選択する**  
クエリ戦略を問題特性に合わせます。一般的な分類には不確実性サンプリング、複雑な決定境界には委員会によるクエリ、多様なカバレッジには情報密度を使用します。

**停止基準を実装する**  
明確な性能目標または予算制限を定義します。検証性能を監視して、追加のクエリからの収穫逓減を示すプラトーを検出します。

**オラクル品質を管理する**  
明確なラベリングガイドラインを提供し、例のサブセットでラベルを検証し、アノテーター間一致メトリクスを検討します。品質管理は、オラクルノイズが学習を脱線させるのを防ぎます。

**探索と活用のバランスを取る**  
不確実性ベースのクエリ(モデルの弱点の活用)と多様性ベースの選択(特徴空間の探索)を組み合わせて、包括的なカバレッジを確保します。

**バッチ選択を最適化する**  
バッチにラベルを付ける場合、バッチ内の多様性を確保して、冗長なクエリを避けます。不確実性測定と並んでクラスタリングまたは多様性基準を使用します。

**クラスバランスを監視する**  
アクティブに選択された例のクラス分布を追跡します。特定のクラスがトレーニングデータで過小表現されている場合は、再バランス戦略を実装します。

**定期的に検証する**  
真のモデル性能を追跡するために、別の検証セットを維持します。これにより、アクティブに選択されたトレーニング分布への過学習を防ぎます。

**クエリ決定を文書化する**  
どの例が選択され、その理由を記録し、アクティブラーニングプロセスの監査証跡を作成し、クエリ戦略の効果の遡及的分析を可能にします。

**スケールを計画する**  
成長するデータセットと進化するモデルを処理するためのアクティブラーニングパイプラインを設計します。スケールでのクエリ評価の計算要件を検討します。

## アクティブラーニング vs 従来の教師あり学習

| 側面 | 従来の教師あり | アクティブラーニング |
|--------|----------------------|----------------|
| **データ選択** | ランダムまたは網羅的 | 戦略的、モデルガイド |
| **ラベリング効率** | 多くの明白な例にラベルを付ける | 有益な例に焦点を当てる |
| **開発速度** | 大規模データセットでは遅い | 目標性能により速く |
| **コスト** | データセットサイズに対して線形 | 準線形、多くの場合50〜90%削減 |
| **モデル性能** | データ量に依存 | 少ないラベルでしばしば優れている |
| **専門家の活用** | 簡単なケースでしばしば無駄 | 希少な専門家時間を最適化 |
| **実装** | よりシンプル、クエリ戦略なし | より複雑、オラクルが必要 |
| **スケーラビリティ** | ラベリング予算によって制限 | 大規模データセットでの学習を可能にする |

## 今後の方向性

**ディープアクティブラーニング**  
アクティブラーニングとディープニューラルネットワークの組み合わせは、モデルの複雑さとトレーニングの不安定性のために課題を提示しますが、tremendous potentialを提供します。研究は、ディープモデルにおける不確実性推定と高次元特徴空間の効率的なクエリ戦略に焦点を当てています。

**人間とAIのコラボレーション**  
次世代システムは、アノテーターの専門知識、自信、認知負荷をよりよくモデル化し、どの例をクエリするかだけでなく、いつどのように提示するかを最適化して、最大のラベリング品質とアノテーターの生産性を実現します。

**自動クエリ戦略選択**  
問題特性に基づいてクエリ戦略を自動的に選択または適応させるメタ学習アプローチが登場しており、手動の戦略選択と調整の必要性を排除します。

**アクティブ少数ショット学習**  
アクティブラーニングと少数ショット学習パラダイムを組み合わせることで、最小限のラベル付きデータで新しいタスクまたはドメインへの迅速な適応が可能になり、継続的に進化するアプリケーションで特に価値があります。

**説明駆動型アクティブラーニング**  
将来のシステムは、特定の例がラベリングのために選択された理由を説明し、オラクルがモデルの弱点を理解し、より良いコンテキストを通じてラベル品質を向上させる可能性があります。

## 参考文献

- [Active Learning Literature Survey - Burr Settles](http://burrsettles.com/pub/settles.activelearning.pdf)
- [Active Learning - Machine Learning Mastery](https://machinelearningmastery.com/what-is-active-learning/)
- [Active Learning with Python - Towards Data Science](https://towardsdatascience.com/active-learning-in-machine-learning-525e61be16e5)
- [The Power of Active Learning in ML - Google Research](https://research.google/pubs/pub45390/)
- [Active Learning Strategies - Papers with Code](https://paperswithcode.com/task/active-learning)
- [Active Learning in Practice - arXiv](https://arxiv.org/abs/2007.15555)