<!DOCTYPE html>
<html dir="ltr" lang="en">
<head>
<meta content="strict-origin-when-cross-origin" name="referrer"/>
<meta charset="utf-8"/>
<meta content="minimum-scale=1, width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport"/>
<title>Speech-to-Text Node | SmartWeb</title>
<link href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/speech-to-text-node/" rel="canonical"/>
<link href="/images/faivicon.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="/images/faivicon.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="/images/faivicon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="/images/faivicon.png" rel="shortcut icon"/>
<link href="%!s(&lt;nil&gt;)/glossary/Speech-to-Text-Node/" hreflang="en" rel="alternate"/>
<link href="%!s(&lt;nil&gt;)/ja/glossary/Speech-to-Text-Node/" hreflang="ja" rel="alternate"/>
<link href="%!s(&lt;nil&gt;)/glossary/Speech-to-Text-Node/" hreflang="x-default" rel="alternate"/>
<meta content="A Speech-to-Text Node converts spoken words from audio files into written text, enabling voice commands, meeting transcriptions, and automated voice-based processes." name="description"/>
<meta content="Speech-to-Text Node, Automatic Speech Recognition, AI workflows, Audio to Text, Transcription" name="keywords"/>
<meta content="website" property="og:type"/>
<meta content="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/speech-to-text-node/" property="og:url"/>
<meta content="Speech-to-Text Node | SmartWeb" property="og:title"/>
<meta content="A Speech-to-Text Node converts spoken words from audio files into written text, enabling voice commands, meeting transcriptions, and automated voice-based processes." property="og:description"/>
<meta content="" property="og:image"/>
<meta content="1200" property="og:image:width"/>
<meta content="630" property="og:image:height"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/speech-to-text-node/" name="twitter:url"/>
<meta content="Speech-to-Text Node | SmartWeb" name="twitter:title"/>
<meta content="A Speech-to-Text Node converts spoken words from audio files into written text, enabling voice commands, meeting transcriptions, and automated voice-based processes." name="twitter:description"/>
<meta content="" name="twitter:image"/>
<style>
  :root {
     
    --color-primary: #1a73e8;
    --color-primary-light: #4285f4;
    --color-primary-dark: #1557b0;

    --color-secondary: #34a853;
    --color-accent: #fbbc05;

    --color-text: #202124;
    --color-background: #ffffff;

     
    --gradient-primary: linear-gradient(to right, var(--color-primary), var(--color-primary-light));
  }

   
  .bg-gradient-primary {
    background-image: var(--gradient-primary);
  }

  .text-gradient,
  .text-gradient-primary {
    background-image: var(--gradient-primary);
    background-clip: text;
    -webkit-background-clip: text;
    color: transparent;
    -webkit-text-fill-color: transparent;
  }
</style>
<link as="font" crossorigin="anonymous" href="/fonts/inter/Inter-VariableFont_opsz,wght.woff2" rel="preload" type="font/woff2"/>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;500;700&amp;family=Noto+Serif+JP:wght@400;500;600;700&amp;display=swap" rel="stylesheet"/>
<link crossorigin="anonymous" href="/css/main.css?v=20260111165525" rel="stylesheet"/>
<link crossorigin="anonymous" href="/css/custom-code-blockquote.css?v=20260111165525" rel="stylesheet"/>
<link href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" rel="stylesheet"/>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
<script defer="" src="/js/main.js?v=20260111165525"></script>
</head>
<body class="antialiased bg-white">
<header class="bg-white">
<nav aria-label="Global" class="mx-auto flex max-w-7xl items-center justify-between gap-x-6 p-6 lg:px-8">
<div class="flex lg:flex-1">
<a class="-m-1.5 p-1.5" href="/en/">
<span class="sr-only">SmartWeb</span>
<picture class="lazy-picture" data-maxwidth="200">
<source data-original-src="/images/smartweb-logo.png" data-srcset="/images/smartweb-logo.png 466w" sizes="200px" type="image/png">
<img alt="SmartWeb Logo" class="lazy-image h-6 sm:h-10 md:h-12 w-auto" data-original-src="/images/smartweb-logo.png" data-src="/images/smartweb-logo.png" decoding="async" loading="lazy"/>
</source></picture>
</a>
</div>
<div class="hidden lg:flex lg:gap-x-12"><a class="text-sm/6 font-semibold text-gray-900" href="/en/">Home</a><a class="text-sm/6 font-semibold text-gray-900" href="/en/blog/">Blog</a><a class="text-sm/6 font-semibold text-gray-900" href="/en/glossary/">Glossary</a><a class="text-sm/6 font-semibold text-gray-900" href="https://www.intwk.co.jp/about/">Company</a></div>
<div class="flex flex-1 items-center justify-end gap-x-6">
<a class="hidden text-sm/6 font-semibold text-gray-900 lg:block" href="https://support.smartweb.jp/">Support</a>
<a class="rounded-md bg-indigo-600 px-3 py-2 text-sm font-semibold text-white shadow-xs hover:bg-indigo-500 focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-indigo-600" href="/en/blog/">Get Started</a>
</div>
<div class="flex lg:hidden">
<button aria-controls="mobile-menu-1768118125587168000" aria-expanded="false" class="-m-2.5 inline-flex items-center justify-center rounded-xl p-2.5 text-gray-700" type="button">
<span class="sr-only">Open main menu</span>
<svg aria-hidden="true" class="size-6" data-slot="icon" fill="none" stroke="currentColor" stroke-width="1.5" viewbox="0 0 24 24">
<path d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
</svg>
</button>
</div>
</nav>
<div aria-modal="true" class="lg:hidden hidden relative z-50" id="mobile-menu-1768118125587168000" role="dialog">
<div class="fixed inset-0 z-50 bg-black bg-opacity-25"></div>
<div class="fixed inset-y-0 right-0 z-50 w-full overflow-y-auto bg-white px-6 py-6 sm:max-w-sm sm:ring-1 sm:ring-gray-900/10 transform transition-transform duration-300 ease-in-out translate-x-full">
<div class="flex items-center gap-x-6">
<a class="-m-1.5 p-1.5" href="/en/">
<span class="sr-only">SmartWeb</span>
<picture class="lazy-picture" data-maxwidth="3000">
<source data-original-src="/images/smartweb-logo.png" data-srcset="/images/smartweb-logo.png 466w" sizes="(max-width: 466px) 466px, 3000px" type="image/png">
<img alt="SmartWeb Logo" class="lazy-image h-6 sm:h-10 md:h-12 w-auto" data-original-src="/images/smartweb-logo.png" data-src="/images/smartweb-logo.png" decoding="async" loading="lazy"/>
</source></picture>
</a>
<a class="ml-auto rounded-md bg-indigo-600 px-3 py-2 text-sm font-semibold text-white shadow-xs hover:bg-indigo-500 focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-indigo-600" href="/en/blog/">Get Started</a>
<button class="-m-2.5 rounded-xl p-2.5 text-gray-700 close-mobile-menu" type="button">
<span class="sr-only">Close menu</span>
<svg aria-hidden="true" class="size-6" data-slot="icon" fill="none" stroke="currentColor" stroke-width="1.5" viewbox="0 0 24 24">
<path d="M6 18 18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
</svg>
</button>
</div>
<div class="mt-6 flow-root">
<div class="-my-6 divide-y divide-gray-500/10">
<div class="space-y-2 py-6"><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="/en/">Home</a><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="/en/blog/">Blog</a><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="/en/glossary/">Glossary</a><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="https://www.intwk.co.jp/about/">Company</a></div>
<div class="py-6">
<a class="-mx-3 block rounded-lg px-3 py-2.5 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="https://support.smartweb.jp/">Support</a>
</div>
</div>
</div>
</div>
</div>
</header>
<script>
  document.addEventListener('DOMContentLoaded', function() {
    const mobileMenuButton = document.querySelector('[aria-controls="mobile-menu-1768118125587168000"]');
    const mobileMenu = document.getElementById('mobile-menu-1768118125587168000');
    const closeButtons = document.querySelectorAll('.close-mobile-menu');
    const mobileMenuContent = mobileMenu.querySelector('.fixed.inset-y-0');
    
    if (mobileMenuButton && mobileMenu) {
      mobileMenuButton.addEventListener('click', function() {
        const expanded = mobileMenuButton.getAttribute('aria-expanded') === 'true';
        
        if (expanded) {
          closeMobileMenu();
        } else {
          openMobileMenu();
        }
      });
      
      
      closeButtons.forEach(button => {
        button.addEventListener('click', closeMobileMenu);
      });
      
      
      mobileMenu.addEventListener('click', function(event) {
        if (event.target === mobileMenu) {
          closeMobileMenu();
        }
      });
      
      
      mobileMenuContent.addEventListener('click', function(event) {
        event.stopPropagation();
      });
      
      function openMobileMenu() {
        mobileMenuButton.setAttribute('aria-expanded', 'true');
        mobileMenu.classList.remove('hidden');
        
        
        mobileMenuContent.offsetHeight;
        
        mobileMenuContent.classList.remove('translate-x-full');
        document.body.classList.add('overflow-hidden');
      }
      
      function closeMobileMenu() {
        mobileMenuButton.setAttribute('aria-expanded', 'false');
        mobileMenuContent.classList.add('translate-x-full');
        
        
        setTimeout(() => {
          mobileMenu.classList.add('hidden');
          document.body.classList.remove('overflow-hidden');
        }, 300);
      }
    }
  });
</script>
<main class="w-full">
<article class="mx-auto max-w-5xl px-4 sm:px-6 lg:px-8">
<header class="py-12 sm:py-16">
<div class="mx-auto max-w-4xl">
<div class="mb-8">
<nav class="text-sm hidden sm:block">
<ol class="flex items-center space-x-2 text-gray-400 dark:text-gray-500">
<li class="flex items-center">
<a class="hover:text-gray-900 dark:hover:text-gray-300 transition-colors flex items-center" href="/en/">
<img alt="Home" class="h-4 w-4 opacity-60" src="/images/home-icon.png"/>
</a>
</li>
<li><span class="mx-2 text-gray-300 dark:text-gray-600">/</span></li>
<li>
<a class="hover:text-gray-900 dark:hover:text-gray-300 transition-colors" href="/en/glossary/">
                Glossary
              </a>
</li>
<li><span class="mx-2 text-gray-300 dark:text-gray-600">/</span></li>
<li class="text-gray-600 dark:text-gray-400 truncate max-w-xs">Speech-to-Text Node</li>
</ol>
</nav>
</div>
<div class="mb-6">
<span class="inline-flex items-center text-xs font-medium tracking-wider uppercase text-gray-500 dark:text-gray-400 border-b border-gray-300 dark:border-gray-600 pb-1">
<svg class="mr-2 h-3.5 w-3.5" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M7 7h.01M7 3h5c.512 0 1.024.195 1.414.586l7 7a2 2 0 010 2.828l-7 7a2 2 0 01-2.828 0l-7-7A1.994 1.994 0 013 12V7a4 4 0 014-4z" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
            AI Chatbot &amp; Automation
          </span>
</div>
<h1 class="text-2xl font-bold tracking-tight text-gray-900 dark:text-white sm:text-3xl md:text-4xl leading-tight mb-2">
        Speech-to-Text Node
      </h1>
<div class="mb-6"></div>
<p class="text-base sm:text-lg leading-relaxed text-gray-600 dark:text-gray-300 font-light max-w-3xl">
          A Speech-to-Text Node converts spoken words from audio files into written text, enabling voice commands, meeting transcriptions, and automated voice-based processes.
        </p>
<div class="mt-6 mb-4 border-t border-gray-100 dark:border-gray-800"></div>
<div class="flex flex-col sm:flex-row sm:items-center sm:justify-between gap-4">
<div class="flex flex-wrap gap-2">
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                Speech-to-Text Node
              </span>
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                Automatic Speech Recognition
              </span>
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                AI workflows
              </span>
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                Audio to Text
              </span>
<span class="inline-flex items-center px-2.5 py-1 text-xs font-medium text-gray-600 dark:text-gray-400 bg-transparent border border-gray-200 dark:border-gray-700 rounded hover:border-gray-400 dark:hover:border-gray-500 transition-colors">
                Transcription
              </span>
</div>
<div class="text-sm text-gray-500 dark:text-gray-400 flex flex-col items-end gap-y-1 text-right">
<span class="inline-flex items-center justify-end">
<svg class="mr-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M8 7V5a3 3 0 013-3h2a3 3 0 013 3v2m4 0h-16a2 2 0 00-2 2v9a2 2 0 002 2h16a2 2 0 002-2V9a2 2 0 00-2-2z" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
      
        Created: December 18, 2025
      
    </span>
</div>
</div>
</div>
</header>
<div class="prose prose-base sm:prose-lg dark:prose-invert mx-auto max-w-4xl py-6 sm:py-8">
<h2 id="what-is-a-speech-to-text-node">What is a Speech-to-Text Node?</h2>
<p>A Speech-to-Text Node is a foundational component in <a data-lb="1" href="/en/glossary/conversational-ai/" title="Conversational AI glossary entry">conversational AI</a>, automation pipelines, and workflow systems that converts spoken language in audio files—voice recordings, calls, or video soundtracks—into accurate, structured text. This transcription enables downstream analysis, summarization, translation, or automated process triggering, making it essential for voice-enabled applications and knowledge management systems.</p>
<p>The node functions as a modular workflow component that receives audio input, processes it through an Automatic <a data-lb="1" href="/en/glossary/speech-recognition/" title="Speech Recognition glossary entry">Speech Recognition</a> (ASR) model, and outputs a transcript. This transcript can optionally include word-level timestamps, speaker labels, translations, or structured metadata for further processing.</p>
<p>Typical Workflow:1. Audio input received (file upload, URL, or workflow variable)
2. Processing via ASR model (<a data-lb="1" href="/en/glossary/openai/" title="OpenAI glossary entry">OpenAI</a> Whisper, Google Speech-to-Text, Azure Speech, Rev AI)
3. Output transcript with optional metadata (timestamps, speaker labels, translations)</p>
<p>Role in Automation:- Enables chatbots to process voice queries</p>
<ul>
<li>Transcribes meetings, interviews, and lectures for knowledge management</li>
<li>Automates content indexing and data extraction from voice interactions</li>
</ul>
<h2 id="key-capabilities">Key Capabilities</h2>
<p>Automatic Speech Recognition (ASR)Converts audio to text using advanced models with high accuracy across diverse accents and audio conditions.Multilingual SupportTranscribes speech in 50-125+ languages and dialects, depending on provider. Major models support global language coverage for international deployments.TranslationTranslates non-English speech into English or other supported languages in a single processing step, eliminating the need for separate translation workflows.Custom Prompt InstructionsAccepts natural language instructions for transcription style, speaker labeling, terminology preferences, or error handling approaches.Flexible Audio InputAccepts file uploads, URLs, or variables from previous workflow steps, supporting diverse integration patterns.Large File HandlingProcesses files up to provider-specific limits (typically 25 MB), with guidance on segmenting larger files at logical boundaries.Timestamps &amp; Speaker DiarizationOptionally includes word-level or <a data-lb="1" href="/en/glossary/utterance/" title="Utterance glossary entry">utterance</a>-level timing and identifies individual speakers in multi-party conversations.Profanity FilteringRemoves or masks offensive content according to configuration or model defaults.Custom Vocabulary &amp; Model AdaptationImproves recognition of domain-specific terms through vocabulary lists and model fine-tuning.Structured Output (JSON)Returns data in schemas suitable for downstream processing, including nested metadata.</p>
<h2 id="how-speech-to-text-nodes-work">How Speech-to-Text Nodes Work</h2>
<h3 id="audio-input">Audio Input</h3>
<p>The node receives an audio file or URL from user upload, cloud storage, or a previous workflow step. Supported formats typically include MP3, WAV, MP4, M4A, WebM, MPGA, and MPEG.</p>
<h3 id="model-selection--preprocessing">Model Selection &amp; Preprocessing</h3>
<p>Choose ASR Provider:Select from OpenAI Whisper, Google Speech-to-Text, Azure Speech Service, AssemblyAI, Deepgram, or other providers.Configure Features:Enable language detection, translation, timestamps, speaker identification, and custom <a data-lb="1" href="/en/glossary/prompts/" title="Prompts glossary entry">prompts</a>.</p>
<h3 id="transcription-process">Transcription Process</h3>
<p>The ASR engine processes the audio, applying acoustic and language models to generate text. Optional features like translation, profanity filtering, formatting, and diarization are applied during or after transcription.</p>
<h3 id="output-handling">Output Handling</h3>
<p>The node outputs the transcript in plain text or structured JSON format. Downstream workflow steps consume this output for summarization, analysis, storage, or user feedback.</p>
<h2 id="supported-audio-formats--file-limits">Supported Audio Formats &amp; File Limits</h2>
<p>Audio Formats:- M4A, MP3, WebM, MP4, MPGA, WAV, MPEG</p>
<ul>
<li>Provider support varies; verify compatibility with your chosen ASR service</li>
</ul>
<p>File Size Limits:- Typical maximum: 25 MB per file</p>
<ul>
<li>Larger files must be split into segments ≤25 MB</li>
<li>Segment at logical sentence boundaries to preserve context and accuracy</li>
</ul>
<p>Input Methods:- Direct file upload</p>
<ul>
<li>URL reference to hosted audio</li>
<li>Variable reference from previous workflow steps</li>
</ul>
<p>Some platforms accept only URLs for security and scalability reasons.</p>
<h2 id="configuration-guide">Configuration Guide</h2>
<h3 id="prerequisites">Prerequisites</h3>
<ul>
<li>Access to <a data-lb="1" href="/en/glossary/automation-platform/" title="Automation Platform glossary entry">automation platform</a> (Kore.ai, LiveKit, Google Cloud, Azure)</li>
<li>API key or integration credentials (if required)</li>
<li>Audio files hosted at accessible URLs or available for upload</li>
</ul>
<h3 id="step-by-step-configuration">Step-by-Step Configuration</h3>
<ol>
<li>Add Node to WorkflowOpen your automation builder and drag the Speech-to-Text or Audio to Text node into your workflow.2. Configure Node Properties-Node Name:Assign unique, descriptive name (e.g., “MeetingTranscription”)</li>
</ol>
<ul>
<li>Audio File Input:Reference variable holding audio URL</li>
<li>Model Selection:Choose ASR provider and specific model</li>
<li>Feature Toggles:Enable translation, timestamps, speaker diarization, profanity filtering3. Set Custom Prompt InstructionsDefine transcription style, speaker labeling requirements, terminology preferences, or error handling approaches in natural language.</li>
</ul>
<p>Example:</p>
<pre tabindex="0"><code>Provide a clean transcript, omitting filler words, with clear speaker labels and correct technical terms.
</code></pre><ol start="4">
<li>Define JSON Schema for Output (Optional)Specify structured output schema for downstream processing:</li>
</ol>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="font-weight:bold">"type"</span>: <span style="color:#0ff;font-weight:bold">"object"</span>,
</span></span><span style="display:flex;"><span>  <span style="font-weight:bold">"properties"</span>: {
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">"transcript"</span>: {<span style="font-weight:bold">"type"</span>: <span style="color:#0ff;font-weight:bold">"string"</span>},
</span></span><span style="display:flex;"><span>    <span style="font-weight:bold">"timestamps"</span>: {
</span></span><span style="display:flex;"><span>      <span style="font-weight:bold">"type"</span>: <span style="color:#0ff;font-weight:bold">"array"</span>,
</span></span><span style="display:flex;"><span>      <span style="font-weight:bold">"items"</span>: {
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold">"type"</span>: <span style="color:#0ff;font-weight:bold">"object"</span>,
</span></span><span style="display:flex;"><span>        <span style="font-weight:bold">"properties"</span>: {
</span></span><span style="display:flex;"><span>          <span style="font-weight:bold">"word"</span>: {<span style="font-weight:bold">"type"</span>: <span style="color:#0ff;font-weight:bold">"string"</span>},
</span></span><span style="display:flex;"><span>          <span style="font-weight:bold">"start"</span>: {<span style="font-weight:bold">"type"</span>: <span style="color:#0ff;font-weight:bold">"number"</span>},
</span></span><span style="display:flex;"><span>          <span style="font-weight:bold">"end"</span>: {<span style="font-weight:bold">"type"</span>: <span style="color:#0ff;font-weight:bold">"number"</span>}
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>      }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><ol start="5">
<li>Connect Success &amp; Failure Paths-On Success:Route to summarization, translation, or analysis nodes</li>
</ol>
<ul>
<li>On Failure:Route to error handling or fallback nodes6. Test and ValidateRun workflow with sample inputs, review output for completeness and correctness, and adjust configuration as needed.</li>
</ul>
<h2 id="configuration-parameters">Configuration Parameters</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Description</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Audio Input</td>
<td>URL or reference to uploaded audio file</td>
<td><code>https://host/path/audio.mp3</code></td>
</tr>
<tr>
<td>Model</td>
<td>ASR engine/model to use</td>
<td><code>OpenAI Whisper-1</code>, <code>Chirp 3</code></td>
</tr>
<tr>
<td>Language Code</td>
<td>Language for transcription (BCP-47)</td>
<td><code>en-US</code>, <code>fr-FR</code></td>
</tr>
<tr>
<td>Translation</td>
<td>Enable translation to English</td>
<td><code>true</code> / <code>false</code></td>
</tr>
<tr>
<td>Timestamps</td>
<td>Include word/utterance-level timestamps</td>
<td><code>true</code> / <code>false</code></td>
</tr>
<tr>
<td>Speaker Labels</td>
<td>Diarization, label speakers in multi-party audio</td>
<td><code>true</code> / <code>false</code></td>
</tr>
<tr>
<td>Profanity Filter</td>
<td>Remove or mask offensive words</td>
<td><code>true</code> / <code>false</code></td>
</tr>
<tr>
<td>Prompt</td>
<td>Custom instructions for transcription style</td>
<td>See above</td>
</tr>
<tr>
<td>JSON Schema</td>
<td>Structured output for downstream processing</td>
<td>See above</td>
</tr>
<tr>
<td>Custom Vocab</td>
<td>Domain-specific words to <a data-lb="1" href="/en/glossary/bias/" title="Bias glossary entry">bias</a> recognition</td>
<td><code>["AcmeCorp", "API Gateway"]</code></td>
</tr>
<tr>
<td>Input Variable</td>
<td>Context variable holding input audio file</td>
<td><code>{{context.steps.Start.AudioURL}}</code></td>
</tr>
</tbody>
</table>
<h2 id="response-formats--output">Response Formats &amp; Output</h2>
<p>Plain Text Output:Default transcript as continuous text string.Structured JSON Output:Includes transcript, timestamps, speaker labels, and confidence scores.Example:```json
{
“transcript”: “Hello, thank you for calling AcmeCorp. How may I assist you today?”,
“timestamps”: [
{ “word”: “Hello”, “start”: 0.0, “end”: 0.5 },
{ “word”: “thank”, “start”: 0.6, “end”: 0.8 }
],
“speakers”: [
{ “segment”: “Customer”, “start”: 0.0, “end”: 3.0 }
]
}</p>
<pre tabindex="0"><code class="language-**Advanced" data-lang="**Advanced">
## Common Use Cases

**Meeting and Lecture Transcription**Transcribe meetings, interviews, or lectures into searchable, indexable text for knowledge management and compliance.**Customer Support Automation**Transcribe voice interactions for chatbots, CRM systems, and help desk platforms to enable automated routing and analysis.**Subtitle and Caption Generation**Generate subtitles for video content with timestamp alignment for accessibility and localization.**Voice Command Processing**Convert spoken commands into actionable text for voice-enabled applications and smart devices.**Audio-Based Translation**Transcribe and translate multilingual audio in a single step for localization and accessibility.**Healthcare Documentation**Convert medical dictations and consultations into patient records with specialized medical vocabulary support.**Call Center Analysis**Transcribe recorded calls for quality assurance, compliance monitoring, and performance analytics.**Market Research**Transcribe focus group or interview recordings for thematic analysis and reporting.

## Integration Best Practices

**Use Context Variables**Reference audio URLs or data dynamically to support flexible workflow design and reusability.**Employ Prompt Engineering**Tailor instructions for speaker labeling, terminology, or formatting to improve accuracy for specific use cases.**Implement Batch Processing**For large volumes, utilize batch or asynchronous modes to optimize resource usage and reduce processing time.**Preprocess Audio Quality**Ensure clear audio, minimal background noise, and compatible format before processing to maximize transcription accuracy.**Segment Files Strategically**Split long recordings at logical breaks (sentence boundaries, speaker changes) to maintain context when approaching size limits.**Provide Custom Vocabulary**Submit domain-specific term lists to improve recognition of technical jargon, product names, or industry terminology.**Configure Compliance Features**Enable profanity filtering and select appropriate data residency options to meet regulatory requirements.

## Error Handling &amp; Monitoring

### Error Types

- Unsupported file format or exceeded size limits
- Invalid or inaccessible audio URLs
- Model selection or configuration errors
- Output schema mismatches

### Error Handling Strategies

- Validate input format and size before processing
- Implement retry logic with exponential backoff
- Design fallback flows for critical workflows
- Log errors with detailed context for troubleshooting

### Performance Metrics

- Minutes of audio processed (for cost/usage tracking)
- Token usage (for LLM-enabled ASR systems)
- Response times and throughput
- Error rates by error type

## Provider Comparison

| Provider | Key Features | Languages | Notes |
|----------|-------------|-----------|-------|
| **OpenAI Whisper**| Multilingual, translation, robust ASR, profanity filtering | 50+ | Best for general-purpose transcription |
| **Google Speech-to-Text**| 125+ languages, streaming &amp; batch, diarization, adaptation | 125+ | Strong enterprise features |
| **Azure Speech**| Real-time/batch, custom models, industry adaptation | 100+ | Deep Microsoft ecosystem integration |
| **Rev AI**| Asynchronous &amp; streaming, human and machine transcription | 58+ | Hybrid human/AI options |
| **LiveKit**| Pluggable models (AssemblyAI, Cartesia, Deepgram) | Model-dependent | Flexible for real-time applications |
| **VectorShift**| Node-based pipelines, LLM integration | Provider-dependent | Best for complex workflows |

## Implementation Examples

### Example 1: Meeting Transcription (Kore.ai)

**Prompt:**"Use direct speech and highlight problem or challenge-related vocabulary."**Input:**```json
{
  "audioFile": "https://example.com/meeting-2024-06-10.mp3"
}
```**Output:**```
Speaker 1: We're experiencing recurring issues with our API gateway.
Speaker 2: The main challenge is integrating external authentication.
</code></pre><h3 id="example-2-google-speech-to-text-api-nodejs">Example 2: Google Speech-to-Text API (Node.js)</h3>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-javascript" data-lang="javascript"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">const</span> speech = require(<span style="color:#0ff;font-weight:bold">'@google-cloud/speech'</span>);
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">const</span> client = <span style="color:#fff;font-weight:bold">new</span> speech.SpeechClient();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">async</span> <span style="color:#fff;font-weight:bold">function</span> transcribe() {
</span></span><span style="display:flex;"><span>  <span style="color:#fff;font-weight:bold">const</span> audio = { uri: <span style="color:#0ff;font-weight:bold">'gs://cloud-samples-data/speech/brooklyn_bridge.raw'</span> };
</span></span><span style="display:flex;"><span>  <span style="color:#fff;font-weight:bold">const</span> config = { 
</span></span><span style="display:flex;"><span>    encoding: <span style="color:#0ff;font-weight:bold">'LINEAR16'</span>, 
</span></span><span style="display:flex;"><span>    sampleRateHertz: <span style="color:#ff0;font-weight:bold">16000</span>, 
</span></span><span style="display:flex;"><span>    languageCode: <span style="color:#0ff;font-weight:bold">'en-US'</span> 
</span></span><span style="display:flex;"><span>  };
</span></span><span style="display:flex;"><span>  <span style="color:#fff;font-weight:bold">const</span> request = { audio, config };
</span></span><span style="display:flex;"><span>  <span style="color:#fff;font-weight:bold">const</span> [response] = <span style="color:#fff;font-weight:bold">await</span> client.recognize(request);
</span></span><span style="display:flex;"><span>  <span style="color:#fff;font-weight:bold">const</span> transcription = response.results
</span></span><span style="display:flex;"><span>    .map(r =&gt; r.alternatives[<span style="color:#ff0;font-weight:bold">0</span>].transcript)
</span></span><span style="display:flex;"><span>    .join(<span style="color:#0ff;font-weight:bold">'\n'</span>);
</span></span><span style="display:flex;"><span>  console.log(<span style="color:#0ff;font-weight:bold">`Transcription: </span><span style="color:#0ff;font-weight:bold">${</span>transcription<span style="color:#0ff;font-weight:bold">}</span><span style="color:#0ff;font-weight:bold">`</span>);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>transcribe();
</span></span></code></pre></div><h3 id="example-3-livekit-stt-model-python">Example 3: LiveKit STT Model (Python)</h3>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;" tabindex="0"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#fff;font-weight:bold">from</span> livekit.agents <span style="color:#fff;font-weight:bold">import</span> AgentSession
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>session = AgentSession(
</span></span><span style="display:flex;"><span>    stt=<span style="color:#0ff;font-weight:bold">"assemblyai/universal-streaming:en"</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#007f7f"># ... llm, tts, etc.</span>
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h2 id="technical-considerations">Technical Considerations</h2>
<p>**Token Limits:**Some ASR models have input token limits (e.g., Whisper: 224 tokens). Plan segmentation strategies for long-form content.**Edge Audio Cases:**For files near size limits, segment at logical boundaries and maintain sentence integrity when splitting.**Profanity and Content Filtering:**Removal may be default for some models; verify configuration options for your use case.**Speaker Diarization:**Not universally supported across all providers—verify availability and accuracy for multi-speaker scenarios.**Real-Time vs Batch:**Choose between streaming (real-time) and <a data-lb="1" href="/en/glossary/batch-processing/" title="Batch Processing glossary entry">batch processing</a> based on <a data-lb="1" href="/en/glossary/latency/" title="Latency glossary entry">latency</a> requirements and cost optimization.</p>
<h2 id="references">References</h2>
<ol>
<li>Kore.ai. (n.d.). Audio to Text Node Documentation. Kore.ai Documentation.</li>
<li>OpenAI. (n.d.). Whisper Documentation. OpenAI Platform.</li>
<li>Google Cloud. (n.d.). Speech-to-Text. Google Cloud Documentation.</li>
<li>Google Cloud. (n.d.). Speech-to-Text Supported Languages. Google Cloud Documentation.</li>
<li>Google Cloud. (n.d.). Speech-to-Text Encoding. Google Cloud Documentation.</li>
<li>Google Cloud. (n.d.). Speech-to-Text Adaptation. Google Cloud Documentation.</li>
<li>Google Cloud. (n.d.). Cloud <a data-lb="1" href="/en/glossary/monitoring/" title="Monitoring glossary entry">Monitoring</a>. Google Cloud Documentation.</li>
<li>Microsoft. (n.d.). Azure Speech Service Overview. Microsoft Learn.</li>
<li>Microsoft. (n.d.). Azure Batch Transcription. Microsoft Learn.</li>
<li>Rev AI. Speech-to-Text Service. URL: <a href="https://www.rev.ai/" rel="nofollow noopener noreferrer" target="_blank">https://www.rev.ai/</a></li>
<li>LiveKit. (n.d.). STT Documentation. LiveKit Documentation.</li>
<li>LiveKit. (n.d.). STT Inference. LiveKit Documentation.</li>
<li>LiveKit. (n.d.). STT Plugins. LiveKit Documentation.</li>
<li>LiveKit. (n.d.). STT Usage. LiveKit Documentation.</li>
<li>LiveKit. (n.d.). STT Additional Parameters. LiveKit Documentation.</li>
<li>VectorShift. (n.d.). Speech-to-Text Documentation. VectorShift Documentation.</li>
<li>Kore.ai. (n.d.). Model Analytics <a data-lb="1" href="/en/glossary/dashboard/" title="Dashboard glossary entry">Dashboard</a>. Kore.ai Documentation.</li>
<li>Google. (n.d.). Codelabs: Cloud Speech Text Node. Google Codelabs.</li>
</ol>
</div>
<div class="mt-16 sm:mt-20 border-t border-gray-200 dark:border-gray-800 pt-12 sm:pt-16">
<h2 class="text-2xl sm:text-3xl font-bold tracking-tight text-gray-900 dark:text-white mb-8 sm:mb-10">
        
          Related Terms
        
      </h2>
<div class="grid gap-6 sm:gap-8 grid-cols-1 sm:grid-cols-2 lg:grid-cols-3">
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/speech-to-text/">
                    Speech-to-Text
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
                    A technology that converts spoken words into written text using <a data-lb="1" href="/en/glossary/artificial-intelligence/" title="Artificial Intelligence glossary entry">artificial intelligence</a>, commonly us...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/speech-to-text/">
                    View details
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/speech-recognition/">
                    Speech Recognition
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
                    Speech recognition is technology that converts spoken words into written text, allowing computers an...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/speech-recognition/">
                    View details
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
<article class="group relative flex flex-col overflow-hidden border border-gray-200 dark:border-gray-700 bg-white dark:bg-gray-900 hover:border-gray-400 dark:hover:border-gray-500 transition-all duration-300">
<div class="flex flex-1 flex-col p-5 sm:p-6">
<h3 class="text-base sm:text-lg font-semibold text-gray-900 dark:text-white line-clamp-2 mb-3">
<a class="hover:text-gray-600 dark:hover:text-gray-300 transition-colors" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/vector-database/">
                    Vector Database
                  </a>
</h3>
<p class="text-sm text-gray-600 dark:text-gray-400 flex-1 line-clamp-3">
                    A specialized database that stores AI-generated numerical representations of data and finds similar ...
                  </p>
<div class="mt-4 pt-4 border-t border-gray-100 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-900 dark:text-gray-100 group-hover:translate-x-1 transition-transform" href="https://main.d1jtfhinlastnr.amplifyapp.com/en/glossary/vector-database/">
                    View details
                    <svg class="ml-1.5 h-4 w-4" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M9 5l7 7-7 7" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</a>
</div>
</div>
</article>
</div>
</div>
<div class="mt-12 sm:mt-16 py-8 border-t border-gray-200 dark:border-gray-800">
<a class="inline-flex items-center text-sm font-medium text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100 transition-colors" href="/en/glossary/">
<svg class="mr-2 h-5 w-5" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M10 19l-7-7m0 0l7-7m-7 7h18" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
      
        Back to Glossary
      
    </a>
</div>
</article>
</main>
<footer style="background-color: #000000;">
<div id="cta-curves-container" style="
    position: relative;
    background: #000000;
    padding: 4rem 2rem;
    overflow: hidden;
  ">
<svg id="cta-curves-svg" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 1; opacity: 0.7;" xmlns="http://www.w3.org/2000/svg">
<defs>
<lineargradient id="curveGrad1" x1="0%" x2="100%" y1="0%" y2="0%">
<stop offset="0%" style="stop-color:rgba(99, 102, 241, 0); stop-opacity:0"></stop>
<stop offset="50%" style="stop-color:rgba(99, 102, 241, 0.9); stop-opacity:1"></stop>
<stop offset="100%" style="stop-color:rgba(99, 102, 241, 0); stop-opacity:0"></stop>
</lineargradient>
<lineargradient id="curveGrad2" x1="0%" x2="100%" y1="0%" y2="0%">
<stop offset="0%" style="stop-color:rgba(139, 92, 246, 0); stop-opacity:0"></stop>
<stop offset="50%" style="stop-color:rgba(139, 92, 246, 0.8); stop-opacity:1"></stop>
<stop offset="100%" style="stop-color:rgba(139, 92, 246, 0); stop-opacity:0"></stop>
</lineargradient>
<lineargradient id="curveGrad3" x1="0%" x2="100%" y1="0%" y2="0%">
<stop offset="0%" style="stop-color:rgba(59, 130, 246, 0); stop-opacity:0"></stop>
<stop offset="50%" style="stop-color:rgba(59, 130, 246, 0.7); stop-opacity:1"></stop>
<stop offset="100%" style="stop-color:rgba(59, 130, 246, 0); stop-opacity:0"></stop>
</lineargradient>
</defs>
<path class="curve" data-speed="0.8" fill="none" stroke="url(#curveGrad1)" stroke-width="2"></path>
<path class="curve" data-speed="1.2" fill="none" opacity="0.8" stroke="url(#curveGrad2)" stroke-width="2.5"></path>
<path class="curve" data-speed="0.6" fill="none" opacity="0.6" stroke="url(#curveGrad3)" stroke-width="1.5"></path>
<path class="curve" data-speed="1.5" fill="none" opacity="0.7" stroke="url(#curveGrad1)" stroke-width="2"></path>
<path class="curve" data-speed="0.9" fill="none" opacity="0.5" stroke="url(#curveGrad2)" stroke-width="3"></path>
<path class="curve" data-speed="1.3" fill="none" opacity="0.9" stroke="url(#curveGrad3)" stroke-width="1.8"></path>
<path class="curve" data-speed="0.7" fill="none" opacity="0.6" stroke="url(#curveGrad1)" stroke-width="2.2"></path>
<path class="curve" data-speed="1.1" fill="none" opacity="0.8" stroke="url(#curveGrad2)" stroke-width="2"></path>
<path class="curve" data-speed="1.4" fill="none" opacity="0.5" stroke="url(#curveGrad3)" stroke-width="2.5"></path>
<path class="curve" data-speed="0.85" fill="none" opacity="0.7" stroke="url(#curveGrad1)" stroke-width="1.5"></path>
<path class="curve" data-speed="1.0" fill="none" opacity="0.6" stroke="url(#curveGrad2)" stroke-width="2.8"></path>
<path class="curve" data-speed="1.25" fill="none" opacity="0.8" stroke="url(#curveGrad3)" stroke-width="2"></path>
<path class="curve" data-speed="0.95" fill="none" opacity="0.5" stroke="url(#curveGrad1)" stroke-width="2.3"></path>
<path class="curve" data-speed="1.35" fill="none" opacity="0.9" stroke="url(#curveGrad2)" stroke-width="1.7"></path>
<path class="curve" data-speed="0.75" fill="none" opacity="0.7" stroke="url(#curveGrad3)" stroke-width="2.5"></path>
</svg>
<div style="position: absolute; top: 0; left: 0; width: 50px; height: 50px; border-left: 2px solid rgba(99, 102, 241, 0.3); border-top: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div style="position: absolute; top: 0; right: 0; width: 50px; height: 50px; border-right: 2px solid rgba(99, 102, 241, 0.3); border-top: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div style="position: absolute; bottom: 0; left: 0; width: 50px; height: 50px; border-left: 2px solid rgba(99, 102, 241, 0.3); border-bottom: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div style="position: absolute; bottom: 0; right: 0; width: 50px; height: 50px; border-right: 2px solid rgba(99, 102, 241, 0.3); border-bottom: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div class="mx-auto max-w-2xl text-center" style="position: relative; z-index: 10;">
<h2 class="text-base/7 font-semibold text-indigo-400">Ready to get started?</h2>
<p class="mt-2 text-4xl font-semibold tracking-tight text-balance text-white sm:text-5xl">Start using our services today</p>
<p class="mx-auto mt-6 max-w-xl text-lg/8 text-pretty text-gray-400">Join thousands of satisfied customers who have transformed their business with our solutions.</p>
<div class="mt-8 flex justify-center">
<a class="rounded-md bg-indigo-500 px-3.5 py-2.5 text-sm font-semibold text-white shadow-xs hover:bg-indigo-400 focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-indigo-400" href="/en/blog/">Get started</a>
</div>
</div>
</div>
<script>
  (function() {
    'use strict';
    
    const container = document.getElementById('cta-curves-container');
    const svg = document.getElementById('cta-curves-svg');
    if (!container || !svg) return;
    
    const curves = svg.querySelectorAll('.curve');
    let mouseX = 0;
    let mouseY = 0;
    let targetMouseX = 0;
    let targetMouseY = 0;
    const mouseInfluence = 150;
    const mouseStrength = 80;
    
    const curveData = Array.from(curves).map((curve, i) => {
      const speed = parseFloat(curve.getAttribute('data-speed')) || 1;
      return {
        element: curve,
        baseY: 50 + (i * 25),
        offset: Math.random() * Math.PI * 2,
        speed: speed,
        amplitude: 30 + Math.random() * 40
      };
    });
    
    container.addEventListener('mousemove', (e) => {
      const rect = container.getBoundingClientRect();
      targetMouseX = e.clientX - rect.left;
      targetMouseY = e.clientY - rect.top;
    });
    
    container.addEventListener('mouseleave', () => {
      targetMouseX = -1000;
      targetMouseY = -1000;
    });
    
    let time = 0;
    
    function animate() {
      time += 0.01;
      
      mouseX += (targetMouseX - mouseX) * 0.15;
      mouseY += (targetMouseY - mouseY) * 0.15;
      
      const width = svg.clientWidth;
      const height = svg.clientHeight;
      
      curveData.forEach((data, index) => {
        const { baseY, offset, speed, amplitude } = data;
        const phase = time * speed + offset;
        
        let path = `M -200,${baseY}`;
        
        for (let x = -200; x <= width + 200; x += 50) {
          const normalY = baseY + Math.sin((x * 0.005) + phase) * amplitude;
          
          const dx = x - mouseX;
          const dy = normalY - mouseY;
          const distance = Math.sqrt(dx * dx + dy * dy);
          
          let y = normalY;
          if (distance < mouseInfluence) {
            const influence = (1 - distance / mouseInfluence);
            const pushY = (normalY - mouseY) * influence * mouseStrength * 0.01;
            y = normalY + pushY;
          }
          
          const nextX = x + 50;
          const controlX = x + 25;
          const controlY = y;
          path += ` Q ${controlX},${controlY} ${nextX},${y}`;
        }
        
        data.element.setAttribute('d', path);
      });
      
      requestAnimationFrame(animate);
    }
    
    animate();
  })();
  </script>
<div class="mx-auto max-w-7xl px-6 py-16 sm:py-24 lg:px-8 lg:py-32">
<div class="mt-24 border-t border-white/10 pt-12 xl:grid xl:grid-cols-3 xl:gap-8">
<picture class="lazy-picture" data-maxwidth="200">
<source data-original-src="/images/interwork-logo-white-1.webp" data-srcset="/images/interwork-logo-white-1.webp 568w" sizes="200px" type="image/webp">
<img alt="Interwork" class="lazy-image h-9" data-original-src="/images/interwork-logo-white-1.webp" data-src="/images/interwork-logo-white-1.webp" decoding="async" loading="lazy"/>
</source></picture>
<div class="mt-16 grid grid-cols-2 gap-8 xl:col-span-2 xl:mt-0">
<div class="md:grid md:grid-cols-2 md:gap-8">
<div>
<h3 class="text-sm/6 font-semibold text-white">Services</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">AI Solutions</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">Web Development</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">System Development</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">Consulting</a>
</li>
</ul>
</div>
<div class="mt-10 md:mt-0">
<h3 class="text-sm/6 font-semibold text-white">Support</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="https://support.smartweb.jp/">Support Portal</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">Documentation</a>
</li>
</ul>
</div>
</div>
<div class="md:grid md:grid-cols-2 md:gap-8">
<div>
<h3 class="text-sm/6 font-semibold text-white">Company</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="https://www.intwk.co.jp/about/">About</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="/en/blog/">Blog</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">Careers</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">News</a>
</li>
</ul>
</div>
<div class="mt-10 md:mt-0">
<h3 class="text-sm/6 font-semibold text-white">Legal</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="/en/privacy-policy/">Privacy Policy</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="/en/ai-chatbot-terms-of-use/">AI Chatbot Terms of Use</a>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="language-selector mt-12 border-t border-white/10 pt-8 md:flex md:items-center md:justify-between">
<div>
<p class="text-sm/6 font-semibold text-white mb-4">Available Languages</p>
<div class="language-selector">
<div class="flex flex-wrap items-center justify-center gap-3">
<a aria-label="日本語" class="inline-flex items-center text-sm hover:opacity-75 transition-opacity" href="/ja/glossary/speech-to-text-node/" hreflang="ja" title="日本語">
<img alt="日本語" class="rounded" height="18" src="/flags/jp.png" width="24"/>
</a>
<span class="inline-flex items-center text-sm opacity-50" title="English">
<img alt="English" class="rounded" height="18" src="/flags/gb.png" width="24"/>
</span>
</div>
</div>
</div>
</div>
<div class="mt-12 border-t border-white/10 pt-8 md:flex md:items-center md:justify-between">
<div class="flex gap-x-6 md:order-2">
<a class="text-gray-400 hover:text-gray-300" href="https://github.com">
<span class="sr-only">GitHub</span>
</a>
<a class="text-gray-400 hover:text-gray-300" href="https://x.com">
<span class="sr-only">X</span>
</a>
<a class="text-gray-400 hover:text-gray-300" href="https://youtube.com">
<span class="sr-only">YouTube</span>
</a>
</div>
<p class="mt-8 text-sm/6 text-gray-400 md:mt-0" style="text-align: center; animation: copyrightGlow 3s ease-in-out infinite;">© 2026 Interwork Corporation All rights reserved.</p>
</div>
</div>
<style>
    @keyframes copyrightGlow {
      0%, 100% {
        opacity: 0.6;
        text-shadow: 0 0 10px rgba(99, 102, 241, 0);
      }
      50% {
        opacity: 1;
        text-shadow: 0 0 20px rgba(99, 102, 241, 0.5), 0 0 30px rgba(99, 102, 241, 0.3);
      }
    }
  </style>
</footer>
<div class="pointer-events-none fixed inset-x-0 bottom-0 px-6 pb-6 z-50 dark" data-cookie-consent-banner="" id="cookie-consent-banner">
<div class="pointer-events-auto max-w-xl rounded-xl section-bg-light dark:section-bg-dark p-6 ring-1 shadow-lg ring-gray-900/10">
<p class="text-secondary text-sm/6"><strong class="text-heading text-md mb-4 font-semibold">Cookie Consent</strong><br/> We use cookies to enhance your browsing experience and analyze our traffic. See our <a class="font-semibold text-primary hover:text-primary-500" href="/en/privacy-policy/">privacy policy</a>.</p>
<div class="mt-4 flex items-center gap-x-3 flex-wrap">
<a aria-label="Accept All" class="btn-primary dark:btn-primary-dark px-3 py-2 text-sm not-prose group" data-cookie-consent="accept-all" href="#" target="_self">
      Accept All
      
      
    </a>
<a aria-label="Reject All" class="btn-secondary dark:btn-secondary-dark px-3 py-2 text-sm not-prose group" data-cookie-consent="accept-necessary" href="#" target="_self">
      Reject All
      
      
    </a>
<a aria-label="Cookie Settings" class="btn-text dark:btn-text-dark px-3 py-2 text-sm not-prose group" data-cookie-consent="settings" href="#" target="_self">
      Cookie Settings
      
      
    </a>
</div>
</div>
</div>
<div class="fixed inset-0 z-50 hidden dark" id="cookie-settings-modal">
<div class="absolute inset-0 bg-black bg-opacity-50" data-cookie-settings-close=""></div>
<div class="relative mx-auto max-w-xl p-4 sm:p-6 section-bg-light dark:section-bg-dark rounded-xl shadow-xl mt-20">
<div class="flex justify-between items-center mb-4">
<h2 class="text-heading text-xl font-bold">Cookie Settings</h2>
<button class="text-gray-400 hover:text-gray-500 dark:text-gray-300 dark:hover:text-white" data-cookie-settings-close="" type="button">
<span class="sr-only">Close</span>
<svg class="h-6 w-6" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</button>
</div>
<div class="space-y-4">
<div class="border-gray-200 dark:border-gray-700 border-b pb-4">
<div class="flex items-center justify-between">
<div>
<h3 class="text-heading text-lg font-medium">Necessary Cookies</h3>
<p class="text-tertiary text-sm">These cookies are required for the website to function and cannot be disabled.</p>
</div>
<div class="ml-3 flex h-5 items-center">
<input checked="" class="h-4 w-4 rounded-xl border-gray-300 text-primary focus:ring-primary dark:border-gray-600 dark:bg-gray-700" disabled="" id="necessary-cookies" name="necessary-cookies" type="checkbox"/>
</div>
</div>
</div>
<div class="border-gray-200 dark:border-gray-700 border-b pb-4">
<div class="flex items-center justify-between">
<div>
<h3 class="text-heading text-lg font-medium">Analytics Cookies</h3>
<p class="text-tertiary text-sm">These cookies help us understand how visitors interact with our website.</p>
</div>
<div class="ml-3 flex h-5 items-center">
<input class="h-4 w-4 rounded-xl border-gray-300 text-primary focus:ring-primary dark:border-gray-600 dark:bg-gray-700" id="analytics-cookies" name="analytics-cookies" type="checkbox"/>
</div>
</div>
</div>
</div>
<div class="mt-6 flex justify-end gap-x-3">
<a aria-label="Cancel" class="btn-secondary dark:btn-secondary-dark px-3 py-2 not-prose group" data-cookie-settings-close="" href="#" target="_self">
      Cancel
      
      
    </a>
<a aria-label="Save Preferences" class="btn-primary dark:btn-primary-dark px-3 py-2 not-prose group" data-cookie-settings-save="" href="#" target="_self">
      Save Preferences
      
      
    </a>
</div>
</div>
</div>
<button aria-label="Back to Top" class="fixed bottom-8 right-8 z-[100] p-3 rounded-full bg-indigo-600 text-white shadow-lg transition-all duration-300 transform translate-y-12 opacity-0 invisible hover:bg-indigo-700 hover:shadow-xl focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:ring-offset-2 dark:bg-indigo-500 dark:hover:bg-indigo-400" id="back-to-top-btn" onclick="window.scrollTo({top: 0, behavior: 'smooth'});">
<svg class="h-6 w-6" fill="none" stroke="currentColor" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
<path d="M5 10l7-7m0 0l7 7m-7-7v18" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</button>
<script>
document.addEventListener('DOMContentLoaded', () => {
  const backToTopBtn = document.getElementById('back-to-top-btn');
  if (!backToTopBtn) return;

  const scrollThreshold = 300;

  const toggleVisibility = () => {
    if (window.scrollY > scrollThreshold) {
      backToTopBtn.classList.remove('translate-y-12', 'opacity-0', 'invisible');
      backToTopBtn.classList.add('translate-y-0', 'opacity-100', 'visible');
    } else {
      backToTopBtn.classList.remove('translate-y-0', 'opacity-100', 'visible');
      backToTopBtn.classList.add('translate-y-12', 'opacity-0', 'invisible');
    }
  };

  let ticking = false;
  window.addEventListener('scroll', () => {
    if (!ticking) {
      window.requestAnimationFrame(() => {
        toggleVisibility();
        ticking = false;
      });
      ticking = true;
    }
  });
});
</script>
<script src="/js/app.js?v=20260111165525"></script>
<script>
  renderMathInElement(document.body, {
    delimiters: [
      {left: "$$", right: "$$", display: true},
      {left: "$", right: "$", display: false},
      {left: "\\[", right: "\\]", display: true},
      {left: "\\(", right: "\\)", display: false}
    ],
    throwOnError: false,
    ignoredTags: ["script", "noscript", "style", "textarea", "pre", "code"]
  });
</script>
</body>
</html>