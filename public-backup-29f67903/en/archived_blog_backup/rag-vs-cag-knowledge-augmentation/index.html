<!DOCTYPE html>
<html dir="ltr" lang="en">
<head>
<meta content="strict-origin-when-cross-origin" name="referrer"/>
<meta charset="utf-8"/>
<meta content="minimum-scale=1, width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport"/>
<title>RAG vs. CAG: Understanding Knowledge Augmentation Strategies for AI Models | SmartWeb</title>
<link href="https://main.d1jtfhinlastnr.amplifyapp.com/en/archived_blog_backup/rag-vs-cag-knowledge-augmentation/" rel="canonical"/>
<link href="/images/faivicon.png" rel="icon" sizes="32x32" type="image/png"/>
<link href="/images/faivicon.png" rel="icon" sizes="16x16" type="image/png"/>
<link href="/images/faivicon.png" rel="apple-touch-icon" sizes="180x180"/>
<link href="/images/faivicon.png" rel="shortcut icon"/>
<link href="%!s(&lt;nil&gt;)%!s(&lt;nil&gt;)" hreflang="en" rel="alternate"/>
<link href="%!s(&lt;nil&gt;)%!s(&lt;nil&gt;)" hreflang="ja" rel="alternate"/>
<link href="%!s(&lt;nil&gt;)%!s(&lt;nil&gt;)" hreflang="x-default" rel="alternate"/>
<meta content="Explore the differences between Retrieval-Augmented Generation (RAG) and Cache-Augmented Generation (CAG), two powerful techniques for enhancing large language models with external knowledge. Learn when to use each approach and how they solve the knowledge gap problem in AI." name="description"/>
<meta content="RAG, CAG, retrieval augmented generation, cache augmented generation, LLM knowledge, AI augmentation, vector database, KV cache, knowledge retrieval" name="keywords"/>
<meta content="website" property="og:type"/>
<meta content="https://main.d1jtfhinlastnr.amplifyapp.com/en/archived_blog_backup/rag-vs-cag-knowledge-augmentation/" property="og:url"/>
<meta content="RAG vs. CAG: Understanding Knowledge Augmentation Strategies for AI Models | SmartWeb" property="og:title"/>
<meta content="Explore the differences between Retrieval-Augmented Generation (RAG) and Cache-Augmented Generation (CAG), two powerful techniques for enhancing large language models with external knowledge. Learn when to use each approach and how they solve the knowledge gap problem in AI." property="og:description"/>
<meta content="https://img.youtube.com/vi/HdafI0t3sEY/maxresdefault.jpg" property="og:image"/>
<meta content="1200" property="og:image:width"/>
<meta content="630" property="og:image:height"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="https://main.d1jtfhinlastnr.amplifyapp.com/en/archived_blog_backup/rag-vs-cag-knowledge-augmentation/" name="twitter:url"/>
<meta content="RAG vs. CAG: Understanding Knowledge Augmentation Strategies for AI Models | SmartWeb" name="twitter:title"/>
<meta content="Explore the differences between Retrieval-Augmented Generation (RAG) and Cache-Augmented Generation (CAG), two powerful techniques for enhancing large language models with external knowledge. Learn when to use each approach and how they solve the knowledge gap problem in AI." name="twitter:description"/>
<meta content="https://img.youtube.com/vi/HdafI0t3sEY/maxresdefault.jpg" name="twitter:image"/>
<style>
  :root {
     
    --color-primary: #1a73e8;
    --color-primary-light: #4285f4;
    --color-primary-dark: #1557b0;

    --color-secondary: #34a853;
    --color-accent: #fbbc05;

    --color-text: #202124;
    --color-background: #ffffff;

     
    --gradient-primary: linear-gradient(to right, var(--color-primary), var(--color-primary-light));
  }

   
  .bg-gradient-primary {
    background-image: var(--gradient-primary);
  }

  .text-gradient,
  .text-gradient-primary {
    background-image: var(--gradient-primary);
    background-clip: text;
    -webkit-background-clip: text;
    color: transparent;
    -webkit-text-fill-color: transparent;
  }
</style>
<link as="font" crossorigin="anonymous" href="/fonts/inter/Inter-VariableFont_opsz,wght.woff2" rel="preload" type="font/woff2"/>
<link href="https://fonts.googleapis.com" rel="preconnect"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;500;700&amp;family=Noto+Serif+JP:wght@400;500;600;700&amp;display=swap" rel="stylesheet"/>
<link crossorigin="anonymous" href="/css/main.css?v=20260111165525" rel="stylesheet"/>
<link crossorigin="anonymous" href="/css/custom-code-blockquote.css?v=20260111165525" rel="stylesheet"/>
<script defer="" src="/js/main.js?v=20260111165525"></script>
</head>
<body class="antialiased bg-white">
<header class="bg-white">
<nav aria-label="Global" class="mx-auto flex max-w-7xl items-center justify-between gap-x-6 p-6 lg:px-8">
<div class="flex lg:flex-1">
<a class="-m-1.5 p-1.5" href="/en/">
<span class="sr-only">SmartWeb</span>
<picture class="lazy-picture" data-maxwidth="200">
<source data-original-src="/images/smartweb-logo.png" data-srcset="/images/smartweb-logo.png 466w" sizes="200px" type="image/png">
<img alt="SmartWeb Logo" class="lazy-image h-6 sm:h-10 md:h-12 w-auto" data-original-src="/images/smartweb-logo.png" data-src="/images/smartweb-logo.png" decoding="async" loading="lazy"/>
</source></picture>
</a>
</div>
<div class="hidden lg:flex lg:gap-x-12"><a class="text-sm/6 font-semibold text-gray-900" href="/en/">Home</a><a class="text-sm/6 font-semibold text-gray-900" href="/en/blog/">Blog</a><a class="text-sm/6 font-semibold text-gray-900" href="/en/glossary/">Glossary</a><a class="text-sm/6 font-semibold text-gray-900" href="https://www.intwk.co.jp/about/">Company</a></div>
<div class="flex flex-1 items-center justify-end gap-x-6">
<a class="hidden text-sm/6 font-semibold text-gray-900 lg:block" href="https://support.smartweb.jp/">Support</a>
<a class="rounded-md bg-indigo-600 px-3 py-2 text-sm font-semibold text-white shadow-xs hover:bg-indigo-500 focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-indigo-600" href="/en/blog/">Get Started</a>
</div>
<div class="flex lg:hidden">
<button aria-controls="mobile-menu-1768118125587168000" aria-expanded="false" class="-m-2.5 inline-flex items-center justify-center rounded-xl p-2.5 text-gray-700" type="button">
<span class="sr-only">Open main menu</span>
<svg aria-hidden="true" class="size-6" data-slot="icon" fill="none" stroke="currentColor" stroke-width="1.5" viewbox="0 0 24 24">
<path d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5" stroke-linecap="round" stroke-linejoin="round"></path>
</svg>
</button>
</div>
</nav>
<div aria-modal="true" class="lg:hidden hidden relative z-50" id="mobile-menu-1768118125587168000" role="dialog">
<div class="fixed inset-0 z-50 bg-black bg-opacity-25"></div>
<div class="fixed inset-y-0 right-0 z-50 w-full overflow-y-auto bg-white px-6 py-6 sm:max-w-sm sm:ring-1 sm:ring-gray-900/10 transform transition-transform duration-300 ease-in-out translate-x-full">
<div class="flex items-center gap-x-6">
<a class="-m-1.5 p-1.5" href="/en/">
<span class="sr-only">SmartWeb</span>
<picture class="lazy-picture" data-maxwidth="3000">
<source data-original-src="/images/smartweb-logo.png" data-srcset="/images/smartweb-logo.png 466w" sizes="(max-width: 466px) 466px, 3000px" type="image/png">
<img alt="SmartWeb Logo" class="lazy-image h-6 sm:h-10 md:h-12 w-auto" data-original-src="/images/smartweb-logo.png" data-src="/images/smartweb-logo.png" decoding="async" loading="lazy"/>
</source></picture>
</a>
<a class="ml-auto rounded-md bg-indigo-600 px-3 py-2 text-sm font-semibold text-white shadow-xs hover:bg-indigo-500 focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-indigo-600" href="/en/blog/">Get Started</a>
<button class="-m-2.5 rounded-xl p-2.5 text-gray-700 close-mobile-menu" type="button">
<span class="sr-only">Close menu</span>
<svg aria-hidden="true" class="size-6" data-slot="icon" fill="none" stroke="currentColor" stroke-width="1.5" viewbox="0 0 24 24">
<path d="M6 18 18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"></path>
</svg>
</button>
</div>
<div class="mt-6 flow-root">
<div class="-my-6 divide-y divide-gray-500/10">
<div class="space-y-2 py-6"><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="/en/">Home</a><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="/en/blog/">Blog</a><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="/en/glossary/">Glossary</a><a class="-mx-3 block rounded-xl px-3 py-2 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="https://www.intwk.co.jp/about/">Company</a></div>
<div class="py-6">
<a class="-mx-3 block rounded-lg px-3 py-2.5 text-base/7 font-semibold text-gray-900 hover:bg-gray-50" href="https://support.smartweb.jp/">Support</a>
</div>
</div>
</div>
</div>
</div>
</header>
<script>
  document.addEventListener('DOMContentLoaded', function() {
    const mobileMenuButton = document.querySelector('[aria-controls="mobile-menu-1768118125587168000"]');
    const mobileMenu = document.getElementById('mobile-menu-1768118125587168000');
    const closeButtons = document.querySelectorAll('.close-mobile-menu');
    const mobileMenuContent = mobileMenu.querySelector('.fixed.inset-y-0');
    
    if (mobileMenuButton && mobileMenu) {
      mobileMenuButton.addEventListener('click', function() {
        const expanded = mobileMenuButton.getAttribute('aria-expanded') === 'true';
        
        if (expanded) {
          closeMobileMenu();
        } else {
          openMobileMenu();
        }
      });
      
      
      closeButtons.forEach(button => {
        button.addEventListener('click', closeMobileMenu);
      });
      
      
      mobileMenu.addEventListener('click', function(event) {
        if (event.target === mobileMenu) {
          closeMobileMenu();
        }
      });
      
      
      mobileMenuContent.addEventListener('click', function(event) {
        event.stopPropagation();
      });
      
      function openMobileMenu() {
        mobileMenuButton.setAttribute('aria-expanded', 'true');
        mobileMenu.classList.remove('hidden');
        
        
        mobileMenuContent.offsetHeight;
        
        mobileMenuContent.classList.remove('translate-x-full');
        document.body.classList.add('overflow-hidden');
      }
      
      function closeMobileMenu() {
        mobileMenuButton.setAttribute('aria-expanded', 'false');
        mobileMenuContent.classList.add('translate-x-full');
        
        
        setTimeout(() => {
          mobileMenu.classList.add('hidden');
          document.body.classList.remove('overflow-hidden');
        }, 300);
      }
    }
  });
</script>
<main class="w-full">
<nav aria-label="Breadcrumb" class="wrapper flex gap-2 py-8">
<ol class="flex flex-wrap items-center gap-y-2" role="list">
<li class="flex items-center">
<a class="icon-on-gray" href="/en/">
<svg class="map[class:size-5 block h-5 shrink-0 ]" fill="currentColor" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
<path d="M11.4697 3.84099C11.7626 3.5481 12.2374 3.5481 12.5303 3.84099L21.2197 12.5303C21.5126 12.8232 21.9874 12.8232 22.2803 12.5303C22.5732 12.2374 22.5732 11.7626 22.2803 11.4697L13.591 2.78033C12.7123 1.90165 11.2877 1.90165 10.409 2.78033L1.71967 11.4697C1.42678 11.7626 1.42678 12.2374 1.71967 12.5303C2.01256 12.8232 2.48744 12.8232 2.78033 12.5303L11.4697 3.84099Z" fill="currentColor"></path>
<path d="M12 5.43198L20.159 13.591C20.1887 13.6207 20.2191 13.6494 20.25 13.6771V19.875C20.25 20.9105 19.4105 21.75 18.375 21.75H15C14.5858 21.75 14.25 21.4142 14.25 21V16.5C14.25 16.0858 13.9142 15.75 13.5 15.75H10.5C10.0858 15.75 9.75 16.0858 9.75 16.5V21C9.75 21.4142 9.41421 21.75 9 21.75H5.625C4.58947 21.75 3.75 20.9105 3.75 19.875V13.6771C3.78093 13.6494 3.81127 13.6207 3.84099 13.591L12 5.43198Z" fill="currentColor"></path>
</svg>
<span class="sr-only">Home</span>
</a><span class="mx-2 lg:mx-4 text-gray-300 dark:text-gray-600 whitespace-nowrap">/</span></li><li class="flex items-center"><a class="text-sm font-medium text-secondary hover:text-gray-700 break-words" href="/en/archived_blog_backup/">Archived_blog_backups</a>
<span class="mx-2 lg:mx-4 text-gray-300 dark:text-gray-600 whitespace-nowrap">/</span></li><li class="flex items-center"><a aria-current="page" class="text-sm font-medium text-heading hover:text-gray-700 break-words" href="/en/archived_blog_backup/rag-vs-cag-knowledge-augmentation/">RAG vs. CAG: Understanding Knowledge Augmentation Strategies for AI Models</a></li></ol>
</nav>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
      "@type": "ListItem",
      "position":  1 ,
      "name": "Home",
      "item": "https:\/\/main.d1jtfhinlastnr.amplifyapp.com\/en\/"
    },{
      "@type": "ListItem",
      "position":  2 ,
      "name": "Archived_blog_backups",
      "item": "https:\/\/main.d1jtfhinlastnr.amplifyapp.com\/en\/archived_blog_backup\/"
    },{
      "@type": "ListItem",
      "position":  3 ,
      "name": "RAG vs. CAG: Understanding Knowledge Augmentation Strategies for AI Models",
      "item": "https:\/\/main.d1jtfhinlastnr.amplifyapp.com\/en\/archived_blog_backup\/rag-vs-cag-knowledge-augmentation\/"
    }]
}
</script>
<div class="split-with-video-hero section-bg-light py-12 lg:py-16">
<div class="wrapper lg:flex lg:justify-between lg:items-stretch gap-x-8 lg:flex-row-reverse">
<div class="lg:flex lg:w-1/2 lg:items-start lg:shrink lg:grow-0 xl:relative xl:inset-y-0 xl:left-0">
<div class="max-md:hidden relative rounded-lg py-6 flex items-start justify-center w-full overflow-hidden mx-auto max-w-[38rem] max-h-[35rem]">
<script>
  
  (function() {
    
    if (!window.videoLightboxCSSLoaded) {
      var cssLink = document.createElement('link');
      cssLink.rel = 'stylesheet';
      cssLink.href = '/css/video-lightbox.css?v=20260111165525';
      document.head.appendChild(cssLink);
      window.videoLightboxCSSLoaded = true;
    }
    
    
    function loadLightbox(callback) {
      if (!window.videoLightboxLoaded && !window.videoLightboxLoading) {
        window.videoLightboxLoading = true;
        
        var script = document.createElement('script');
        script.src = '/js/video-lightbox.js?v=20260111165525';
        script.onload = function() {
          window.videoLightboxLoaded = true;
          window.videoLightboxLoading = false;
          
          
          if (typeof window.initVideoLightbox === 'function') {
            window.initVideoLightbox();
          }
          
          if (typeof callback === 'function') {
            callback();
          }
        };
        script.onerror = function() {
          window.videoLightboxLoading = false;
          console.error('Failed to load video lightbox script');
          if (typeof callback === 'function') {
            callback();
          }
        };
        document.head.appendChild(script);
      } else if (window.videoLightboxLoaded && typeof callback === 'function') {
        
        callback();
      } else if (window.videoLightboxLoading && typeof callback === 'function') {
        
        var checkInterval = setInterval(function() {
          if (window.videoLightboxLoaded) {
            clearInterval(checkInterval);
            callback();
          } else if (!window.videoLightboxLoading) {
            
            clearInterval(checkInterval);
            callback();
          }
        }, 100);
      }
    }
    
    
    function loadHandler() {
      if (!window.videoHandlerLoaded && !window.videoHandlerLoading) {
        window.videoHandlerLoading = true;
        
        var script = document.createElement('script');
        script.src = '/js/video-handler.js?v=20260111165525';
        script.onload = function() {
          window.videoHandlerLoaded = true;
          window.videoHandlerLoading = false;
          
          
          if (window.flowhuntMedia && window.flowhuntMedia.video) {
            window.flowhuntMedia.video.init();
          }
        };
        script.onerror = function() {
          window.videoHandlerLoading = false;
          console.error('Failed to load video handler script');
        };
        document.head.appendChild(script);
      }
    }
    
    
    loadLightbox(loadHandler);
  })();
</script>
<script>
  
  (function() {
    
    if (!window.youtubeVideoCSSLoaded) {
      var cssLink = document.createElement('link');
      cssLink.rel = 'stylesheet';
      cssLink.href = '/css/youtube-video.css?v=20260111165525';
      document.head.appendChild(cssLink);
      window.youtubeVideoCSSLoaded = true;
    }
    
    
    if (!window.youtubeVideoLoaded && !window.youtubeVideoLoading) {
      window.youtubeVideoLoading = true;
      
      var script = document.createElement('script');
      script.src = '/js/youtube-video.js?v=20260111165525';
      script.onload = function() {
        window.youtubeVideoLoaded = true;
        window.youtubeVideoLoading = false;
      };
      script.onerror = function() {
        window.youtubeVideoLoading = false;
        console.error('Failed to load YouTube video script');
      };
      document.head.appendChild(script);
    }
  })();

  
  function findBestThumbnail(img) {
    
    function waitForScript() {
      if (window.findBestThumbnail && typeof window.findBestThumbnail === 'function') {
        window.findBestThumbnail(img);
      } else if (!window.youtubeVideoLoading) {
        
        console.warn('YouTube video script not loaded, using fallback');
        
        if (img && img.dataset && img.dataset.src) {
          img.src = img.dataset.src;
        }
      } else {
        
        setTimeout(waitForScript, 100);
      }
    }
    waitForScript();
  }
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "VideoObject",
  "name": "RAG vs. CAG: Solving Knowledge Gaps in AI Models",
  "description": "RAG vs. CAG: Solving Knowledge Gaps in AI Models",
  "thumbnailUrl": "https://img.youtube.com/vi/HdafI0t3sEY/maxresdefault.jpg",
  "uploadDate": "2026-01-11T16:55:25+09:00",
  "duration": "PT0M0S",
  "contentUrl": "https://www.youtube.com/watch?v=HdafI0t3sEY",
  "embedUrl": "https://www.youtube.com/embed/HdafI0t3sEY"
}
</script>
<div class="relative w-full overflow-hidden rounded-lg shadow-md rounded-xl shadow-lg w-full h-auto" data-video-autoplay="true" data-video-fallback-url="https://www.youtube.com/watch?v=HdafI0t3sEY" data-video-height="auto" data-video-id="HdafI0t3sEY" data-video-provider="youtube" data-video-title="RAG vs. CAG: Solving Knowledge Gaps in AI Models" data-video-use-lightbox="true" data-video-width="100%" id="video-1768118125602497000">
<div class="lazy-video-thumbnail aspect-ratio video-aspect-ratio relative w-full overflow-hidden cursor-pointer" data-video-trigger="true">
<img alt="Thumbnail for RAG vs. CAG: Solving Knowledge Gaps in AI Models" class="lazy-video-thumb-img lazy-image absolute inset-0 w-full h-full object-cover transition-transform duration-300" data-src="https://img.youtube.com/vi/HdafI0t3sEY/maxresdefault.jpg" data-video-id="HdafI0t3sEY" decoding="async" height="auto" loading="eager" onload="this.onload=null; if(this.dataset.src === this.src) findBestThumbnail(this);" src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 9'%3E%3C/svg%3E" width="100%"/>
</div>
<div class="lazy-video-play-button absolute top-1/2 left-1/2 transform -translate-x-1/2 -translate-y-1/2 flex items-center justify-center transition-all duration-300 z-10 w-16 h-12 bg-red-600 rounded-lg hover:bg-red-700 hover:scale-110">
<svg class="size-6 text-white ml-1" fill="currentColor" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
<path clip-rule="evenodd" d="M4.5 5.65257C4.5 4.22644 6.029 3.32239 7.2786 4.00967L18.8192 10.357C20.1144 11.0694 20.1144 12.9304 18.8192 13.6428L7.2786 19.9901C6.029 20.6774 4.5 19.7733 4.5 18.3472V5.65257Z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</div>
</div>
</div>
<div class="lg:flex lg:w-1/2 lg:items-center">
<div class="py-4 lg:w-full lg:flex-none">
<div class="">
<h1 class="mt-6 lg:text-[2rem] xl:text-[2.25rem] font-semibold tracking-tight text-heading leading-tight" data-dynamic-font="" data-text-length="74">
            RAG vs. CAG: Understanding Knowledge Augmentation Strategies for AI Models
        </h1>
<p class="mt-8 text-lg/7 text-secondary sm:text-xl/8 prose-links">Explore the differences between <a data-lb="1" href="/blog/introduction-to-rag/" title="Learn the basics and practical applications of RAG (Retrieval-Augmented Generation). Detailed coverage from differences with traditional AI to benefits and real-world use cases.">Retrieval-Augmented Generation</a> (RAG) and Cache-Augmented Generation (<a data-lb="1" href="/blog/rag-vs-cag-knowledge-augmentation/" title="Explore the differences between Retrieval-Augmented Generation (RAG) and Cache-Augmented Generation (CAG), two powerful techniques for enhancing large language models with external knowledge. Learn when to use each approach and how they solve the knowledge gap problem in AI.">CAG</a>), two powerful techniques for enhancing <a data-lb="1" href="/blog/how-to-use-large-language-models-effectively/" title="Learn practical applications of large language models like ChatGPT, explore different LLM platforms, understand how these models work under the hood, and discover how to leverage them effectively in your daily work and life.">large language models</a> with external knowledge. Learn when to use each approach and how they solve the knowledge gap problem in AI.</p>
<div class="mt-6 flex flex-col gap-4">
<div class="pt-4 pb-4 gap-3 flex flex-wrap justify-start" id="tags-container-default">
<a class="tag-visible" href="/en/tags/ai/">
<span class="badge-base badge-gray badge-with-border not-prose whitespace-nowrap [&amp;_a]:no-underline [&amp;_a]:!text-inherit [&amp;_a]:px-0.5 [&amp;_.link-building-link]:!no-underline [&amp;_.link-building-link]:!text-inherit">
    AI
  </span>
</a>
<a class="tag-visible" href="/en/tags/llm/">
<span class="badge-base badge-gray badge-with-border not-prose whitespace-nowrap [&amp;_a]:no-underline [&amp;_a]:!text-inherit [&amp;_a]:px-0.5 [&amp;_.link-building-link]:!no-underline [&amp;_.link-building-link]:!text-inherit">
    LLM
  </span>
</a>
<a class="tag-visible" href="/en/tags/knowledge-management/">
<span class="badge-base badge-gray badge-with-border not-prose whitespace-nowrap [&amp;_a]:no-underline [&amp;_a]:!text-inherit [&amp;_a]:px-0.5 [&amp;_.link-building-link]:!no-underline [&amp;_.link-building-link]:!text-inherit">
    Knowledge Management
  </span>
</a>
<a class="tag-visible" href="/en/tags/generative-ai/">
<span class="badge-base badge-gray badge-with-border not-prose whitespace-nowrap [&amp;_a]:no-underline [&amp;_a]:!text-inherit [&amp;_a]:px-0.5 [&amp;_.link-building-link]:!no-underline [&amp;_.link-building-link]:!text-inherit">
    Generative AI
  </span>
</a>
<a class="tag-hidden hidden" href="/en/tags/ai-architecture/">
<span class="badge-base badge-gray badge-with-border not-prose whitespace-nowrap [&amp;_a]:no-underline [&amp;_a]:!text-inherit [&amp;_a]:px-0.5 [&amp;_.link-building-link]:!no-underline [&amp;_.link-building-link]:!text-inherit">
    AI Architecture
  </span>
</a>
<button class="show-more-btn text-secondary font-semibold text-xs tracking-[0.216px] cursor-pointer" data-container="default" data-container-type="tags" type="button">
<div class="flex items-center gap-1">
<span>+1 more</span>
<svg class="size-5 text-secondary" fill="none" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
<path d="M19.5 8.25L12 15.75L4.5 8.25" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5"></path>
</svg>
</div>
</button>
<button class="show-less-btn text-secondary font-semibold text-xs tracking-[0.216px] cursor-pointer hidden" data-container="default" data-container-type="tags" type="button">
<div class="flex items-center gap-1">
<span>Show less</span>
<svg class="size-5 text-secondary" fill="none" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
<path d="M4.5 15.75L12 8.25L19.5 15.75" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5"></path>
</svg>
</div>
</button>
</div>
<script>
  
  if (!window.itemToggleLoaded && !window.itemToggleLoading) {
    window.itemToggleLoading = true;
    
    var script = document.createElement('script');
    script.src = '/js/item-toggle.js?v=20260111165525';
    script.defer = true;
    script.onload = function() {
      window.itemToggleLoaded = true;
      window.itemToggleLoading = false;
    };
    script.onerror = function() {
      window.itemToggleLoading = false;
      console.error('Failed to load item-toggle.js');
    };
    
    document.head.appendChild(script);
  }
</script>
</div>
<div class="mt-10 flex items-center gap-x-6">
</div>
</div>
</div>
</div>
</div>
</div>
<div class="bg-white">
<div class="wrapper">
<div class="mx-auto max-w-none prose">
<h2 id="introduction">Introduction</h2>
<p>Large language models have revolutionized how we interact with <a data-lb="1" href="/en/glossary/artificial-intelligence/" title="Artificial Intelligence glossary entry">artificial intelligence</a>, but they face a fundamental challenge: <strong>knowledge cutoff</strong>. If information wasn’t included in a model’s training data, the model simply cannot recall it. Whether it’s recent news events, proprietary business data, or real-time information, traditional LLMs struggle to provide accurate answers about knowledge beyond their training window. This limitation has sparked the development of augmented generation techniques—methods that extend an AI model’s capabilities by connecting it to external knowledge sources. Two prominent approaches have emerged to solve this problem: <strong>Retrieval-Augmented Generation (<a data-lb="1" href="/blog/rag-vs-cag-knowledge-augmentation/" title="Explore the differences between Retrieval-Augmented Generation (RAG) and Cache-Augmented Generation (CAG), two powerful techniques for enhancing large language models with external knowledge. Learn when to use each approach and how they solve the knowledge gap problem in AI.">RAG</a>)</strong>and <strong>Cache-Augmented Generation (CAG)</strong>. Each offers distinct advantages and trade-offs, and understanding when to use each approach is crucial for building effective <a data-lb="1" href="/en/glossary/artificial-intelligence/" title="Artificial Intelligence (AI) glossary entry">AI systems</a>. This comprehensive guide explores both techniques in depth, examining their architectures, capabilities, and real-world applications.</p>
<div class="youtube-embed-wrapper">
<div class="youtube-embed-container">
<iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" loading="lazy" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/HdafI0t3sEY" title="RAG vs. CAG: Solving Knowledge Gaps in AI Models">
</iframe>
</div>
</div>
<style>
 
.youtube-embed-wrapper {
  max-width: 768px !important;
  margin: 2rem auto 3rem !important;
  padding: 0 !important;
}

 
.youtube-embed-container {
  position: relative !important;
  width: 100% !important;
  padding-top: 56.25% !important;  
  border-radius: 18px !important;
  overflow: hidden !important;
  box-shadow: 0 25px 60px rgba(0, 0, 0, 0.25) !important;
  background: #000 !important;
}

 
.youtube-embed-container iframe {
  position: absolute !important;
  inset: 0 !important;
  width: 100% !important;
  height: 100% !important;
  border: 0 !important;
}

 
.dark .youtube-embed-container {
  box-shadow: 0 25px 60px rgba(0, 0, 0, 0.5) !important;
}

 
@media (max-width: 768px) {
  .youtube-embed-wrapper {
    margin: 1.5rem auto 2rem !important;
    padding: 0 1rem !important;
  }
  
  .youtube-embed-container {
    border-radius: 12px !important;
  }
}
</style>
<h2 id="the-knowledge-problem-in-large-language-models">The Knowledge Problem in Large Language Models</h2>
<p>Before diving into solutions, it’s essential to understand the core problem that RAG and CAG address. Large language models are trained on massive datasets collected at a specific point in time. Once training is complete, the model’s knowledge becomes static—it cannot learn new information or update its understanding of the world. This creates several critical issues for real-world applications. <strong>First</strong>, models lack awareness of recent events. If you ask a model about the 2025 Academy Awards winner for Best Picture, it may not have this information if the training data was collected before the ceremony. <strong>Second</strong>, models cannot access proprietary or confidential information. A customer service <a data-lb="1" href="/en/glossary/chatbot/" title="Chatbot glossary entry">chatbot</a> cannot answer questions about a specific client’s purchase history or account details because this information was never part of the training dataset. <strong>Third</strong>, models may provide outdated information when facts change. Medical guidelines, legal precedents, product specifications, and company policies all evolve over time, but a static model cannot reflect these changes. These limitations make it impossible to deploy LLMs in many enterprise and mission-critical applications without some mechanism to augment their knowledge with current, relevant information.</p>
<h2 id="understanding-knowledge-augmentation-the-foundation-for-modern-ai">Understanding Knowledge Augmentation: The Foundation for Modern AI</h2>
<p>Knowledge augmentation represents a paradigm shift in how we approach <a data-lb="1" href="/en/glossary/artificial-intelligence/" title="Artificial Intelligence (AI) glossary entry">AI system</a> design. Rather than relying solely on what a model learned during training, augmentation techniques create a bridge between the model’s inherent capabilities and external information sources. This approach acknowledges a fundamental truth: <strong>the best AI systems are not those with the largest training datasets, but those that can dynamically access and integrate relevant information when needed</strong>. Knowledge augmentation techniques come in various forms, but they all share a common goal—to enhance the model’s ability to provide accurate, contextual, and current responses. The beauty of augmentation is that it decouples knowledge storage from model training. You can update your <a data-lb="1" href="/en/glossary/knowledge-base/" title="Knowledge Base glossary entry">knowledge base</a> without retraining the model, add new information without expensive fine-tuning processes, and scale your system’s knowledge far beyond what any single model could contain. This flexibility has made augmentation techniques essential for building production-grade AI systems that must operate in dynamic, real-world environments where information constantly changes.</p>
<h2 id="knowledge-augmentation-in-practice">Knowledge Augmentation in Practice</h2>
<p>The RAG and CAG techniques discussed in this guide are already being applied in real-world AI platforms. <a href="https://www.flowhunt.io/" rel="nofollow noopener noreferrer" target="_blank">FlowHunt</a> implements RAG through its Knowledge Sources feature, allowing businesses to connect AI chatbots and workflows to company documents, FAQs, and websites. This enables AI responses grounded in verified company information rather than general training data. <a href="https://www.liveagent.com/" rel="nofollow noopener noreferrer" target="_blank">LiveAgent</a> integrates AI features like AI Answer Improver and <a data-lb="1" href="/en/glossary/ai-chatbot/" title="AI Chatbot glossary entry">AI Chatbot</a> that can reference knowledge bases to provide accurate <a data-lb="1" href="/en/glossary/customer-support/" title="Customer Support glossary entry">customer support</a> responses.</p>
<p><strong>SmartWeb</strong>leverages both platforms to build AI solutions that use controlled knowledge sources—company FAQs, product manuals, and support documentation—ensuring responses remain accurate and consistent with company policies. As knowledge augmentation techniques continue to advance, these platforms evolve alongside them, meaning businesses that implement RAG-based solutions today can benefit from future improvements in retrieval accuracy and response quality.</p>
<h2 id="rag-retrieval-augmented-generation-explained">RAG: Retrieval-Augmented Generation Explained</h2>
<p>Retrieval-Augmented Generation represents the more established and widely-adopted approach to knowledge augmentation. RAG operates on a simple but powerful principle: <strong>retrieve only the information you need, when you need it</strong>. Rather than loading all knowledge upfront, RAG maintains a searchable index of your knowledge base and retrieves relevant pieces on-demand during the query process. This two-phase architecture—offline indexing and online retrieval—provides remarkable flexibility and scalability.</p>
<h3 id="the-rag-architecture-offline-and-online-phases">The RAG Architecture: Offline and Online Phases</h3>
<p>RAG’s power comes from its modular design, which separates knowledge preparation from query processing. <strong>In the offline phase</strong>, your knowledge base is prepared for efficient retrieval. This begins with document ingestion, where you gather all your knowledge sources—Word documents, PDFs, web pages, database records, or any other format containing information you want the model to access. These documents are then broken into manageable chunks, typically ranging from a few sentences to a few paragraphs. This chunking process is critical because it determines the granularity of information the model will receive. Too-large chunks may include irrelevant information; too-small chunks may fragment important context. Once documents are chunked, an <strong>embedding model</strong>converts each chunk into a numerical vector representation. This embedding captures the semantic meaning of the text—chunks with similar meanings will have similar embeddings, even if they use different words. These embeddings are stored in a <strong>vector database</strong>, a specialized database optimized for similarity search. The vector database creates a searchable index of your entire knowledge base, enabling fast retrieval of relevant information.</p>
<p><strong>In the online phase</strong>, when a user submits a query, the system springs into action. The user’s question is converted into a vector using the same embedding model that processed the documents. This query vector is then used to search the vector database, finding the most similar document chunks. The system typically retrieves the top K results—often three to five passages most likely to contain the answer. These retrieved chunks are then placed into the context window of the large language model, alongside the original user query. The model now has both the question and relevant contextual information, allowing it to generate a more accurate, informed response. Importantly, the model can see where the information came from, enabling it to cite sources and provide transparency about its reasoning.</p>
<h3 id="key-advantages-of-rag">Key Advantages of RAG</h3>
<p><strong>Scalability</strong>stands as RAG’s most compelling advantage. Because the system only retrieves small slices of data per query, it can handle enormous knowledge bases. A RAG system could index ten million documents and still retrieve only the few most relevant ones for any given question. The language model never sees all ten million documents at once—it only processes the retrieved subset. This scalability is crucial for enterprise applications where knowledge bases grow continuously. <strong>Data freshness</strong>is another critical strength. When your knowledge base changes, RAG can update the index incrementally. New documents can be added, outdated information can be removed, and the system can immediately use this new knowledge without any retraining or recomputation. This makes RAG ideal for domains where information changes frequently—legal research with new case rulings, medical systems with updated treatment guidelines, or customer support with evolving product information. <strong>Transparency and citations</strong>provide significant value in regulated or professional contexts. Because RAG retrieves specific documents, the system can tell you exactly where information came from. A lawyer using RAG for legal research can see which cases support a particular argument. A doctor using RAG for clinical decisions can reference the specific research papers or guidelines that informed a recommendation. This traceability builds trust and enables verification of the system’s reasoning.</p>
<h3 id="rag-limitations-and-trade-offs">RAG Limitations and Trade-offs</h3>
<p>Despite its advantages, RAG introduces <strong>retrieval <a data-lb="1" href="/en/glossary/latency/" title="Latency glossary entry">latency</a></strong>. Each query requires embedding the question, searching the vector database, and retrieving relevant documents before the language model can even begin generating an answer. This adds measurable overhead compared to systems that don’t require retrieval. For applications where response time is critical, this latency can be problematic. <strong>Retriever quality</strong>is another crucial consideration. RAG’s accuracy depends entirely on whether the retriever successfully finds relevant documents. If the retrieval step fails—if the embedding search doesn’t return documents containing the answer—then the language model won’t have the information needed to respond correctly. A poorly configured embedding model or vector database can significantly degrade system performance. <strong>System complexity</strong>increases with RAG implementation. You must manage multiple components: the embedding model, the vector database, the retrieval mechanism, and the language model. Each component introduces potential failure points and requires careful tuning and <a data-lb="1" href="/en/glossary/monitoring/" title="Monitoring glossary entry">monitoring</a>. This complexity can make RAG systems more challenging to deploy and maintain compared to simpler approaches.</p>
<h2 id="cag-cache-augmented-generation-explained">CAG: Cache-Augmented Generation Explained</h2>
<p>Cache-Augmented Generation takes a fundamentally different approach to the knowledge problem. Rather than retrieving information on-demand, CAG preloads all relevant knowledge into the model’s context window before processing any queries. This strategy trades flexibility for speed, creating a system optimized for rapid, consistent responses with a fixed knowledge base.</p>
<h3 id="the-cag-architecture-preloading-and-kv-caching">The CAG Architecture: Preloading and KV Caching</h3>
<p>CAG’s architecture is elegantly simple compared to RAG. Instead of maintaining a separate vector database and retrieval mechanism, CAG works directly with the language model’s internal architecture. The process begins by formatting all your knowledge into a single, massive prompt that fits within the model’s context window. This could be tens or even hundreds of thousands of tokens—everything from product manuals to legal documents to medical guidelines, all concatenated into one enormous input. The language model then processes this entire knowledge blob in a single forward pass through its neural network. As the model reads and processes all this information, it creates an internal representation called the <strong><a data-lb="1" href="/en/glossary/kv-cache/" title="KV Cache glossary entry">KV cache</a></strong>(Key-Value cache). This cache is created from each self-attention layer in the transformer architecture and represents the model’s encoded understanding of all the preloaded documents. Think of it as the model having already read and memorized all your documents—the KV cache is the model’s internal memory of that knowledge.</p>
<p>Once the KV cache is created and stored, it becomes the foundation for all subsequent queries. When a user submits a question, the system doesn’t need to retrieve anything or reprocess the documents. Instead, it simply appends the user’s query to the KV cache and sends everything to the language model. Because the transformer’s cache already contains all the knowledge tokens, the model can reference any relevant information as it generates an answer without having to reread or reprocess the original documents. This is remarkably efficient—the model can generate responses using information from anywhere in the preloaded knowledge base without the computational cost of searching or retrieving.</p>
<h3 id="key-advantages-of-cag">Key Advantages of CAG</h3>
<p><strong>Latency reduction</strong>is CAG’s defining strength. Once the knowledge is cached, answering queries becomes a single forward pass of the language model on the user prompt plus generation. There’s no retrieval lookup time, no embedding computation, no vector database search. The response time depends only on the model’s generation speed, not on any external retrieval mechanism. For applications where speed is paramount—real-time customer interactions, time-sensitive decision support, or high-volume query processing—CAG’s low latency is invaluable. <strong>Computational efficiency</strong>follows naturally from the latency advantage. By eliminating the retrieval step, CAG reduces overall computational overhead. You don’t need to maintain a separate embedding model or vector database. You don’t need to perform similarity searches. The system is simpler, leaner, and more resource-efficient. This efficiency translates directly to lower operational costs, making CAG attractive for cost-sensitive applications. <strong>Simplicity of deployment</strong>cannot be overstated. CAG requires fewer moving parts than RAG. You don’t need to manage vector databases, embedding models, or retrieval pipelines. The system is more straightforward to implement, test, and deploy. This simplicity reduces the surface area for bugs and makes the system easier to understand and maintain.</p>
<h3 id="cag-limitations-and-trade-offs">CAG Limitations and Trade-offs</h3>
<p><strong>Context window constraints</strong>represent CAG’s fundamental limitation. Modern language models have context windows ranging from 32,000 to 100,000 tokens, with some larger models pushing beyond this. However, this is still finite. Everything you want the model to know must fit within this window. For a 100,000-token context window, you might fit a few hundred documents at most. This hard limit means CAG cannot scale to the massive knowledge bases that RAG handles effortlessly. If your knowledge base grows beyond what fits in the context window, CAG becomes impractical. <strong>Static knowledge</strong>is another critical constraint. CAG preloads knowledge once and caches it. If your knowledge base changes—new documents are added, information is updated, or outdated content needs to be removed—you must recompute the entire KV cache. This recomputation negates the caching benefit and introduces significant overhead. For domains with frequently changing information, CAG’s static nature becomes a liability. <strong>Potential for confusion</strong>in the model’s responses is a subtle but important consideration. When you preload all possible relevant information, you’re not just giving the model the answer—you’re giving it everything. The model must extract the right information from this large context and avoid mixing in unrelated information. While modern language models are generally good at this, there’s always a risk that the model might conflate information or provide answers that blend multiple unrelated pieces of knowledge inappropriately.</p>
<h2 id="comparing-rag-and-cag-accuracy-latency-scalability-and-data-freshness">Comparing RAG and CAG: Accuracy, Latency, Scalability, and Data Freshness</h2>
<p>Understanding the trade-offs between RAG and CAG requires examining them across multiple dimensions that matter for real-world applications.</p>
<h3 id="accuracy-retrieval-vs-comprehensiveness">Accuracy: Retrieval vs. Comprehensiveness</h3>
<p><strong>RAG’s accuracy</strong>depends critically on the retriever component. If the retriever successfully finds relevant documents, the language model has the information needed to answer correctly. The retriever acts as a filter, shielding the model from irrelevant information and focusing its attention on what matters. However, if the retriever fails—if it doesn’t find the relevant documents—then the model lacks the facts needed for an accurate answer. RAG’s accuracy is only as good as its retrieval mechanism. <strong>CAG’s accuracy</strong>works differently. By preloading all potential relevant information, CAG guarantees that the information is present somewhere in the context. Assuming your knowledge base actually contains the answer to the question being asked, the information is definitely there. However, the burden shifts to the model to extract the right information from the large context. There’s potential for the model to get confused, to mix in unrelated information, or to provide answers that blend multiple pieces of knowledge inappropriately. CAG trades the risk of retrieval failure for the risk of model confusion.</p>
<h3 id="latency-speed-matters">Latency: Speed Matters</h3>
<p><strong>RAG introduces latency</strong>through its retrieval step. Each query requires embedding the question, searching the vector database, and retrieving relevant documents before the language model can generate an answer. This overhead is measurable and becomes more significant as your knowledge base grows or as your retrieval infrastructure becomes more complex. For applications where response time is critical, this latency can be problematic. <strong>CAG minimizes latency</strong>by eliminating the retrieval step entirely. Once knowledge is cached, answering a query is just one forward pass of the model. The response time is determined solely by the model’s generation speed, not by any external retrieval mechanism. This makes CAG significantly faster for query processing, though the initial caching step requires computation upfront.</p>
<h3 id="scalability-size-of-knowledge-base">Scalability: Size of Knowledge Base</h3>
<p><strong>RAG scales to massive knowledge bases</strong>because it only retrieves small pieces per query. You could have ten million documents indexed in your vector database, and the model would still only see the few most relevant ones for any given question. This scalability is crucial for enterprise applications where knowledge bases grow continuously. <strong>CAG has a hard scalability limit</strong>determined by the model’s context window size. With typical context windows of 32,000 to 100,000 tokens, you can fit a few hundred documents at most. Even as context windows grow—and they are expected to—RAG will likely maintain an edge in scalability because the retrieval mechanism allows you to handle arbitrarily large knowledge bases.</p>
<h3 id="data-freshness-keeping-knowledge-current">Data Freshness: Keeping Knowledge Current</h3>
<p><strong>RAG handles data freshness elegantly</strong>. When your knowledge base changes, you simply update the vector database. New documents can be added incrementally, outdated documents can be removed, and the system immediately uses this new information. There’s minimal downtime and no need to recompute anything. This makes RAG ideal for domains where information changes frequently. <strong>CAG requires recomputation</strong>when data changes. If your knowledge base is updated, you must recompute the KV cache to reflect the new information. This recomputation negates the caching benefit and introduces significant overhead. If your knowledge base changes frequently, CAG loses much of its appeal because you’re constantly reloading and recomputing, which defeats the purpose of caching.</p>
<h2 id="real-world-application-scenarios-rag-or-cag">Real-World Application Scenarios: RAG or CAG?</h2>
<p>The choice between RAG and CAG isn’t abstract—it depends on your specific use case. Let’s examine several scenarios to understand how to make this decision.</p>
<h3 id="scenario-1-it-help-desk-bot-with-product-manual">Scenario 1: IT Help Desk Bot with Product Manual</h3>
<p>Imagine you’re building an IT help desk chatbot that uses a 200-page product manual to augment its answers. The manual is updated only a few times per year, and users submit questions about how to use the product. <strong>This is a CAG scenario.</strong>The knowledge base is small enough to fit comfortably in most language model context windows. The information is static, so the KV cache won’t need frequent updates. By caching the product manual, the system can answer user questions with minimal latency, providing fast support responses. The simplicity of CAG deployment also makes sense for this use case—you don’t need the complexity of a vector database and retrieval pipeline for a small, static knowledge base.</p>
<h3 id="scenario-2-legal-research-assistant-for-law-firm">Scenario 2: Legal Research Assistant for Law Firm</h3>
<p>Now consider a research assistant for a law firm that must search through thousands of legal cases that are constantly being updated with new rulings and amendments. Lawyers need answers with accurate citations to relevant legal documents. <strong>This is clearly a RAG scenario.</strong>The knowledge base is massive and dynamic, with new content being added continuously. Attempting to cache all this information would quickly exceed most models’ context windows. The requirement for precise citations to source materials is something RAG naturally supports through its retrieval mechanism—it tells you exactly where information came from. The ability to incrementally update the vector database as new legal documents emerge means the system always has access to the most current information without requiring full cache recomputation.</p>
<h3 id="scenario-3-clinical-decision-support-system-for-hospitals">Scenario 3: Clinical Decision Support System for Hospitals</h3>
<p>Consider a clinical decision support system where doctors query patient records, treatment guides, and drug interactions. Responses must be comprehensive and highly accurate because they’ll be used during patient consultations. Doctors often ask complex follow-up questions. <strong>This is a hybrid scenario.</strong>The system could first use RAG to retrieve the most relevant subset from the massive knowledge base—pulling specific sections of a patient’s history and relevant research papers based on the doctor’s query. Rather than simply passing those retrieved chunks to the language model, the system could load all that retrieved content into a long-context model that uses CAG, creating a temporary working memory for the specific patient case. This hybrid approach combines RAG’s ability to efficiently search enormous knowledge bases with CAG’s capability to provide comprehensive knowledge for follow-up questions without repeatedly querying the database.</p>
<h2 id="advanced-insights-hybrid-approaches-and-future-directions">Advanced Insights: Hybrid Approaches and Future Directions</h2>
<p>The most sophisticated AI systems don’t choose between RAG and CAG—they use both strategically. <strong>Hybrid architectures</strong>leverage RAG’s scalability and data freshness for initial retrieval, then use CAG’s speed and comprehensiveness for detailed processing. This approach is particularly powerful for complex, multi-turn conversations where the system needs to maintain context across multiple questions while also accessing a large knowledge base.</p>
<p><strong>Context window expansion</strong>is changing the RAG vs. CAG calculus. As language models develop larger context windows—some now supporting 200,000 tokens or more—CAG becomes viable for larger knowledge bases. However, even with expanded context windows, RAG will likely maintain advantages for truly massive knowledge bases and frequently updated information. <strong>Retrieval optimization</strong>continues to improve RAG’s latency. Techniques like dense passage retrieval, hybrid search combining keyword and semantic search, and learned retrieval mechanisms are making RAG faster and more accurate. These improvements narrow the latency gap between RAG and CAG. <strong>Caching innovations</strong>are making CAG more flexible. Techniques for partial cache updates and selective recomputation could eventually allow CAG to handle more dynamic knowledge bases without full recomputation. The future likely involves increasingly sophisticated hybrid approaches that combine the strengths of both techniques.</p>
<h2 id="conclusion">Conclusion</h2>
<p>RAG and CAG represent two fundamentally different philosophies for augmenting language models with external knowledge. RAG retrieves only what’s needed on-demand, offering unmatched scalability, data freshness, and transparency at the cost of retrieval latency. CAG preloads all knowledge upfront, delivering exceptional speed and simplicity but constrained by context window size and static knowledge. The choice between them—or the decision to use both in a hybrid approach—depends on your specific requirements: the size of your knowledge base, how frequently information changes, whether you need source citations, and how critical response latency is to your application. Modern AI systems increasingly recognize that this isn’t a binary choice but rather a spectrum of strategies that can be combined and optimized for specific use cases. By understanding the strengths and limitations of each approach, you can architect AI systems that deliver both accuracy and efficiency in real-world applications.</p>
</div>
</div>
</div>
<div class="bg-white py-20">
<div class="wrapper">
<h2 class="text-4xl font-semibold tracking-tight text-gray-900 sm:text-5xl">Frequently asked questions</h2>
<dl class="mt-20 divide-y divide-gray-900/10">
<div class="py-8 first:pt-0 last:pb-0 lg:grid lg:grid-cols-12 lg:gap-8">
<dt class="text-base/7 font-semibold text-gray-900 lg:col-span-5">What is the main difference between RAG and CAG?</dt>
<dd class="mt-4 lg:col-span-7 lg:mt-0">
<p class="text-base/7 text-gray-600">
<a data-lb="1" href="/en/glossary/rag/" title="RAG (Retrieval-Augmented Generation) glossary entry">RAG (Retrieval-Augmented Generation)</a> retrieves relevant information from external sources on-demand during query processing, while CAG (Cache-Augmented Generation) preloads all knowledge into the model's context window upfront. RAG offers better scalability and data freshness, while CAG provides lower latency and faster responses.
          </p>
</dd>
</div>
<div class="py-8 first:pt-0 last:pb-0 lg:grid lg:grid-cols-12 lg:gap-8">
<dt class="text-base/7 font-semibold text-gray-900 lg:col-span-5">When should I use RAG instead of CAG?</dt>
<dd class="mt-4 lg:col-span-7 lg:mt-0">
<p class="text-base/7 text-gray-600">
            Use RAG when you have a large, frequently updated knowledge base, need precise citations to source materials, or require the system to handle millions of documents. RAG is ideal for legal research, customer support with dynamic information, and research assistants where data freshness is critical.
          </p>
</dd>
</div>
<div class="py-8 first:pt-0 last:pb-0 lg:grid lg:grid-cols-12 lg:gap-8">
<dt class="text-base/7 font-semibold text-gray-900 lg:col-span-5">What is a KV cache in the context of CAG?</dt>
<dd class="mt-4 lg:col-span-7 lg:mt-0">
<p class="text-base/7 text-gray-600">
            A KV (Key-Value) cache is the internal state created from each self-attention layer in a transformer model after it processes and digests all preloaded documents. It represents the model's encoded form of all your knowledge, allowing the model to reference this information without reprocessing the text.
          </p>
</dd>
</div>
<div class="py-8 first:pt-0 last:pb-0 lg:grid lg:grid-cols-12 lg:gap-8">
<dt class="text-base/7 font-semibold text-gray-900 lg:col-span-5">Can RAG and CAG be used together?</dt>
<dd class="mt-4 lg:col-span-7 lg:mt-0">
<p class="text-base/7 text-gray-600">
            Yes, a hybrid approach can combine both techniques. For example, RAG can retrieve the most relevant subset from a massive knowledge base, and then CAG can load that retrieved content into a long-context model for comprehensive processing. This is particularly effective for complex scenarios like clinical decision support systems.
          </p>
</dd>
</div>
<div class="py-8 first:pt-0 last:pb-0 lg:grid lg:grid-cols-12 lg:gap-8">
<dt class="text-base/7 font-semibold text-gray-900 lg:col-span-5">What are the scalability limits of CAG?</dt>
<dd class="mt-4 lg:col-span-7 lg:mt-0">
<p class="text-base/7 text-gray-600">
            CAG is constrained by the model's context window size, typically 32,000 to 100,000 tokens in modern models. This limits CAG to handling a few hundred documents at most, whereas RAG can scale to millions of documents since it only retrieves small relevant pieces per query.
          </p>
</dd>
</div>
</dl>
</div>
</div>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "FAQPage",
  "mainEntity": [
    
    {
      "@type": "Question",
      "name": "\"What is the main difference between RAG and CAG?\"",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "\"RAG (Retrieval-Augmented Generation) retrieves relevant information from external sources on-demand during query processing, while CAG (Cache-Augmented Generation) preloads all knowledge into the model's context window upfront. RAG offers better scalability and data freshness, while CAG provides lower latency and faster responses.\""
      }
    },
    
    {
      "@type": "Question",
      "name": "\"When should I use RAG instead of CAG?\"",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "\"Use RAG when you have a large, frequently updated knowledge base, need precise citations to source materials, or require the system to handle millions of documents. RAG is ideal for legal research, customer support with dynamic information, and research assistants where data freshness is critical.\""
      }
    },
    
    {
      "@type": "Question",
      "name": "\"What is a KV cache in the context of CAG?\"",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "\"A KV (Key-Value) cache is the internal state created from each self-attention layer in a transformer model after it processes and digests all preloaded documents. It represents the model's encoded form of all your knowledge, allowing the model to reference this information without reprocessing the text.\""
      }
    },
    
    {
      "@type": "Question",
      "name": "\"Can RAG and CAG be used together?\"",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "\"Yes, a hybrid approach can combine both techniques. For example, RAG can retrieve the most relevant subset from a massive knowledge base, and then CAG can load that retrieved content into a long-context model for comprehensive processing. This is particularly effective for complex scenarios like clinical decision support systems.\""
      }
    },
    
    {
      "@type": "Question",
      "name": "\"What are the scalability limits of CAG?\"",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "\"CAG is constrained by the model's context window size, typically 32,000 to 100,000 tokens in modern models. This limits CAG to handling a few hundred documents at most, whereas RAG can scale to millions of documents since it only retrieves small relevant pieces per query.\""
      }
    }
    
  ]
}
</script>
<div class="wrapper dark">
<div style="
    position: relative;
    isolation: isolate;
    overflow: hidden;
    border-radius: 0.75rem;
    margin-top: 6rem;
    margin-bottom: 6rem;
    background-color: #000000;
    background-image: 
      linear-gradient(rgba(99, 102, 241, 0.15) 2px, transparent 2px),
      linear-gradient(90deg, rgba(99, 102, 241, 0.15) 2px, transparent 2px);
    background-size: 40px 40px;
    min-height: 400px;
  ">
<div style="position: absolute; top: 0; left: 0; right: 0; bottom: 0; border: 5px solid rgba(99, 102, 241, 0.5); pointer-events: none; z-index: 999;"></div>
<div style="position: absolute; top: 20px; left: 20px; width: 80px; height: 80px; border-left: 3px solid rgba(99, 102, 241, 0.7); border-top: 3px solid rgba(99, 102, 241, 0.7); z-index: 10;"></div>
<div style="position: absolute; top: 20px; right: 20px; width: 80px; height: 80px; border-right: 3px solid rgba(99, 102, 241, 0.7); border-top: 3px solid rgba(99, 102, 241, 0.7); z-index: 10;"></div>
<div style="position: absolute; bottom: 20px; left: 20px; width: 80px; height: 80px; border-left: 3px solid rgba(99, 102, 241, 0.7); border-bottom: 3px solid rgba(99, 102, 241, 0.7); z-index: 10;"></div>
<div style="position: absolute; bottom: 20px; right: 20px; width: 80px; height: 80px; border-right: 3px solid rgba(99, 102, 241, 0.7); border-bottom: 3px solid rgba(99, 102, 241, 0.7); z-index: 10;"></div>
<div style="position: relative; z-index: 20; padding: 6rem 1.5rem;">
<div style="max-width: 42rem; margin: 0 auto; text-align: center;">
<h2 style="font-size: 2.25rem; font-weight: 600; color: #ffffff; margin-bottom: 1.5rem;">
          Build Intelligent AI Workflows with SmartWeb
        </h2>
<p style="font-size: 1.125rem; color: #d1d5db; margin-bottom: 2.5rem; max-width: 36rem; margin-left: auto; margin-right: auto;">
          Create powerful AI agents that leverage RAG and CAG techniques to deliver accurate, contextual responses. Start building with FlowHunt's no-code AI platform today.
        </p>
<div style="display: flex; align-items: center; justify-content: center; gap: 1.5rem; flex-wrap: wrap;">
<a aria-label="Browse resources" class="btn-primary-alternate dark:btn-primary-alternate-dark px-3 py-2 not-prose group" href="#" target="_self">
      Browse resources
      
      
    </a>
<a aria-label="Contact our experts" class="btn-secondary dark:btn-secondary-dark px-3 py-2 not-prose group" href="#" target="_self">
      Contact our experts
      
        <span aria-hidden="true" class="ml-1.5 btn-arrow">
<svg class="map[class:w-5 h-5 p-0.5 icon:arrow-up-right]" fill="none" viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
<path d="M4.5 19.5L19.5 4.5M19.5 4.5L8.25 4.5M19.5 4.5V15.75" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5"></path>
</svg>
</span>
</a>
</div>
</div>
</div>
</div>
</div>
</main>
<footer style="background-color: #000000;">
<div id="cta-curves-container" style="
    position: relative;
    background: #000000;
    padding: 4rem 2rem;
    overflow: hidden;
  ">
<svg id="cta-curves-svg" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 1; opacity: 0.7;" xmlns="http://www.w3.org/2000/svg">
<defs>
<lineargradient id="curveGrad1" x1="0%" x2="100%" y1="0%" y2="0%">
<stop offset="0%" style="stop-color:rgba(99, 102, 241, 0); stop-opacity:0"></stop>
<stop offset="50%" style="stop-color:rgba(99, 102, 241, 0.9); stop-opacity:1"></stop>
<stop offset="100%" style="stop-color:rgba(99, 102, 241, 0); stop-opacity:0"></stop>
</lineargradient>
<lineargradient id="curveGrad2" x1="0%" x2="100%" y1="0%" y2="0%">
<stop offset="0%" style="stop-color:rgba(139, 92, 246, 0); stop-opacity:0"></stop>
<stop offset="50%" style="stop-color:rgba(139, 92, 246, 0.8); stop-opacity:1"></stop>
<stop offset="100%" style="stop-color:rgba(139, 92, 246, 0); stop-opacity:0"></stop>
</lineargradient>
<lineargradient id="curveGrad3" x1="0%" x2="100%" y1="0%" y2="0%">
<stop offset="0%" style="stop-color:rgba(59, 130, 246, 0); stop-opacity:0"></stop>
<stop offset="50%" style="stop-color:rgba(59, 130, 246, 0.7); stop-opacity:1"></stop>
<stop offset="100%" style="stop-color:rgba(59, 130, 246, 0); stop-opacity:0"></stop>
</lineargradient>
</defs>
<path class="curve" data-speed="0.8" fill="none" stroke="url(#curveGrad1)" stroke-width="2"></path>
<path class="curve" data-speed="1.2" fill="none" opacity="0.8" stroke="url(#curveGrad2)" stroke-width="2.5"></path>
<path class="curve" data-speed="0.6" fill="none" opacity="0.6" stroke="url(#curveGrad3)" stroke-width="1.5"></path>
<path class="curve" data-speed="1.5" fill="none" opacity="0.7" stroke="url(#curveGrad1)" stroke-width="2"></path>
<path class="curve" data-speed="0.9" fill="none" opacity="0.5" stroke="url(#curveGrad2)" stroke-width="3"></path>
<path class="curve" data-speed="1.3" fill="none" opacity="0.9" stroke="url(#curveGrad3)" stroke-width="1.8"></path>
<path class="curve" data-speed="0.7" fill="none" opacity="0.6" stroke="url(#curveGrad1)" stroke-width="2.2"></path>
<path class="curve" data-speed="1.1" fill="none" opacity="0.8" stroke="url(#curveGrad2)" stroke-width="2"></path>
<path class="curve" data-speed="1.4" fill="none" opacity="0.5" stroke="url(#curveGrad3)" stroke-width="2.5"></path>
<path class="curve" data-speed="0.85" fill="none" opacity="0.7" stroke="url(#curveGrad1)" stroke-width="1.5"></path>
<path class="curve" data-speed="1.0" fill="none" opacity="0.6" stroke="url(#curveGrad2)" stroke-width="2.8"></path>
<path class="curve" data-speed="1.25" fill="none" opacity="0.8" stroke="url(#curveGrad3)" stroke-width="2"></path>
<path class="curve" data-speed="0.95" fill="none" opacity="0.5" stroke="url(#curveGrad1)" stroke-width="2.3"></path>
<path class="curve" data-speed="1.35" fill="none" opacity="0.9" stroke="url(#curveGrad2)" stroke-width="1.7"></path>
<path class="curve" data-speed="0.75" fill="none" opacity="0.7" stroke="url(#curveGrad3)" stroke-width="2.5"></path>
</svg>
<div style="position: absolute; top: 0; left: 0; width: 50px; height: 50px; border-left: 2px solid rgba(99, 102, 241, 0.3); border-top: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div style="position: absolute; top: 0; right: 0; width: 50px; height: 50px; border-right: 2px solid rgba(99, 102, 241, 0.3); border-top: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div style="position: absolute; bottom: 0; left: 0; width: 50px; height: 50px; border-left: 2px solid rgba(99, 102, 241, 0.3); border-bottom: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div style="position: absolute; bottom: 0; right: 0; width: 50px; height: 50px; border-right: 2px solid rgba(99, 102, 241, 0.3); border-bottom: 2px solid rgba(99, 102, 241, 0.3);"></div>
<div class="mx-auto max-w-2xl text-center" style="position: relative; z-index: 10;">
<h2 class="text-base/7 font-semibold text-indigo-400">Ready to get started?</h2>
<p class="mt-2 text-4xl font-semibold tracking-tight text-balance text-white sm:text-5xl">Start using our services today</p>
<p class="mx-auto mt-6 max-w-xl text-lg/8 text-pretty text-gray-400">Join thousands of satisfied customers who have transformed their business with our solutions.</p>
<div class="mt-8 flex justify-center">
<a class="rounded-md bg-indigo-500 px-3.5 py-2.5 text-sm font-semibold text-white shadow-xs hover:bg-indigo-400 focus-visible:outline-2 focus-visible:outline-offset-2 focus-visible:outline-indigo-400" href="/en/blog/">Get started</a>
</div>
</div>
</div>
<script>
  (function() {
    'use strict';
    
    const container = document.getElementById('cta-curves-container');
    const svg = document.getElementById('cta-curves-svg');
    if (!container || !svg) return;
    
    const curves = svg.querySelectorAll('.curve');
    let mouseX = 0;
    let mouseY = 0;
    let targetMouseX = 0;
    let targetMouseY = 0;
    const mouseInfluence = 150;
    const mouseStrength = 80;
    
    const curveData = Array.from(curves).map((curve, i) => {
      const speed = parseFloat(curve.getAttribute('data-speed')) || 1;
      return {
        element: curve,
        baseY: 50 + (i * 25),
        offset: Math.random() * Math.PI * 2,
        speed: speed,
        amplitude: 30 + Math.random() * 40
      };
    });
    
    container.addEventListener('mousemove', (e) => {
      const rect = container.getBoundingClientRect();
      targetMouseX = e.clientX - rect.left;
      targetMouseY = e.clientY - rect.top;
    });
    
    container.addEventListener('mouseleave', () => {
      targetMouseX = -1000;
      targetMouseY = -1000;
    });
    
    let time = 0;
    
    function animate() {
      time += 0.01;
      
      mouseX += (targetMouseX - mouseX) * 0.15;
      mouseY += (targetMouseY - mouseY) * 0.15;
      
      const width = svg.clientWidth;
      const height = svg.clientHeight;
      
      curveData.forEach((data, index) => {
        const { baseY, offset, speed, amplitude } = data;
        const phase = time * speed + offset;
        
        let path = `M -200,${baseY}`;
        
        for (let x = -200; x <= width + 200; x += 50) {
          const normalY = baseY + Math.sin((x * 0.005) + phase) * amplitude;
          
          const dx = x - mouseX;
          const dy = normalY - mouseY;
          const distance = Math.sqrt(dx * dx + dy * dy);
          
          let y = normalY;
          if (distance < mouseInfluence) {
            const influence = (1 - distance / mouseInfluence);
            const pushY = (normalY - mouseY) * influence * mouseStrength * 0.01;
            y = normalY + pushY;
          }
          
          const nextX = x + 50;
          const controlX = x + 25;
          const controlY = y;
          path += ` Q ${controlX},${controlY} ${nextX},${y}`;
        }
        
        data.element.setAttribute('d', path);
      });
      
      requestAnimationFrame(animate);
    }
    
    animate();
  })();
  </script>
<div class="mx-auto max-w-7xl px-6 py-16 sm:py-24 lg:px-8 lg:py-32">
<div class="mt-24 border-t border-white/10 pt-12 xl:grid xl:grid-cols-3 xl:gap-8">
<picture class="lazy-picture" data-maxwidth="200">
<source data-original-src="/images/interwork-logo-white-1.webp" data-srcset="/images/interwork-logo-white-1.webp 568w" sizes="200px" type="image/webp">
<img alt="Interwork" class="lazy-image h-9" data-original-src="/images/interwork-logo-white-1.webp" data-src="/images/interwork-logo-white-1.webp" decoding="async" loading="lazy"/>
</source></picture>
<div class="mt-16 grid grid-cols-2 gap-8 xl:col-span-2 xl:mt-0">
<div class="md:grid md:grid-cols-2 md:gap-8">
<div>
<h3 class="text-sm/6 font-semibold text-white">Services</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">AI Solutions</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">Web Development</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">System Development</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">Consulting</a>
</li>
</ul>
</div>
<div class="mt-10 md:mt-0">
<h3 class="text-sm/6 font-semibold text-white">Support</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="https://support.smartweb.jp/">Support Portal</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">Documentation</a>
</li>
</ul>
</div>
</div>
<div class="md:grid md:grid-cols-2 md:gap-8">
<div>
<h3 class="text-sm/6 font-semibold text-white">Company</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="https://www.intwk.co.jp/about/">About</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="/en/blog/">Blog</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">Careers</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="#">News</a>
</li>
</ul>
</div>
<div class="mt-10 md:mt-0">
<h3 class="text-sm/6 font-semibold text-white">Legal</h3>
<ul class="mt-6 space-y-4" role="list">
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="/en/privacy-policy/">Privacy Policy</a>
</li>
<li>
<a class="text-sm/6 text-gray-400 hover:text-white" href="/en/ai-chatbot-terms-of-use/">AI Chatbot Terms of Use</a>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="language-selector mt-12 border-t border-white/10 pt-8 md:flex md:items-center md:justify-between">
<div>
<p class="text-sm/6 font-semibold text-white mb-4">Available Languages</p>
<div class="language-selector">
<div class="flex flex-wrap items-center justify-center gap-3">
<a aria-label="日本語" class="inline-flex items-center text-sm hover:opacity-75 transition-opacity" href="/ja/" hreflang="ja" title="日本語">
<img alt="日本語" class="rounded" height="18" src="/flags/jp.png" width="24"/>
</a>
<span class="inline-flex items-center text-sm opacity-50" title="English">
<img alt="English" class="rounded" height="18" src="/flags/gb.png" width="24"/>
</span>
</div>
</div>
</div>
</div>
<div class="mt-12 border-t border-white/10 pt-8 md:flex md:items-center md:justify-between">
<div class="flex gap-x-6 md:order-2">
<a class="text-gray-400 hover:text-gray-300" href="https://github.com">
<span class="sr-only">GitHub</span>
</a>
<a class="text-gray-400 hover:text-gray-300" href="https://x.com">
<span class="sr-only">X</span>
</a>
<a class="text-gray-400 hover:text-gray-300" href="https://youtube.com">
<span class="sr-only">YouTube</span>
</a>
</div>
<p class="mt-8 text-sm/6 text-gray-400 md:mt-0" style="text-align: center; animation: copyrightGlow 3s ease-in-out infinite;">© 2026 Interwork Corporation All rights reserved.</p>
</div>
</div>
<style>
    @keyframes copyrightGlow {
      0%, 100% {
        opacity: 0.6;
        text-shadow: 0 0 10px rgba(99, 102, 241, 0);
      }
      50% {
        opacity: 1;
        text-shadow: 0 0 20px rgba(99, 102, 241, 0.5), 0 0 30px rgba(99, 102, 241, 0.3);
      }
    }
  </style>
</footer>
<div class="pointer-events-none fixed inset-x-0 bottom-0 px-6 pb-6 z-50 dark" data-cookie-consent-banner="" id="cookie-consent-banner">
<div class="pointer-events-auto max-w-xl rounded-xl section-bg-light dark:section-bg-dark p-6 ring-1 shadow-lg ring-gray-900/10">
<p class="text-secondary text-sm/6"><strong class="text-heading text-md mb-4 font-semibold">Cookie Consent</strong><br/> We use cookies to enhance your browsing experience and analyze our traffic. See our <a class="font-semibold text-primary hover:text-primary-500" href="/en/privacy-policy/">privacy policy</a>.</p>
<div class="mt-4 flex items-center gap-x-3 flex-wrap">
<a aria-label="Accept All" class="btn-primary dark:btn-primary-dark px-3 py-2 text-sm not-prose group" data-cookie-consent="accept-all" href="#" target="_self">
      Accept All
      
      
    </a>
<a aria-label="Reject All" class="btn-secondary dark:btn-secondary-dark px-3 py-2 text-sm not-prose group" data-cookie-consent="accept-necessary" href="#" target="_self">
      Reject All
      
      
    </a>
<a aria-label="Cookie Settings" class="btn-text dark:btn-text-dark px-3 py-2 text-sm not-prose group" data-cookie-consent="settings" href="#" target="_self">
      Cookie Settings
      
      
    </a>
</div>
</div>
</div>
<div class="fixed inset-0 z-50 hidden dark" id="cookie-settings-modal">
<div class="absolute inset-0 bg-black bg-opacity-50" data-cookie-settings-close=""></div>
<div class="relative mx-auto max-w-xl p-4 sm:p-6 section-bg-light dark:section-bg-dark rounded-xl shadow-xl mt-20">
<div class="flex justify-between items-center mb-4">
<h2 class="text-heading text-xl font-bold">Cookie Settings</h2>
<button class="text-gray-400 hover:text-gray-500 dark:text-gray-300 dark:hover:text-white" data-cookie-settings-close="" type="button">
<span class="sr-only">Close</span>
<svg class="h-6 w-6" fill="none" stroke="currentColor" viewbox="0 0 24 24">
<path d="M6 18L18 6M6 6l12 12" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"></path>
</svg>
</button>
</div>
<div class="space-y-4">
<div class="border-gray-200 dark:border-gray-700 border-b pb-4">
<div class="flex items-center justify-between">
<div>
<h3 class="text-heading text-lg font-medium">Necessary Cookies</h3>
<p class="text-tertiary text-sm">These cookies are required for the website to function and cannot be disabled.</p>
</div>
<div class="ml-3 flex h-5 items-center">
<input checked="" class="h-4 w-4 rounded-xl border-gray-300 text-primary focus:ring-primary dark:border-gray-600 dark:bg-gray-700" disabled="" id="necessary-cookies" name="necessary-cookies" type="checkbox"/>
</div>
</div>
</div>
<div class="border-gray-200 dark:border-gray-700 border-b pb-4">
<div class="flex items-center justify-between">
<div>
<h3 class="text-heading text-lg font-medium">Analytics Cookies</h3>
<p class="text-tertiary text-sm">These cookies help us understand how visitors interact with our website.</p>
</div>
<div class="ml-3 flex h-5 items-center">
<input class="h-4 w-4 rounded-xl border-gray-300 text-primary focus:ring-primary dark:border-gray-600 dark:bg-gray-700" id="analytics-cookies" name="analytics-cookies" type="checkbox"/>
</div>
</div>
</div>
</div>
<div class="mt-6 flex justify-end gap-x-3">
<a aria-label="Cancel" class="btn-secondary dark:btn-secondary-dark px-3 py-2 not-prose group" data-cookie-settings-close="" href="#" target="_self">
      Cancel
      
      
    </a>
<a aria-label="Save Preferences" class="btn-primary dark:btn-primary-dark px-3 py-2 not-prose group" data-cookie-settings-save="" href="#" target="_self">
      Save Preferences
      
      
    </a>
</div>
</div>
</div>
<script src="/js/app.js?v=20260111165525"></script>
</body>
</html>